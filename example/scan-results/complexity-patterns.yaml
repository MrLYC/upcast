metadata: {}
results:
  apiserver/paasng/paas_wl/bk_app/cnative/specs/resource.py:
  - code: "\ndef detect_state(self) -> ModelResState:\n    \"\"\"Detect the final\
      \ state from status.conditions\"\"\"\n    if not self.mres.status.conditions:\n\
      \        return ModelResState(DeployStatus.PENDING, 'Pending', 'state not initialized')\n\
      \    if self.mres.status.phase == MResPhaseType.AppRunning:\n        available\
      \ = self._find_condition(MResConditionType.APP_AVAILABLE)\n        if available\
      \ and available.status == ConditionStatus.TRUE:\n            return ModelResState(DeployStatus.READY,\
      \ available.reason, available.message)\n    if self.mres.status.phase == MResPhaseType.AppFailed:\n\
      \        reasons: List[str] = []\n        messages: List[str] = []\n       \
      \ for cond in self.mres.status.conditions:\n            if cond.status == ConditionStatus.FALSE\
      \ and cond.message:\n                reasons.append(cond.reason)\n         \
      \       messages.append(cond.message)\n        if messages:\n            return\
      \ ModelResState(DeployStatus.ERROR, '\\n'.join(reasons), '\\n'.join(messages))\n\
      \        return ModelResState(DeployStatus.ERROR, 'Unknown', '')\n    return\
      \ ModelResState(DeployStatus.PROGRESSING, 'Progressing', 'progressing')"
    code_lines: 22
    comment_lines: 0
    complexity: 10
    description: Detect the final state from status.conditions
    end_line: 204
    line: 183
    message: Complexity 10 exceeds threshold 10
    name: detect_state
    severity: acceptable
    signature: 'def detect_state ( self ) -> ModelResState :'
  apiserver/paasng/paas_wl/bk_app/dev_sandbox/kres_slzs/ingress.py:
  - code: "\ndef serialize(self, obj: 'DevSandboxIngress', original_obj: Optional[ResourceInstance]\
      \ = None, **kwargs) -> Dict:\n    \"\"\"serialize obj into Ingress(networking.k8s.io/v1)\"\
      \"\"\n    nginx_adaptor = NginxRegexRewrittenProvider()\n    annotations = {ANNOT_SSL_REDIRECT:\
      \ 'false', ANNOT_SKIP_FILTER_CLB: 'true'}\n    if obj.rewrite_to_root:\n   \
      \     annotations[ANNOT_REWRITE_TARGET] = nginx_adaptor.make_rewrite_target()\n\
      \    if obj.set_header_x_script_name:\n        annotations[ANNOT_CONFIGURATION_SNIPPET]\
      \ = nginx_adaptor.make_configuration_snippet()\n    if settings.APP_INGRESS_CLASS\
      \ is not None:\n        annotations['kubernetes.io/ingress.class'] = settings.APP_INGRESS_CLASS\n\
      \    tls_group_by_secret_name: Dict[str, List] = defaultdict(list)\n    for\
      \ domain in obj.domains:\n        if domain.tls_enabled:\n            tls_group_by_secret_name[domain.tls_secret_name].append(domain.host)\n\
      \    tls = []\n    for (secret_name, hosts) in tls_group_by_secret_name.items():\n\
      \        tls.append({'hosts': hosts, 'secretName': secret_name})\n    rules\
      \ = []\n    for domain in obj.domains:\n        paths = []\n        for backend\
      \ in domain.path_backends:\n            paths.append({'path': nginx_adaptor.make_location_path(backend.path_prefix\
      \ or '/') if obj.rewrite_to_root else backend.path_prefix, 'pathType': 'ImplementationSpecific',\
      \ 'backend': {'service': {'name': backend.service_name, 'port': {'name': backend.service_port_name}}}})\n\
      \        rules.append({'host': domain.host, 'http': {'paths': paths}})\n   \
      \ body: Dict[str, Any] = {'metadata': {'name': obj.name, 'annotations': annotations,\
      \ 'labels': {'env': 'dev'}}, 'spec': {'rules': rules, 'tls': tls}, 'apiVersion':\
      \ self.get_api_version_from_gvk(self.gvk_config), 'kind': 'Ingress'}\n    if\
      \ original_obj:\n        body['metadata']['resourceVersion'] = original_obj.metadata.resourceVersion\n\
      \    return body"
    code_lines: 57
    comment_lines: 0
    complexity: 11
    description: serialize obj into Ingress(networking.k8s.io/v1)
    end_line: 108
    line: 52
    message: Complexity 11 exceeds threshold 10
    name: serialize
    severity: warning
    signature: 'def serialize ( self, obj: ''DevSandboxIngress'', original_obj: Optional[ResourceInstance]
      = None, **kwargs ) -> Dict :'
  apiserver/paasng/paas_wl/bk_app/processes/kres_slzs.py:
  - code: "\ndef deserialize(self, app: WlApp, kube_data: ResourceInstance) -> 'Instance':\n\
      \    \"\"\"Generate a ProcInstance by given Pod object\"\"\"\n    pod = kube_data\n\
      \    health_status = check_pod_health_status(parse_pod(kube_data))\n    (instance_state,\
      \ state_message) = self.parse_instance_state(pod.status.phase, health_status)\n\
      \    c_status = None\n    c_status_dict = {}\n    if pod.status.get('containerStatuses'):\n\
      \        c_status = pod.status.containerStatuses[0]\n        c_status_dict =\
      \ get_items(pod.to_dict(), 'status.containerStatuses', [{}])[0]\n    process_type\
      \ = self.get_process_type(pod)\n    target_container = self._get_main_container(app,\
      \ pod)\n    envs = {}\n    if target_container and hasattr(target_container,\
      \ 'env'):\n        for env in target_container.env:\n            name = getattr(env,\
      \ 'name', None)\n            value = getattr(env, 'value', None)\n         \
      \   if name and value is not None:\n                envs[name] = value\n   \
      \ if app.type == WlAppType.DEFAULT:\n        labels = pod.metadata.labels or\
      \ {}\n        version = int(labels.get('release_version', 0))\n    else:\n \
      \       annotations = pod.metadata.annotations or {}\n        version = int(annotations.get(BKPAAS_DEPLOY_ID_ANNO_KEY,\
      \ 0))\n    terminated_info = {}\n    if c_status_dict:\n        terminated_info\
      \ = {'exit_code': get_items(c_status_dict, 'lastState.terminated.exitCode'),\
      \ 'reason': get_items(c_status_dict, 'lastState.terminated.reason')}\n    return\
      \ self.entity_type(app=app, name=pod.metadata.name, process_type=process_type,\
      \ host_ip=pod.status.get('hostIP', None), start_time=pod.status.get('startTime',\
      \ None), state=instance_state, state_message=state_message, rich_status=self.extract_rich_status(pod.status.phase,\
      \ c_status), image=target_container.image if target_container else '', envs=envs,\
      \ ready=health_status.status == HealthStatusType.HEALTHY, restart_count=c_status.restartCount\
      \ if c_status else 0, terminated_info=terminated_info, version=version)"
    code_lines: 53
    comment_lines: 0
    complexity: 11
    description: Generate a ProcInstance by given Pod object
    end_line: 246
    line: 194
    message: Complexity 11 exceeds threshold 10
    name: deserialize
    severity: warning
    signature: 'def deserialize ( self, app: WlApp, kube_data: ResourceInstance )
      -> ''Instance'' :'
  apiserver/paasng/paas_wl/bk_app/processes/models.py:
  - code: "\ndef process_spec_updator(process: ProcessTmpl) -> Tuple[bool, ProcessSpec]:\n\
      \    process_spec = proc_specs.get(name=process.name)\n    recorder = AttrSetter(process_spec)\n\
      \    if process_spec.target_status != ProcessTargetStatus.START.value:\n   \
      \     recorder.setattr('target_status', ProcessTargetStatus.START.value)\n \
      \   if command := process.command and command != process_spec.proc_command:\n\
      \        recorder.setattr('proc_command', command)\n    if plan_name := process.plan\
      \ and plan := self.get_plan(plan_name, None):\n        recorder.setattr('plan',\
      \ plan)\n    if process.autoscaling != process_spec.autoscaling:\n        recorder.setattr('autoscaling',\
      \ process.autoscaling)\n    if scaling_config := process.scaling_config and\
      \ scaling_config.dict() != process_spec.scaling_config:\n        recorder.setattr('scaling_config',\
      \ scaling_config.dict())\n    if replicas := process.replicas and replicas !=\
      \ process_spec.target_replicas:\n        recorder.setattr('target_replicas',\
      \ replicas)\n    return recorder.changed, process_spec"
    code_lines: 19
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 199
    line: 181
    message: Complexity 11 exceeds threshold 10
    name: process_spec_updator
    severity: warning
    signature: 'def process_spec_updator ( process: ProcessTmpl ) -> Tuple[bool, ProcessSpec]
      :'
  - code: "\ndef sync(self, processes: List[ProcessTmpl]):\n    \"\"\"Sync ProcessSpecs\
      \ data with given processes.\n\n        :param processes: plain process spec\
      \ structure,\n                          such as [{\"name\": \"web\", \"command\"\
      : \"foo\", \"replicas\": 1, \"plan\": \"bar\"}, ...]\n                     \
      \     where 'replicas' and 'plan' is optional\n        \"\"\"\n    processes_map:\
      \ Dict[str, ProcessTmpl] = {process.name: process for process in processes}\n\
      \    environment = get_metadata(self.wl_app).environment\n    proc_type = 'process'\n\
      \    proc_specs = ProcessSpec.objects.filter(engine_app=self.wl_app, type=proc_type)\n\
      \    existed_procs_name = set(proc_specs.values_list('name', flat=True))\n \
      \   removing_procs_name = list(existed_procs_name - processes_map.keys())\n\
      \    if removing_procs_name:\n        proc_specs.filter(name__in=removing_procs_name).delete()\n\
      \    default_process_spec_plan = ProcessSpecPlan.objects.get_by_name(name=settings.DEFAULT_PROC_SPEC_PLAN)\n\
      \    if self.wl_app.type == WlAppType.CLOUD_NATIVE:\n        default_process_spec_plan\
      \ = ProcessSpecPlan.objects.get_by_name(name=ResQuotaPlan.P_DEFAULT) or default_process_spec_plan\n\
      \    adding_procs = [process for (name, process) in processes_map.items() if\
      \ name not in existed_procs_name]\n    \n    def process_spec_builder(process:\
      \ ProcessTmpl) -> ProcessSpec:\n        target_replicas = process.replicas or\
      \ self.get_default_replicas(process.name, environment)\n        plan = default_process_spec_plan\n\
      \        if plan_name := process.plan:\n            plan = self.get_plan(plan_name,\
      \ default_process_spec_plan)\n        return ProcessSpec(type=proc_type, region=self.wl_app.region,\
      \ name=process.name, engine_app_id=self.wl_app.pk, target_replicas=target_replicas,\
      \ plan=plan, proc_command=process.command, autoscaling=process.autoscaling,\
      \ scaling_config=process.scaling_config.dict() if process.scaling_config else\
      \ None)\n    self.bulk_create_procs(proc_creator=process_spec_builder, adding_procs=adding_procs)\n\
      \    updating_proc_specs = [process for (name, process) in processes_map.items()\
      \ if name in existed_procs_name]\n    \n    def process_spec_updator(process:\
      \ ProcessTmpl) -> Tuple[bool, ProcessSpec]:\n        process_spec = proc_specs.get(name=process.name)\n\
      \        recorder = AttrSetter(process_spec)\n        if process_spec.target_status\
      \ != ProcessTargetStatus.START.value:\n            recorder.setattr('target_status',\
      \ ProcessTargetStatus.START.value)\n        if command := process.command and\
      \ command != process_spec.proc_command:\n            recorder.setattr('proc_command',\
      \ command)\n        if plan_name := process.plan and plan := self.get_plan(plan_name,\
      \ None):\n            recorder.setattr('plan', plan)\n        if process.autoscaling\
      \ != process_spec.autoscaling:\n            recorder.setattr('autoscaling',\
      \ process.autoscaling)\n        if scaling_config := process.scaling_config\
      \ and scaling_config.dict() != process_spec.scaling_config:\n            recorder.setattr('scaling_config',\
      \ scaling_config.dict())\n        if replicas := process.replicas and replicas\
      \ != process_spec.target_replicas:\n            recorder.setattr('target_replicas',\
      \ replicas)\n        return recorder.changed, process_spec\n    self.bulk_update_procs(proc_updator=process_spec_updator,\
      \ updating_procs=updating_proc_specs, updated_fields=['proc_command', 'plan',\
      \ 'autoscaling', 'scaling_config', 'target_replicas', 'target_status', 'updated'])"
    code_lines: 85
    comment_lines: 0
    complexity: 17
    description: Sync ProcessSpecs data with given processes.
    end_line: 213
    line: 129
    message: Complexity 17 exceeds threshold 10
    name: sync
    severity: high_risk
    signature: 'def sync ( self, processes: List[ProcessTmpl] ) :'
  apiserver/paasng/paas_wl/infras/cluster/models.py:
  - code: "\n@transaction.atomic(using='workloads')\ndef register_cluster(self, region:\
      \ str, name: str, type: str = ClusterType.NORMAL, is_default: bool = False,\
      \ description: Optional[str] = None, ingress_config: Optional[Dict] = None,\
      \ annotations: Optional[Dict] = None, ca_data: Optional[str] = None, cert_data:\
      \ Optional[str] = None, key_data: Optional[str] = None, token_type: Optional[ClusterTokenType]\
      \ = None, token_value: Optional[str] = None, default_node_selector: Optional[Dict]\
      \ = None, default_tolerations: Optional[List] = None, feature_flags: Optional[Dict]\
      \ = None, pk: Optional[str] = None, **kwargs) -> 'Cluster':\n    \"\"\"Register\
      \ a cluster to db, work Like update_or_create, but will validate some-attr\n\
      \n        Auth type: client-side cert\n        ---------------------------\n\
      \n        :param cert_data: client cert data\n        :param key_data: client\
      \ key data\n\n        Auth type: Bearer token\n        -----------------------\n\
      \n        :param token_type: token type, use `SERVICE_ACCOUNT` by default\n\
      \        :param token_value: value of token\n        \"\"\"\n    default_cluster_qs\
      \ = self.filter(region=region, is_default=True)\n    if not default_cluster_qs.exists()\
      \ and not is_default:\n        raise NoDefaultClusterError('This region has\
      \ not define a default cluster.')\n    elif default_cluster_qs.filter(name=name).exists()\
      \ and not is_default:\n        raise SwitchDefaultClusterError(\"Can't change\
      \ default cluster by calling `register_cluster`, please use `switch_default_cluster`\"\
      )\n    elif default_cluster_qs.exclude(name=name).exists() and is_default:\n\
      \        raise DuplicatedDefaultClusterError('This region should have one and\
      \ only one default cluster.')\n    validate_ingress_config(ingress_config)\n\
      \    defaults: Dict[str, Any] = {'type': type, 'is_default': is_default, 'description':\
      \ description, 'ingress_config': ingress_config, 'annotations': annotations,\
      \ 'ca_data': ca_data, 'cert_data': cert_data, 'key_data': key_data, 'default_node_selector':\
      \ default_node_selector, 'default_tolerations': default_tolerations, 'feature_flags':\
      \ feature_flags}\n    if token_value:\n        _token_type = token_type or ClusterTokenType.SERVICE_ACCOUNT\n\
      \        defaults.update({'token_value': token_value, 'token_type': _token_type})\n\
      \    defaults = {k: v for (k, v) in defaults.items() if v is not None}\n   \
      \ if pk:\n        (cluster, _) = self.update_or_create(pk=pk, name=name, region=region,\
      \ defaults=defaults)\n    else:\n        (cluster, _) = self.update_or_create(name=name,\
      \ region=region, defaults=defaults)\n    return cluster"
    code_lines: 73
    comment_lines: 0
    complexity: 10
    description: Register a cluster to db, work Like update_or_create, but will validate
      some-attr
    end_line: 207
    line: 135
    message: Complexity 10 exceeds threshold 10
    name: register_cluster
    severity: acceptable
    signature: 'def register_cluster ( self, region: str, name: str, type: str = ClusterType.NORMAL,
      is_default: bool = False, description: Optional[str] = None, ingress_config:
      Optional[Dict] = None, annotations: Optional[Dict] = None, ca_data: Optional[str]
      = None, cert_data: Optional[str] = None, key_data: Optional[str] = None, token_type:
      Optional[ClusterTokenType] = None, token_value: Optional[str] = None, default_node_selector:
      Optional[Dict] = None, default_tolerations: Optional[List] = None, feature_flags:
      Optional[Dict] = None, pk: Optional[str] = None, **kwargs ) -> ''Cluster'' :'
  apiserver/paasng/paas_wl/infras/resources/base/kres.py:
  - code: "\ndef create_or_update(self, name: str, namespace: Namespace = None, body:\
      \ Optional[Manifest] = None, update_method: str = 'replace', content_type: Optional[str]\
      \ = None, auto_add_version: bool = False) -> Tuple[ResourceInstance, bool]:\n\
      \    \"\"\"Create or update a resource by name\n\n        :param content_type:\
      \ content_type header for patch/replace requests\n        :param auto_add_version:\
      \ 当 update_method=replace 时，是否自动添加 metadata.resourceVersion 字段，默认为 False\n \
      \       :returns: (instance, created)\n        \"\"\"\n    assert update_method\
      \ in ['replace', 'patch'], 'Invalid update_method {}'.format(update_method)\n\
      \    if not body:\n        body_dict: Dict = {'kind': self.kres.kind, 'metadata':\
      \ {'name': name}}\n    else:\n        body_dict = self.client.serialize_body(body)\n\
      \    body_dict.setdefault('kind', self.kres.kind)\n    if body_dict and body_dict['metadata']['name']\
      \ != name:\n        raise ValueError('name in args must match name in body')\n\
      \    try:\n        obj = self.resource.create(body=body_dict, namespace=namespace,\
      \ **self.default_kwargs)\n    except ApiException as e:\n        if not (e.status\
      \ == 409 and json.loads(e.body)['reason'] == 'AlreadyExists'):\n           \
      \ raise\n    else:\n        return obj, True\n    if update_method == 'replace'\
      \ and auto_add_version:\n        self._add_resource_version(name, namespace,\
      \ body_dict)\n    logger.info(f'Create {self.kres.kind} {name} failed, already\
      \ existed, continue update')\n    _func = getattr(self.resource, update_method)\n\
      \    update_kwargs = self.default_kwargs.copy()\n    if content_type:\n    \
      \    update_kwargs['content_type'] = content_type\n    obj = _func(name=name,\
      \ body=body_dict, namespace=namespace, **update_kwargs)\n    return obj, False"
    code_lines: 46
    comment_lines: 0
    complexity: 11
    description: Create or update a resource by name
    end_line: 335
    line: 290
    message: Complexity 11 exceeds threshold 10
    name: create_or_update
    severity: warning
    signature: 'def create_or_update ( self, name: str, namespace: Namespace = None,
      body: Optional[Manifest] = None, update_method: str = ''replace'', content_type:
      Optional[str] = None, auto_add_version: bool = False ) -> Tuple[ResourceInstance,
      bool] :'
  apiserver/paasng/paas_wl/infras/resources/base/kube_client.py:
  - code: "\ndef __search(self, parts, resources, reqParams):\n    part = parts[0]\n\
      \    if part != '*':\n        resourcePart = resources.get(part)\n        if\
      \ not resourcePart:\n            return []\n        elif isinstance(resourcePart,\
      \ ResourceGroup):\n            if len(reqParams) != 2:\n                raise\
      \ ValueError('prefix and group params should be present, have %s' % reqParams)\n\
      \            if not resourcePart.resources:\n                (prefix, group,\
      \ version) = (reqParams[0], reqParams[1], part)\n                try:\n    \
      \                resourcePart.resources = self.get_resources_for_api_version(prefix,\
      \ group, part, resourcePart.preferred)\n                except NotFoundError:\n\
      \                    raise ResourceNotFoundError\n                if resourcePart.resources:\n\
      \                    self._cache['resources'][prefix][group][version] = resourcePart\n\
      \                    self.__update_cache = True\n            return self.__search(parts[1:],\
      \ resourcePart.resources, reqParams)\n        elif isinstance(resourcePart,\
      \ dict):\n            return self.__search(parts[1:], resourcePart, reqParams\
      \ + [part])\n        elif parts[1] != '*' and isinstance(parts[1], dict):\n\
      \            for _resource in resourcePart:\n                for (term, value)\
      \ in parts[1].items():\n                    if getattr(_resource, term) == value:\n\
      \                        return [_resource]\n            return []\n       \
      \ else:\n            return resourcePart\n    else:\n        matches = []\n\
      \        for key in resources.keys():\n            matches.extend(self.__search([key]\
      \ + parts[1:], resources, reqParams))\n        return matches"
    code_lines: 44
    comment_lines: 0
    complexity: 15
    description: ''
    end_line: 78
    line: 35
    message: Complexity 15 exceeds threshold 10
    name: __search
    severity: warning
    signature: 'def __search ( self, parts, resources, reqParams ) :'
  apiserver/paasng/paas_wl/infras/resources/kube_res/base.py:
  - code: "\ndef watch_by_app(self, app: WlApp, labels: Optional[Dict] = None, ignore_unknown_objs:\
      \ bool = False, **kwargs) -> Iterator[WatchEvent[AET]]:\n    \"\"\"Get notified\
      \ when resource changes\n\n        :param labels: labels for filtering results\n\
      \        :param ignore_unknown_objs: whether skip watch event when deserialize\
      \ can not handle the object\n        \"\"\"\n    labels = labels or {}\n   \
      \ if 'resource_version' in kwargs and kwargs['resource_version'] is None:\n\
      \        kwargs.pop('resource_version')\n    if kwargs.get('namespace'):\n \
      \       raise ValueError('\"namespace\" is not supported')\n    deserializer\
      \ = self._make_deserializer(app)\n    with self.kres(app, api_version=deserializer.get_apiversion())\
      \ as kres_client:\n        try:\n            for raw_event in kres_client.ops_batch.create_watch_stream(namespace=self._get_namespace(app),\
      \ labels=labels, **kwargs):\n                if raw_event['type'] == 'ERROR':\n\
      \                    raw_object = raw_event['raw_object']\n                \
      \    msg = raw_object.get('message', 'Unknown')\n                    yield WatchEvent(type='ERROR',\
      \ error_message=msg)\n                    return\n                event = WatchEvent[AET](type=raw_event['type'])\n\
      \                try:\n                    event.res_object = deserializer.deserialize(app,\
      \ raw_event['object'])\n                except AppEntityDeserializeError as\
      \ e:\n                    if ignore_unknown_objs:\n                        logger.warning('failed\
      \ to deserialize k8s resource %s, skip.', e.res)\n                        continue\n\
      \                    yield WatchEvent(type='ERROR', error_message=e.msg)\n \
      \                   return\n                event.res_object._kube_data = raw_event['object']\n\
      \                yield event\n        except ApiException as exc:\n        \
      \    if self._exc_is_expired_rv(exc):\n                yield WatchEvent(type='ERROR',\
      \ error_message=exc.reason)\n                return\n            else:\n   \
      \             raise"
    code_lines: 47
    comment_lines: 0
    complexity: 10
    description: Get notified when resource changes
    end_line: 509
    line: 463
    message: Complexity 10 exceeds threshold 10
    name: watch_by_app
    severity: acceptable
    signature: 'def watch_by_app ( self, app: WlApp, labels: Optional[Dict] = None,
      ignore_unknown_objs: bool = False, **kwargs ) -> Iterator[WatchEvent[AET]] :'
  apiserver/paasng/paas_wl/utils/kubestatus.py:
  - code: "\ndef check_pod_health_status(pod: kmodels.V1Pod) -> HealthStatus:\n  \
      \  \"\"\"Check if the pod is healthy\n\n    For a Pod, healthy is meaning that\
      \ the Pod is successfully complete or is Ready\n               unhealthy is\
      \ meaning that the Pod is restarting or is Failed\n               progressing\
      \ is meaning that the Pod is still running and condition `PodReady` is False.\n\
      \    \"\"\"\n    pod_status: kmodels.V1PodStatus = pod.status\n    healthy =\
      \ HealthStatus(reason=pod_status.reason, message=pod_status.message, status=HealthStatusType.HEALTHY)\n\
      \    unhealthy = HealthStatus(reason=pod_status.reason, message=pod_status.message,\
      \ status=HealthStatusType.UNHEALTHY)\n    progressing = HealthStatus(reason=pod_status.reason,\
      \ message=pod_status.message, status=HealthStatusType.PROGRESSING)\n    if pod_status.phase\
      \ == 'Succeeded':\n        return healthy\n    elif pod_status.phase == 'Running':\n\
      \        pod_spec: kmodels.V1PodSpec = pod.spec\n        if pod_spec.restart_policy\
      \ == 'Always':\n            cond_ready = find_pod_status_condition(pod_status.conditions\
      \ or [], cond_type='Ready')\n            if cond_ready and cond_ready.status\
      \ == 'True':\n                return healthy\n            if fail_message :=\
      \ get_any_container_fail_message(pod):\n                return unhealthy.with_message(fail_message)\n\
      \            return progressing\n        return progressing\n    elif pod_status.phase\
      \ == 'Failed':\n        if pod_status.message:\n            return unhealthy\n\
      \        if fail_message := get_any_container_fail_message(pod):\n         \
      \   return unhealthy.with_message(fail_message)\n        return unhealthy.with_message('unknown')\n\
      \    elif pod_status.phase == 'Pending':\n        if fail_message := get_any_container_fail_message(pod)\
      \ and fail_message not in ['ContainerCreating', 'PodInitializing']:\n      \
      \      return unhealthy.with_message(fail_message)\n        scheduled_cond =\
      \ find_pod_status_condition(pod_status.conditions or [], cond_type='PodScheduled')\n\
      \        if scheduled_cond and scheduled_cond.status == 'False' and scheduled_cond.reason\
      \ in ['Unschedulable', 'SchedulingGated']:\n            return unhealthy.with_message(scheduled_cond.message)\n\
      \        return progressing\n    else:\n        return HealthStatus(reason=pod_status.phase\
      \ or 'unknown', message=pod_status.message, status=HealthStatusType.UNKNOWN)"
    code_lines: 62
    comment_lines: 0
    complexity: 16
    description: Check if the pod is healthy
    end_line: 150
    line: 89
    message: Complexity 16 exceeds threshold 10
    name: check_pod_health_status
    severity: high_risk
    signature: 'def check_pod_health_status ( pod: kmodels.V1Pod ) -> HealthStatus
      :'
  apiserver/paasng/paas_wl/utils/models.py:
  - code: "\ndef make_json_field(cls_name: str, py_model: Type[M], decoder: Callable[[M],\
      \ Dict] = cattr.unstructure, module: Optional[str] = None) -> Type[JSONField]:\n\
      \    \"\"\"生成会自动进行类型转换为 `py_model` 的 JSONField\n\n    :param cls_name: 自动生成的\
      \ JSONField 的类名, 在使用时, cls_name 必须与赋值的变量名一致！否则 migrations 会报错.\n    :param py_model:\
      \ Python 对象, 需要能被 decoder 转换成可序列化成 json serializable 的 dict 对象.\n    :param\
      \ decoder: 能将 py_model instance 反序列化为 json serializable 的 dict 对象\n    :param\
      \ module:\n\n    >>> @dataclass\n    ... class Dummy:\n    ...   foo: str\n\
      \    ...   bar: bool = False\n    >>> DummyField = make_json_field('DummyField',\
      \ Dummy)\n    \"\"\"\n    if not isinstance(py_model, type):\n        raise\
      \ NotImplementedError(f'Unsupported type: {py_model}')\n    \n    def pre_init(self,\
      \ value, obj):\n        \"\"\"Convert a dict/list to dataclass_model object\"\
      \"\"\n        loaded_value = super(JSONField, self).pre_init(value, obj)\n \
      \       if isinstance(loaded_value, py_model) or loaded_value is None:\n   \
      \         return loaded_value\n        return cattr.structure(loaded_value,\
      \ py_model)\n    \n    def get_prep_value(self, value):\n        \"\"\"Convert\
      \ dataclass_model object to a string\"\"\"\n        if isinstance(value, py_model):\n\
      \            value = decoder(value)\n        return super(JSONField, self).get_prep_value(value)\n\
      \    \n    def dumps_for_display(self, value):\n        \"\"\"Convert dataclass_model\
      \ object to a string, calling by jsonfield\"\"\"\n        if isinstance(value,\
      \ py_model):\n            return decoder(value)\n        return super(JSONField,\
      \ self).dumps_for_display(value)\n    \n    def to_python(self, value):\n  \
      \      \"\"\"The jsonfield.SubfieldBase metaclass calls pre_init instead of\
      \ to_python, however to_python\n        is still necessary for Django's deserializer\"\
      \"\"\n        loaded_value = super(JSONField, self).to_python(value)\n     \
      \   if isinstance(loaded_value, py_model) or loaded_value is None:\n       \
      \     return loaded_value\n        return cattr.structure(loaded_value, py_model)\n\
      \    \n    def from_db_value(self, value, expression, connection):\n       \
      \ \"\"\"Convert string-like value to dataclass_model object, calling by django\"\
      \"\"\n        loaded_value = super(JSONField, self).from_db_value(value, expression,\
      \ connection)\n        if isinstance(loaded_value, py_model) or loaded_value\
      \ is None:\n            return loaded_value\n        return cattr.structure(loaded_value,\
      \ py_model)\n    \n    def value_to_string(self, obj):\n        \"\"\"Convert\
      \ dataclass_model object to a string, calling by django\"\"\"\n        value\
      \ = self.value_from_object(obj)\n        return self.get_prep_value(value)\n\
      \    cls = type(cls_name, (JSONField, ), dict(pre_init=pre_init, get_prep_value=get_prep_value,\
      \ dumps_for_display=dumps_for_display, to_python=to_python, from_db_value=from_db_value,\
      \ value_to_string=value_to_string))\n    try:\n        module = sys._getframe(1).f_globals.get('__name__',\
      \ '__main__')\n    except (AttributeError, ValueError):\n        if module is\
      \ None:\n            raise RuntimeError(\"Can't detect the module name. please\
      \ provide by func args.\")\n    finally:\n        cls.__module__ = str(module)\n\
      \    assert issubclass(cls, JSONField)\n    return cls"
    code_lines: 83
    comment_lines: 0
    complexity: 13
    description: 生成会自动进行类型转换为 `py_model` 的 JSONField
    end_line: 148
    line: 66
    message: Complexity 13 exceeds threshold 10
    name: make_json_field
    severity: warning
    signature: 'def make_json_field ( cls_name: str, py_model: Type[M], decoder: Callable[[M],
      Dict] = cattr.unstructure, module: Optional[str] = None ) -> Type[JSONField]
      :'
  apiserver/paasng/paas_wl/workloads/networking/egress/management/commands/region_gen_state.py:
  - code: "\ndef handle(self, *args, **options):\n    all_regions = set(Cluster.objects.values_list('region',\
      \ flat=True))\n    if options['region']:\n        if options['region'] not in\
      \ all_regions:\n            print(f\"{options['region']} is not a valid region\
      \ name\")\n            sys.exit(1)\n        regions = [options['region']]\n\
      \    else:\n        regions = list(all_regions)\n    ignore_labels = options['ignore_labels']\n\
      \    ignore_labels = [value.split('=') for value in ignore_labels]\n    if any((len(label)\
      \ != 2 for label in ignore_labels)):\n        raise ValueError('Invalid label\
      \ given!')\n    if not options['include_masters']:\n        ignore_labels.append(('node-role.kubernetes.io/master',\
      \ 'true'))\n    cluster_name = options.get('cluster_name')\n    for region in\
      \ regions:\n        logger.debug(f'Make scheduler client from region: {region}')\n\
      \        for cluster in Cluster.objects.filter(region=region):\n           \
      \ if cluster_name and cluster.name != cluster_name:\n                continue\n\
      \            logger.info(f'Will generate state for [{region}/{cluster.name}]...')\n\
      \            if not options.get('no_input') and input('Confirm? (y/n, default:\
      \ n) ').lower() != 'y':\n                continue\n            try:\n      \
      \          client = get_client_by_cluster_name(cluster_name=cluster.name)\n\
      \                logger.info(f'Generating state for [{region} - {cluster.name}]...')\n\
      \                state = generate_state(region, cluster.name, client, ignore_labels=ignore_labels)\n\
      \                logger.info('Syncing the state to nodes...')\n            \
      \    sync_state_to_nodes(client, state)\n            except Exception:\n   \
      \             logger.exception('Unable to generate state')\n               \
      \ continue"
    code_lines: 42
    comment_lines: 0
    complexity: 12
    description: ''
    end_line: 123
    line: 82
    message: Complexity 12 exceeds threshold 10
    name: handle
    severity: warning
    signature: 'def handle ( self, *args, **options ) :'
  apiserver/paasng/paas_wl/workloads/networking/ingress/kres_slzs/ingress.py:
  - code: "\ndef serialize(self, obj: 'ProcessIngress', original_obj: Optional[ResourceInstance]\
      \ = None, **kwargs) -> Dict:\n    \"\"\"serialize obj into Ingress(networking.k8s.io/v1beta1)\"\
      \"\"\n    nginx_adaptor = IngressNginxAdaptor(get_cluster_by_app(obj.app))\n\
      \    annotations = {constants.ANNOT_SERVER_SNIPPET: obj.server_snippet, constants.ANNOT_CONFIGURATION_SNIPPET:\
      \ obj.configuration_snippet, constants.ANNOT_SSL_REDIRECT: 'false', constants.ANNOT_SKIP_FILTER_CLB:\
      \ 'true', **obj.annotations}\n    if obj.rewrite_to_root:\n        annotations[constants.ANNOT_REWRITE_TARGET]\
      \ = nginx_adaptor.build_rewrite_target()\n    if obj.set_header_x_script_name:\n\
      \        annotations[constants.ANNOT_CONFIGURATION_SNIPPET] = ConfigurationSnippetPatcher().patch(obj.configuration_snippet,\
      \ nginx_adaptor.make_configuration_snippet(fallback_script_name=obj.domains[0].primary_prefix_path)).configuration_snippet\n\
      \    tls_group_by_secret_name: Dict[str, List] = defaultdict(list)\n    for\
      \ domain in obj.domains:\n        if domain.tls_enabled:\n            tls_group_by_secret_name[domain.tls_secret_name].append(domain.host)\n\
      \    tls = []\n    for (secret_name, hosts) in tls_group_by_secret_name.items():\n\
      \        tls.append({'hosts': hosts, 'secretName': secret_name})\n    rules\
      \ = []\n    for domain in obj.domains:\n        paths = []\n        for path_str\
      \ in domain.path_prefix_list:\n            paths.append({'path': nginx_adaptor.build_http_path(path_str\
      \ or '/') if obj.rewrite_to_root else path_str, 'backend': {'serviceName': obj.service_name,\
      \ 'servicePort': obj.service_port_name}})\n        rules.append({'host': domain.host,\
      \ 'http': {'paths': paths}})\n    body: Dict[str, Any] = {'metadata': {'name':\
      \ obj.name, 'namespace': obj.app.namespace, 'annotations': annotations}, 'spec':\
      \ {'rules': rules, 'tls': tls}, 'apiVersion': self.get_api_version_from_gvk(self.gvk_config),\
      \ 'kind': 'Ingress'}\n    if original_obj:\n        body['metadata']['resourceVersion']\
      \ = original_obj.metadata.resourceVersion\n    return body"
    code_lines: 58
    comment_lines: 0
    complexity: 10
    description: serialize obj into Ingress(networking.k8s.io/v1beta1)
    end_line: 112
    line: 55
    message: Complexity 10 exceeds threshold 10
    name: serialize
    severity: acceptable
    signature: 'def serialize ( self, obj: ''ProcessIngress'', original_obj: Optional[ResourceInstance]
      = None, **kwargs ) -> Dict :'
  - code: "\ndef serialize(self, obj: 'ProcessIngress', original_obj: Optional[ResourceInstance]\
      \ = None, **kwargs) -> Dict:\n    \"\"\"serialize obj into Ingress(networking.k8s.io/v1)\"\
      \"\"\n    nginx_adaptor = NginxRegexRewrittenProvider()\n    annotations = {constants.ANNOT_SERVER_SNIPPET:\
      \ obj.server_snippet, constants.ANNOT_CONFIGURATION_SNIPPET: obj.configuration_snippet,\
      \ constants.ANNOT_SSL_REDIRECT: 'false', constants.ANNOT_SKIP_FILTER_CLB: 'true',\
      \ **obj.annotations}\n    if obj.rewrite_to_root:\n        annotations[constants.ANNOT_REWRITE_TARGET]\
      \ = nginx_adaptor.make_rewrite_target()\n    if obj.set_header_x_script_name:\n\
      \        annotations[constants.ANNOT_CONFIGURATION_SNIPPET] = ConfigurationSnippetPatcher().patch(obj.configuration_snippet,\
      \ nginx_adaptor.make_configuration_snippet()).configuration_snippet\n    tls_group_by_secret_name:\
      \ Dict[str, List] = defaultdict(list)\n    for domain in obj.domains:\n    \
      \    if domain.tls_enabled:\n            tls_group_by_secret_name[domain.tls_secret_name].append(domain.host)\n\
      \    tls = []\n    for (secret_name, hosts) in tls_group_by_secret_name.items():\n\
      \        tls.append({'hosts': hosts, 'secretName': secret_name})\n    rules\
      \ = []\n    for domain in obj.domains:\n        paths = []\n        for path_str\
      \ in domain.path_prefix_list:\n            paths.append({'path': nginx_adaptor.make_location_path(path_str\
      \ or '/') if obj.rewrite_to_root else path_str, 'pathType': 'ImplementationSpecific',\
      \ 'backend': {'service': {'name': obj.service_name, 'port': {'name': obj.service_port_name}}}})\n\
      \        rules.append({'host': domain.host, 'http': {'paths': paths}})\n   \
      \ body: Dict[str, Any] = {'metadata': {'name': obj.name, 'namespace': obj.app.namespace,\
      \ 'annotations': annotations}, 'spec': {'rules': rules, 'tls': tls}, 'apiVersion':\
      \ self.get_api_version_from_gvk(self.gvk_config), 'kind': 'Ingress'}\n    if\
      \ original_obj:\n        body['metadata']['resourceVersion'] = original_obj.metadata.resourceVersion\n\
      \    return body"
    code_lines: 61
    comment_lines: 0
    complexity: 10
    description: serialize obj into Ingress(networking.k8s.io/v1)
    end_line: 274
    line: 214
    message: Complexity 10 exceeds threshold 10
    name: serialize
    severity: acceptable
    signature: 'def serialize ( self, obj: ''ProcessIngress'', original_obj: Optional[ResourceInstance]
      = None, **kwargs ) -> Dict :'
  apiserver/paasng/paasng/accessories/log/filters.py:
  - code: "\ndef count_filters_options_from_logs(logs: List, properties: Dict[str,\
      \ FieldFilter]) -> Dict[str, FieldFilter]:\n    \"\"\"从日志样本(logs) 中统计 ES 日志的字段分布,\
      \ 返回对应的 FieldFilters. 会忽略无可选 options 的 filters\n\n    :param logs: 日志样本\n  \
      \  :param properties: 需要统计的ES 字段\n    \"\"\"\n    field_counter: Dict[str, Counter]\
      \ = defaultdict(Counter)\n    log_fields = [(f, f.split('.')) for f in properties]\n\
      \    for log in logs:\n        for (log_field, split_log_field) in log_fields:\n\
      \            try:\n                value = get_attribute(log, split_log_field)\n\
      \            except (AttributeError, KeyError):\n                continue\n\
      \            try:\n                field_counter[log_field][value] += 1\n  \
      \          except TypeError:\n                logger.warning('Field<%s> got\
      \ an unhashable value: %s', log_field, value)\n    result = {}\n    for (title,\
      \ values) in field_counter.items():\n        f = properties[title]\n       \
      \ options = dict(f.options)\n        total = sum(values.values())\n        if\
      \ total == 0 and len(options) == 0:\n            continue\n        for (value,\
      \ count) in values.items():\n            if value not in options:\n        \
      \        percentage = calculate_percentage(count, total)\n                options[value]\
      \ = percentage\n        result[title] = FieldFilter(name=f.name, key=f.key,\
      \ options=list(options.items()), total=total)\n    return result"
    code_lines: 40
    comment_lines: 0
    complexity: 10
    description: 从日志样本(logs) 中统计 ES 日志的字段分布, 返回对应的 FieldFilters. 会忽略无可选 options 的
      filters
    end_line: 143
    line: 104
    message: Complexity 10 exceeds threshold 10
    name: count_filters_options_from_logs
    severity: acceptable
    signature: 'def count_filters_options_from_logs ( logs: List, properties: Dict[str,
      FieldFilter] ) -> Dict[str, FieldFilter] :'
  apiserver/paasng/paasng/accessories/log/management/commands/batch_disable_mount_hostpath.py:
  - code: "\ndef handle(self, app_code, region, cluster_name, all_clusters, edge_disable,\
      \ dry_run, *args, **options):\n    style_func = self.style.SUCCESS if not dry_run\
      \ else self.style.NOTICE\n    qs = self.validate_params(app_code, region, cluster_name,\
      \ all_clusters)\n    for application in qs:\n        can_use_bklog = True\n\
      \        pending_latest_config = []\n        for module in application.modules.all():\n\
      \            for env in module.envs.all():\n                env_can_use_bklog\
      \ = self.check_env_status(env)\n                if env_can_use_bklog:\n    \
      \                if not dry_run:\n                        wl_app = env.wl_app\n\
      \                        latest_config = wl_app.latest_config\n            \
      \            latest_config.mount_log_to_host = False\n                     \
      \   if edge_disable:\n                            latest_config.save(update_fields=['mount_log_to_host',\
      \ 'updated'])\n                        else:\n                            pending_latest_config.append(latest_config)\n\
      \                    self.stdout.write(f'disable hostpath log collector for\
      \ Application<{application.code}> Module<{module.name}>Env<{env.environment}>',\
      \ style_func=style_func)\n                can_use_bklog = can_use_bklog and\
      \ env_can_use_bklog\n        if can_use_bklog:\n            if not dry_run:\n\
      \                application.feature_flag.set_feature(AppFeatureFlagConst.ENABLE_BK_LOG_COLLECTOR,\
      \ True)\n                for cfg in pending_latest_config:\n               \
      \     cfg.save(update_fields=['mount_log_to_host', 'updated'])\n           \
      \ self.stdout.write(f'switch log query to bk-log index for Application<{application.code}>',\
      \ style_func=style_func)"
    code_lines: 40
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 105
    line: 66
    message: Complexity 11 exceeds threshold 10
    name: handle
    severity: warning
    signature: 'def handle ( self, app_code, region, cluster_name, all_clusters, edge_disable,
      dry_run, *args, **options ) :'
  apiserver/paasng/paasng/accessories/servicehub/management/commands/update_legacy_rabbitmq.py:
  - code: "\ndef handle(self, name, region, id, dry_run, *args, **options):\n    services\
      \ = models.Service.objects.all()\n    if name:\n        services = services.filter(name=name)\n\
      \    if region:\n        services = services.filter(region=region)\n    if id:\n\
      \        services = services.filter(pk=id)\n    service = services.get()\n \
      \   for i in models.ServiceInstance.objects.filter(service=service):\n     \
      \   if not i.credentials:\n            print(f'credentials of instance {i.pk}\
      \ is None')\n            continue\n        credentials = json.loads(i.credentials)\n\
      \        if not credentials:\n            print(f'credentials of instance {i.pk}\
      \ is empty')\n            continue\n        to_update = {}\n        prefix =\
      \ 'LEGACY_'\n        for (k, v) in credentials.items():\n            if not\
      \ k.startswith(prefix):\n                to_update[f'{prefix}{k}'] = v\n   \
      \     if not to_update:\n            continue\n        print(f'updating instance\
      \ {i.pk}')\n        credentials.update(to_update)\n        if not dry_run:\n\
      \            i.credentials = json.dumps(credentials)\n            i.save(update_fields=['credentials'])"
    code_lines: 40
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 76
    line: 37
    message: Complexity 11 exceeds threshold 10
    name: handle
    severity: warning
    signature: 'def handle ( self, name, region, id, dry_run, *args, **options ) :'
  apiserver/paasng/paasng/accessories/services/providers/sentry/client.py:
  - code: "\ndef _request(self, method, path, data, timeout=10):\n    url = '{base_url}{path}'.format(base_url=self.base_url,\
      \ path=path)\n    headers = self.headers\n    try:\n        if method == 'GET':\n\
      \            resp = requests.get(url=url, headers=headers, params=data, timeout=timeout)\n\
      \        elif method == 'HEAD':\n            resp = requests.head(url=url, headers=headers,\
      \ timeout=timeout)\n        elif method == 'POST':\n            resp = requests.post(url=url,\
      \ headers=headers, json=data, timeout=timeout)\n        elif method == 'DELETE':\n\
      \            resp = requests.delete(url=url, headers=headers, json=data)\n \
      \       elif method == 'PUT':\n            resp = requests.put(url=url, headers=headers,\
      \ json=data)\n        else:\n            return False, None\n    except requests.exceptions.RequestException:\n\
      \        logger.exception('Request sentry failed, connection exception')\n \
      \       raise RequestSentryAPIFail('Request sentry failed, connection exception')\n\
      \    resp_json = {}\n    try:\n        if resp.status_code != 204:\n       \
      \     resp_json = resp.json()\n    except Exception:\n        logger.exception('Failed\
      \ to request sentry, failed to parse json')\n    if resp.status_code not in\
      \ (200, 201, 202, 204, 409):\n        logger.exception('Request sentry failed,\
      \ return status is not 20X/409[method=%s, url=%s, data=%s, status=%s, resp=%s]',\
      \ method, url, data, resp.status_code, resp_json)\n        return False, resp_json\n\
      \    return True, resp_json"
    code_lines: 40
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 73
    line: 34
    message: Complexity 10 exceeds threshold 10
    name: _request
    severity: acceptable
    signature: 'def _request ( self, method, path, data, timeout = 10 ) :'
  apiserver/paasng/paasng/accessories/smart_advisor/tagging.py:
  - code: "\ndef dig_tags_local_repo(local_path: str | PathLike):\n    \"\"\"Dig a\
      \ local repo to find proper tags for this module\"\"\"\n    p = Path(local_path)\n\
      \    if not p.exists():\n        return []\n    tags = []\n    req_file = p\
      \ / 'requirements.txt'\n    if req_file.exists() and not req_file.is_symlink():\n\
      \        tags.append(force_tag('app-pl:python'))\n        requirements_txt =\
      \ req_file.read_text(encoding='utf-8', errors='ignore')\n        for pkg_name\
      \ in ('celery', 'django', 'gunicorn', 'blueapps'):\n            if py_module_in_requirements(pkg_name,\
      \ requirements_txt):\n                tags.append(force_tag('app-sdk:{}'.format(pkg_name)))\n\
      \    for fname in p.iterdir():\n        if fname.name.endswith('.go'):\n   \
      \         tags.append(force_tag('app-pl:go'))\n            break\n        if\
      \ fname.name.endswith('.php'):\n            tags.append(force_tag('app-pl:php'))\n\
      \            break\n    if (p / 'package.json').exists() and (p / 'index.js').exists():\n\
      \        tags.append(force_tag('app-pl:nodejs'))\n    return tags"
    code_lines: 33
    comment_lines: 0
    complexity: 11
    description: Dig a local repo to find proper tags for this module
    end_line: 68
    line: 36
    message: Complexity 11 exceeds threshold 10
    name: dig_tags_local_repo
    severity: warning
    signature: 'def dig_tags_local_repo ( local_path: str | PathLike ) :'
  apiserver/paasng/paasng/bk_plugins/pluginscenter/releases/executor.py:
  - code: "\ndef back_to_previous_stage(self, operator: str):\n    \"\"\"回滚当前发布阶段至上一阶段:\
      \ 重置 release.current_stage, 并将 release.current_stage 设置成 previous_stage\n  \
      \      ITSM 单据审批中不能返回上一步\n        \"\"\"\n    if self.release.status == constants.PluginReleaseStatus.SUCCESSFUL:\n\
      \        raise error_codes.CANNOT_ROLLBACK_CURRENT_STEP.f(_('当前发布流程已结束'))\n\
      \    if not self.release.retryable:\n        raise error_codes.CANNOT_ROLLBACK_CURRENT_STEP.f(_('当前插件类型不支持重置历史版本,\
      \ 如需发布请创建新的版本'))\n    current_stage = self.release.current_stage\n    if current_stage.invoke_method\
      \ == constants.ReleaseStageInvokeMethod.ITSM and current_stage.status in constants.PluginReleaseStatus.running_status():\n\
      \        raise error_codes.CANNOT_ROLLBACK_CURRENT_STEP.f(_('请先撤回审批单据, 再返回上一步'))\n\
      \    if current_stage.invoke_method == constants.ReleaseStageInvokeMethod.DEPLOY_API\
      \ and current_stage.status in constants.PluginReleaseStatus.running_status():\n\
      \        raise error_codes.CANNOT_ROLLBACK_CURRENT_STEP.f(_('请等待部署完成, 再返回上一步'))\n\
      \    previous_stage_id = None\n    for stage in self.release.stages_shortcut:\n\
      \        if stage.id == current_stage.stage_id:\n            break\n       \
      \ previous_stage_id = stage.id\n    if previous_stage_id is None:\n        raise\
      \ error_codes.CANNOT_ROLLBACK_CURRENT_STEP\n    previous_stage = self.release.all_stages.get(stage_id=previous_stage_id)\n\
      \    current_stage.reset()\n    self.release.current_stage = previous_stage\n\
      \    self.release.status = constants.PluginReleaseStatus.PENDING\n    self.release.save()"
    code_lines: 37
    comment_lines: 0
    complexity: 10
    description: '回滚当前发布阶段至上一阶段: 重置 release.current_stage, 并将 release.current_stage
      设置成 previous_stage'
    end_line: 157
    line: 121
    message: Complexity 10 exceeds threshold 10
    name: back_to_previous_stage
    severity: acceptable
    signature: 'def back_to_previous_stage ( self, operator: str ) :'
  apiserver/paasng/paasng/bk_plugins/pluginscenter/serializers.py:
  - code: "\ndef make_release_validator(plugin: PluginInstance, version_rule: PluginReleaseVersionRule,\
      \ release_type: str, revision_policy: str, revision_type: str):\n    \"\"\"\
      make a validator to validate ReleaseVersion object\"\"\"\n    \n    def validate_semver(version:\
      \ str, previous_version_str: Optional[str], semver_type: SemverAutomaticType):\n\
      \        try:\n            parsed_version = semver.VersionInfo.parse(version)\n\
      \            previous_version = semver.VersionInfo.parse(previous_version_str\
      \ or '0.0.0')\n        except ValueError as e:\n            raise ValidationError(str(e))\n\
      \        if semver_type == SemverAutomaticType.MAJOR:\n            computational_revision\
      \ = previous_version.bump_major()\n        elif semver_type == SemverAutomaticType.MINOR:\n\
      \            computational_revision = previous_version.bump_minor()\n      \
      \  else:\n            computational_revision = previous_version.bump_patch()\n\
      \        if computational_revision != parsed_version:\n            raise ValidationError({'revision':\
      \ _('版本号不符合，下一个 {label} 版本是 {revision}').format(label=SemverAutomaticType.get_choice_label(semver_type),\
      \ revision=computational_revision)})\n        return True\n    \n    def validate_release_policy(plugin:\
      \ PluginInstance, release_type: str, revision_policy: str, source_version_name:\
      \ str):\n        \"\"\"Plugin version release rules, e.g., cannot release already\
      \ published versions.\"\"\"\n        policy = REVISION_POLICIES.get(revision_policy)\n\
      \        if not policy:\n            return True\n        source_version_exists\
      \ = PluginRelease.objects.filter(plugin=plugin, source_version_name=source_version_name,\
      \ type=release_type, **policy['filter']).exists()\n        if source_version_exists:\n\
      \            raise policy['error']\n        return True\n    \n    def validator(self,\
      \ attrs: Dict):\n        if revision_type == PluginRevisionType.TESTED_VERSION\
      \ and not attrs['release_id']:\n            raise ValidationError(_('使用测试版本发布时必须传参数:\
      \ release_id'))\n        version = attrs['version']\n        source_version_type\
      \ = attrs['source_version_type']\n        source_version_name = attrs['source_version_name']\n\
      \        source_hash = get_source_hash_by_plugin_version(plugin, source_version_type,\
      \ source_version_name, revision_type, attrs['release_id'])\n        if version_rule\
      \ == PluginReleaseVersionRule.AUTOMATIC:\n            validate_semver(version,\
      \ self.context['previous_version'], SemverAutomaticType(attrs['semver_type']))\n\
      \        elif version_rule == PluginReleaseVersionRule.REVISION and version\
      \ != source_version_name:\n            raise ValidationError(_('版本号必须与代码分支一致'))\n\
      \        elif version_rule == PluginReleaseVersionRule.COMMIT_HASH and version\
      \ != source_hash:\n            raise ValidationError(_('版本号必须与提交哈希一致'))\n  \
      \      elif version_rule == PluginReleaseVersionRule.BRANCH_TIMESTAMP and not\
      \ version.startswith(source_version_name):\n            raise ValidationError(_('版本号必须以代码分支开头'))\n\
      \        if revision_policy:\n            validate_release_policy(plugin, release_type,\
      \ revision_policy, source_version_name)\n        attrs['source_hash'] = source_hash\n\
      \        attrs.pop('release_id')\n        return attrs\n    return validator"
    code_lines: 75
    comment_lines: 0
    complexity: 17
    description: make a validator to validate ReleaseVersion object
    end_line: 554
    line: 480
    message: Complexity 17 exceeds threshold 10
    name: make_release_validator
    severity: high_risk
    signature: 'def make_release_validator ( plugin: PluginInstance, version_rule:
      PluginReleaseVersionRule, release_type: str, revision_policy: str, revision_type:
      str ) :'
  - code: "\ndef validator(self, attrs: Dict):\n    if revision_type == PluginRevisionType.TESTED_VERSION\
      \ and not attrs['release_id']:\n        raise ValidationError(_('使用测试版本发布时必须传参数:\
      \ release_id'))\n    version = attrs['version']\n    source_version_type = attrs['source_version_type']\n\
      \    source_version_name = attrs['source_version_name']\n    source_hash = get_source_hash_by_plugin_version(plugin,\
      \ source_version_type, source_version_name, revision_type, attrs['release_id'])\n\
      \    if version_rule == PluginReleaseVersionRule.AUTOMATIC:\n        validate_semver(version,\
      \ self.context['previous_version'], SemverAutomaticType(attrs['semver_type']))\n\
      \    elif version_rule == PluginReleaseVersionRule.REVISION and version != source_version_name:\n\
      \        raise ValidationError(_('版本号必须与代码分支一致'))\n    elif version_rule ==\
      \ PluginReleaseVersionRule.COMMIT_HASH and version != source_hash:\n       \
      \ raise ValidationError(_('版本号必须与提交哈希一致'))\n    elif version_rule == PluginReleaseVersionRule.BRANCH_TIMESTAMP\
      \ and not version.startswith(source_version_name):\n        raise ValidationError(_('版本号必须以代码分支开头'))\n\
      \    if revision_policy:\n        validate_release_policy(plugin, release_type,\
      \ revision_policy, source_version_name)\n    attrs['source_hash'] = source_hash\n\
      \    attrs.pop('release_id')\n    return attrs"
    code_lines: 27
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 552
    line: 526
    message: Complexity 11 exceeds threshold 10
    name: validator
    severity: warning
    signature: 'def validator ( self, attrs: Dict ) :'
  apiserver/paasng/paasng/infras/accounts/permissions/global_site.py:
  - code: "\ndef gen_site_role_perm_map(role: SiteRole) -> Dict[SiteAction, bool]:\n\
      \    \"\"\"根据不同的用户角色，生成对应的权限映射表\"\"\"\n    perm_map = {SiteAction.VISIT_SITE:\
      \ True, SiteAction.VISIT_ADMIN42: False, SiteAction.SYSAPI_READ_APPLICATIONS:\
      \ False, SiteAction.SYSAPI_MANAGE_APPLICATIONS: False, SiteAction.SYSAPI_READ_SERVICES:\
      \ False, SiteAction.SYSAPI_MANAGE_ACCESS_CONTROL: False, SiteAction.SYSAPI_MANAGE_LIGHT_APPLICATIONS:\
      \ False, SiteAction.SYSAPI_READ_DB_CREDENTIAL: False, SiteAction.SYSAPI_BIND_DB_SERVICE:\
      \ False, SiteAction.MANAGE_PLATFORM: False, SiteAction.MANAGE_APP_TEMPLATES:\
      \ False, SiteAction.OPERATE_PLATFORM: False}\n    if role == SiteRole.BANNED_USER:\n\
      \        perm_map[SiteAction.VISIT_SITE] = False\n    elif role in [SiteRole.ADMIN,\
      \ SiteRole.SUPER_USER]:\n        perm_map[SiteAction.VISIT_ADMIN42] = True\n\
      \        perm_map[SiteAction.MANAGE_PLATFORM] = True\n        perm_map[SiteAction.MANAGE_APP_TEMPLATES]\
      \ = True\n        perm_map[SiteAction.OPERATE_PLATFORM] = True\n    elif role\
      \ == SiteRole.PLATFORM_MANAGER:\n        perm_map[SiteAction.VISIT_ADMIN42]\
      \ = True\n        perm_map[SiteAction.MANAGE_PLATFORM] = True\n    elif role\
      \ == SiteRole.APP_TEMPLATES_MANAGER:\n        perm_map[SiteAction.VISIT_ADMIN42]\
      \ = True\n        perm_map[SiteAction.MANAGE_APP_TEMPLATES] = True\n    elif\
      \ role == SiteRole.PLATFORM_OPERATOR:\n        perm_map[SiteAction.VISIT_ADMIN42]\
      \ = True\n        perm_map[SiteAction.OPERATE_PLATFORM] = True\n    elif role\
      \ == SiteRole.SYSTEM_API_BASIC_READER:\n        perm_map[SiteAction.SYSAPI_READ_APPLICATIONS]\
      \ = True\n        perm_map[SiteAction.SYSAPI_READ_SERVICES] = True\n    elif\
      \ role == SiteRole.SYSTEM_API_BASIC_MAINTAINER:\n        perm_map[SiteAction.SYSAPI_READ_APPLICATIONS]\
      \ = True\n        perm_map[SiteAction.SYSAPI_MANAGE_APPLICATIONS] = True\n \
      \       perm_map[SiteAction.SYSAPI_READ_SERVICES] = True\n        perm_map[SiteAction.SYSAPI_MANAGE_ACCESS_CONTROL]\
      \ = True\n    elif role == SiteRole.SYSTEM_API_LIGHT_APP_MAINTAINER:\n     \
      \   perm_map[SiteAction.SYSAPI_READ_APPLICATIONS] = True\n        perm_map[SiteAction.SYSAPI_READ_SERVICES]\
      \ = True\n        perm_map[SiteAction.SYSAPI_MANAGE_LIGHT_APPLICATIONS] = True\n\
      \    elif role == SiteRole.SYSTEM_API_LESSCODE:\n        perm_map[SiteAction.SYSAPI_READ_APPLICATIONS]\
      \ = True\n        perm_map[SiteAction.SYSAPI_MANAGE_APPLICATIONS] = True\n \
      \       perm_map[SiteAction.SYSAPI_READ_SERVICES] = True\n        perm_map[SiteAction.SYSAPI_READ_DB_CREDENTIAL]\
      \ = True\n        perm_map[SiteAction.SYSAPI_BIND_DB_SERVICE] = True\n    return\
      \ perm_map"
    code_lines: 62
    comment_lines: 0
    complexity: 10
    description: 根据不同的用户角色，生成对应的权限映射表
    end_line: 123
    line: 62
    message: Complexity 10 exceeds threshold 10
    name: gen_site_role_perm_map
    severity: acceptable
    signature: 'def gen_site_role_perm_map ( role: SiteRole ) -> Dict[SiteAction,
      bool] :'
  apiserver/paasng/paasng/infras/iam/members/management/commands/migrate_bkpaas3_perm.py:
  - code: "\ndef _migrate_single(self, idx: int, app: Dict) -> List:\n    \"\"\"迁移单个应用权限数据\"\
      \"\"\n    (app_code, app_name, creator) = (app['code'], app['name'], app['creator'])\n\
      \    migrate_logs = []\n    administrator_key = (app_code, ApplicationRole.ADMINISTRATOR)\n\
      \    developer_key = (app_code, ApplicationRole.DEVELOPER)\n    operator_key\
      \ = (app_code, ApplicationRole.OPERATOR)\n    all_role_keys = [administrator_key,\
      \ developer_key, operator_key]\n    migrate_logs.append(f'start migrate application\
      \ [{app_name}/{app_code}] user roles... {idx}/{self.total_count}')\n    administrators\
      \ = self.members_map[administrator_key]\n    if not administrators:\n      \
      \  raise ValueError(\"application hasn't administrators\")\n    first_grade_manager\
      \ = creator\n    if creator not in administrators:\n        first_grade_manager\
      \ = administrators[0]\n        migrate_logs.append(f\"creator not app's administrators,\
      \ use first administrator {first_grade_manager}\")\n    grade_manager_id = self.grade_manager_map.get(app_code)\n\
      \    if not grade_manager_id:\n        migrate_logs.append('grade manager not\
      \ exists, create...')\n        if first_grade_manager in self.exclude_users:\n\
      \            first_grade_manager = None\n            migrate_logs.append(f'{first_grade_manager}\
      \ in exclude users, skip add as members...')\n        else:\n            migrate_logs.append(f'add\
      \ {first_grade_manager} as grade manager members...')\n        grade_manager_id\
      \ = self.cli.create_grade_managers(app_code, app_name, first_grade_manager)\n\
      \        self.grade_manager_map[app_code] = grade_manager_id\n        ApplicationGradeManager.objects.create(app_code=app_code,\
      \ grade_manager_id=grade_manager_id)\n    migrate_logs.append(f'add grade manager\
      \ (id: {grade_manager_id}) members: count: {len(administrators)}, users: {administrators}')\n\
      \    for username in administrators:\n        if username in self.exclude_users:\n\
      \            migrate_logs.append(f'user {username} in exclude user list, skip\
      \ add as grade manager')\n            continue\n        try:\n            self.cli.add_grade_manager_members(grade_manager_id,\
      \ [username])\n        except Exception as e:\n            migrate_logs.append(f'failed\
      \ to add grade manager: {username}, maybe was resigned: {str(e)}')\n    exists_user_group_ids\
      \ = [self.user_group_map[role_key] for role_key in all_role_keys if role_key\
      \ in self.user_group_map]\n    if len(exists_user_group_ids) < len(all_role_keys):\n\
      \        if exists_user_group_ids:\n            migrate_logs.append(f'user groups\
      \ {exists_user_group_ids} exists, clean them and recreate...')\n           \
      \ self.cli.delete_user_groups(exists_user_group_ids)\n            ApplicationUserGroup.objects.filter(app_code=app_code).delete()\n\
      \        groups = self.cli.create_builtin_user_groups(grade_manager_id, app_code)\n\
      \        for group in groups:\n            (role, group_id, group_name) = (group['role'],\
      \ group['id'], group['name'])\n            migrate_logs.append(f'create user\
      \ group id: {group_id}, role: {ApplicationRole(role).name}, name: {group_name}')\n\
      \            self.user_group_map[app_code, role] = group_id\n            ApplicationUserGroup.objects.create(app_code=app_code,\
      \ role=role, user_group_id=group_id)\n        self.cli.grant_user_group_policies(app_code,\
      \ app_name, groups)\n    user_group_id = self.user_group_map[administrator_key]\n\
      \    migrate_logs.append(f'try add user_group (id: {user_group_id}, role: {ApplicationRole.ADMINISTRATOR.name})\
      \ members...count: {len(administrators)}, users: {administrators}')\n    for\
      \ username in administrators:\n        try:\n            self.cli.add_user_group_members(user_group_id,\
      \ [username], NEVER_EXPIRE_DAYS)\n        except Exception as e:\n         \
      \   migrate_logs.append(f'failed to add app administrator: {username}, maybe\
      \ was resigned: {str(e)}')\n    if developers := self.members_map[developer_key]:\n\
      \        user_group_id = self.user_group_map[developer_key]\n        migrate_logs.append(f'try\
      \ add user_group (id: {user_group_id}, role: {ApplicationRole.DEVELOPER.name})\
      \ members...count: {len(developers)}, users: {developers}')\n        for username\
      \ in developers:\n            try:\n                self.cli.add_user_group_members(user_group_id,\
      \ [username], NEVER_EXPIRE_DAYS)\n            except Exception as e:\n     \
      \           migrate_logs.append(f'failed to add app developer: {username}, maybe\
      \ was resigned: {str(e)}')\n    if operators := self.members_map[operator_key]:\n\
      \        user_group_id = self.user_group_map[operator_key]\n        migrate_logs.append(f'try\
      \ add user_group (id: {user_group_id}, role: {ApplicationRole.OPERATOR.name})\
      \ members...count: {len(operators)}, users: {operators}')\n        for username\
      \ in operators:\n            try:\n                self.cli.add_user_group_members(user_group_id,\
      \ [username], NEVER_EXPIRE_DAYS)\n            except Exception as e:\n     \
      \           migrate_logs.append(f'failed to add app operator: {username}, maybe\
      \ was resigned: {str(e)}')\n    migrate_logs.append(f'migrate application [{app_name}/{app_code}]\
      \ user role success! {idx}/{self.total_count}')\n    return migrate_logs"
    code_lines: 121
    comment_lines: 0
    complexity: 20
    description: 迁移单个应用权限数据
    end_line: 264
    line: 144
    message: Complexity 20 exceeds threshold 10
    name: _migrate_single
    severity: high_risk
    signature: 'def _migrate_single ( self, idx: int, app: Dict ) -> List :'
  apiserver/paasng/paasng/infras/perm_insure/views_perm.py:
  - code: "\ndef check_drf_view_perm(view_func, is_admin42: bool):\n    \"\"\"Check\
      \ if a DRF view function has configured permission properly.\n\n    :raise ImproperlyConfigured:\
      \ When the permission is not configured properly.\n    \"\"\"\n    view_cls\
      \ = view_func.cls\n    if view_cls.__name__ in INSURE_CHECKING_EXCLUDED_VIEWS:\n\
      \        return\n    if issubclass(view_cls, ViewSetMixin):\n        unprotected_actions\
      \ = get_unprotected_actions(view_func)\n        if view_func.actions and not\
      \ unprotected_actions:\n            return\n    elif issubclass(view_cls, APIView):\n\
      \        pass\n    else:\n        raise TypeError('not a valid DRF View')\n\
      \    enabled_perm = view_cls.permission_classes\n    if is_admin42:\n      \
      \  if not any((is_admin42_permission(p) for p in enabled_perm)):\n         \
      \   raise ImproperlyConfigured(f'The view class {view_cls} has no site_perm_class\
      \ configured in permission_classes')\n    if not enabled_perm or len(enabled_perm)\
      \ == 1 and enabled_perm[0].__name__ == 'IsAuthenticated':\n        name = view_cls\
      \ if not unprotected_actions else f'{view_cls} - {unprotected_actions!r}'\n\
      \        raise ImproperlyConfigured('The view class {} has no extra permission_classes\
      \ configured other than `IsAuthenticated`, this may be a bug and lead to a permission\
      \ leak error, add the view name to `perm_insure.conf.INSURE_CHECKING_EXCLUDED_VIEWS`\
      \ if this is intended.'.format(name))"
    code_lines: 38
    comment_lines: 0
    complexity: 12
    description: Check if a DRF view function has configured permission properly.
    end_line: 122
    line: 85
    message: Complexity 12 exceeds threshold 10
    name: check_drf_view_perm
    severity: warning
    signature: 'def check_drf_view_perm ( view_func, is_admin42: bool ) :'
  apiserver/paasng/paasng/misc/audit/views.py:
  - code: "\ndef filter_queryset(self, queryset):\n    queryset = super().filter_queryset(queryset)\n\
      \    slz = AppOperationRecordFilterSlZ(data=self.request.query_params)\n   \
      \ slz.is_valid(raise_exception=True)\n    query_params = slz.validated_data\n\
      \    if target := query_params.get('target'):\n        queryset = queryset.filter(target=target)\n\
      \    if operation := query_params.get('operation'):\n        queryset = queryset.filter(operation=operation)\n\
      \    if access_type := query_params.get('access_type'):\n        queryset =\
      \ queryset.filter(access_type=access_type)\n    if 'result_code' in query_params:\n\
      \        result_code = query_params['result_code']\n        queryset = queryset.filter(result_code=result_code)\n\
      \    if module_name := query_params.get('module_name'):\n        queryset =\
      \ queryset.filter(module_name=module_name)\n    if environment := query_params.get('environment'):\n\
      \        queryset = queryset.filter(environment=environment)\n    if start_time\
      \ := query_params.get('start_time'):\n        queryset = queryset.filter(created__gte=start_time)\n\
      \    if end_time := query_params.get('end_time'):\n        queryset = queryset.filter(created__lte=end_time)\n\
      \    if operator := query_params.get('operator'):\n        operator = user_id_encoder.encode(settings.USER_TYPE,\
      \ operator)\n        queryset = queryset.filter(user=operator)\n    return queryset"
    code_lines: 28
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 77
    line: 50
    message: Complexity 10 exceeds threshold 10
    name: filter_queryset
    severity: acceptable
    signature: 'def filter_queryset ( self, queryset ) :'
  apiserver/paasng/paasng/plat_admin/numbers/app.py:
  - code: "\ndef get_results(self) -> Generator[SimpleApp, None, None]:\n    \"\"\"\
      Return simple apps as result\"\"\"\n    session = legacy_db.get_scoped_session()\n\
      \    qs = self.get_default_qs(session)\n    for app in qs.all():\n        deploy_status\
      \ = self.get_deploy_status(app)\n        normalizer = LegacyAppNormalizer(app)\n\
      \        region = normalizer.get_region()\n        if not region:\n        \
      \    continue\n        if app.code.startswith('collection_'):\n            continue\n\
      \        developers = normalizer.get_developers()\n        if self.filter_app_codes_enabled\
      \ and app.code not in self.filter_app_codes:\n            continue\n       \
      \ if self.filter_developers_enabled and not self.filter_developers_devs & set(developers):\n\
      \            continue\n        if hasattr(app, 'svn_domain'):\n            source_location\
      \ = f'svn://{app.svn_domain}:80/apps/{app.code}'\n        else:\n          \
      \  source_location = ''\n        market_address = market_tag = None\n      \
      \  if self.include_market_info:\n            market_address = self.get_market_address(region=region,\
      \ app_code=app.code)\n            market_tag = self.get_tag_display_name(app.tags_id)\n\
      \        sim_app = SimpleApp(_source=SimpleAppSource.LEGACY, name=app.name,\
      \ type='legacy', region=region, code=app.code, created=app.created_date, deploy_status=deploy_status,\
      \ source_origin=SourceOrigin.AUTHORIZED_VCS.value, source_repo_type='bk_svn',\
      \ source_location=source_location, engine_enabled=True, creator=normalizer.get_creator(),\
      \ developers=developers, market_address=market_address, market_tag=market_tag)\n\
      \        yield sim_app"
    code_lines: 49
    comment_lines: 0
    complexity: 10
    description: Return simple apps as result
    end_line: 401
    line: 353
    message: Complexity 10 exceeds threshold 10
    name: get_results
    severity: acceptable
    signature: 'def get_results ( self ) -> Generator[SimpleApp, None, None] :'
  apiserver/paasng/paasng/platform/applications/models.py:
  - code: "\n@classmethod\ndef filter_queryset(cls, queryset: QuerySet, include_inactive=False,\
      \ regions=None, languages=None, search_term='', has_deployed: Optional[bool]\
      \ = None, source_origin: Optional[SourceOrigin] = None, type_: Optional[ApplicationType]\
      \ = None, order_by: Optional[List] = None, market_enabled: Optional[bool] =\
      \ None):\n    \"\"\"Filter applications by given parameters\"\"\"\n    if order_by\
      \ is None:\n        order_by = []\n    if queryset.model is not Application:\n\
      \        raise ValueError('BaseApplicationFilter only support to filter Application')\n\
      \    if regions:\n        queryset = queryset.filter_by_regions(regions)\n \
      \   if languages:\n        queryset = queryset.filter_by_languages(languages)\n\
      \    if search_term:\n        queryset = queryset.search_by_code_or_name(search_term)\n\
      \    if has_deployed is not None:\n        queryset = queryset.filter(last_deployed_date__isnull=not\
      \ has_deployed)\n    if not include_inactive:\n        queryset = queryset.only_active()\n\
      \    if order_by:\n        queryset = cls.process_order_by(order_by, queryset)\n\
      \    if source_origin:\n        queryset = queryset.filter_by_source_origin(source_origin)\n\
      \    if market_enabled is not None:\n        queryset = queryset.filter(market_config__enabled=market_enabled)\n\
      \    if type_ is not None:\n        queryset = queryset.filter(type=type_)\n\
      \    return queryset"
    code_lines: 40
    comment_lines: 0
    complexity: 12
    description: Filter applications by given parameters
    end_line: 180
    line: 141
    message: Complexity 12 exceeds threshold 10
    name: filter_queryset
    severity: warning
    signature: 'def filter_queryset ( cls, queryset: QuerySet, include_inactive =
      False, regions = None, languages = None, search_term = '''', has_deployed: Optional[bool]
      = None, source_origin: Optional[SourceOrigin] = None, type_: Optional[ApplicationType]
      = None, order_by: Optional[List] = None, market_enabled: Optional[bool] = None
      ) :'
  apiserver/paasng/paasng/platform/bkapp_model/importer.py:
  - code: "\ndef import_bkapp_spec_entity(module: Module, spec_entity: v1alpha2_entity.BkAppSpec,\
      \ manager: FieldMgrName):\n    \"\"\"Import a BkApp spec entity to the current\
      \ module, will overwrite existing data.\n\n    :param module: The module object.\n\
      \    :param spec_entity: BkApp spec entity.\n    :param manager: The manager\
      \ performing this action.\n    \"\"\"\n    env_vars = []\n    mounts = spec_entity.mounts\
      \ or []\n    if configuration := spec_entity.configuration:\n        env_vars\
      \ = configuration.env or []\n    overlay_replicas: NotSetType | list = NOTSET\n\
      \    overlay_res_quotas: NotSetType | list = NOTSET\n    overlay_env_vars: NotSetType\
      \ | list = NOTSET\n    overlay_autoscaling: NotSetType | list = NOTSET\n   \
      \ overlay_mounts: NotSetType | list = NOTSET\n    if not isinstance(spec_entity.env_overlay,\
      \ NotSetType):\n        eo = spec_entity.env_overlay\n        if eo:\n     \
      \       overlay_replicas = [] if eo.replicas is None else eo.replicas\n    \
      \        overlay_res_quotas = [] if eo.res_quotas is None else eo.res_quotas\n\
      \            overlay_env_vars = [] if eo.env_variables is None else eo.env_variables\n\
      \            overlay_autoscaling = [] if eo.autoscaling is None else eo.autoscaling\n\
      \            overlay_mounts = [] if eo.mounts is None else eo.mounts\n    sync_processes(module,\
      \ processes=spec_entity.processes, manager=manager)\n    if build := spec_entity.build:\n\
      \        sync_build(module, build)\n    sync_hooks(module, spec_entity.hooks,\
      \ manager)\n    sync_env_vars(module, env_vars, overlay_env_vars)\n    if addons\
      \ := spec_entity.addons:\n        sync_addons(module, addons)\n    if mounts\
      \ or overlay_mounts:\n        sync_mounts(module, mounts, overlay_mounts, manager)\n\
      \    sync_svc_discovery(module, spec_entity.svc_discovery, manager)\n    sync_domain_resolution(module,\
      \ spec_entity.domain_resolution, manager)\n    sync_observability(module, spec_entity.observability)\n\
      \    sync_env_overlays_replicas(module, overlay_replicas, manager, spec_entity.processes)\n\
      \    sync_env_overlays_res_quotas(module, overlay_res_quotas, manager, spec_entity.processes)\n\
      \    sync_env_overlays_autoscalings(module, overlay_autoscaling, manager, spec_entity.processes)\n\
      \    clean_empty_overlays(module)"
    code_lines: 54
    comment_lines: 0
    complexity: 13
    description: Import a BkApp spec entity to the current module, will overwrite
      existing data.
    end_line: 124
    line: 71
    message: Complexity 13 exceeds threshold 10
    name: import_bkapp_spec_entity
    severity: warning
    signature: 'def import_bkapp_spec_entity ( module: Module, spec_entity: v1alpha2_entity.BkAppSpec,
      manager: FieldMgrName ) :'
  apiserver/paasng/paasng/platform/bkapp_model/manifest.py:
  - code: "\ndef apply_to_proc_overlay(self, model_res: crd.BkAppResource, module:\
      \ Module):\n    \"\"\"Apply changes to the sub-fields in the 'envOverlay' field\
      \ which is related\n        with process, fields list:\n\n        - replicas\n\
      \        - autoscaling\n        - resQuotas\n        \"\"\"\n    overlay = model_res.spec.envOverlay\n\
      \    if not overlay:\n        overlay = crd.EnvOverlay()\n    for proc_spec\
      \ in ModuleProcessSpec.objects.filter(module=module).order_by('created'):\n\
      \        for item in ProcessSpecEnvOverlay.objects.filter(proc_spec=proc_spec):\n\
      \            if item.target_replicas is not None and item.target_replicas !=\
      \ proc_spec.target_replicas:\n                overlay.append_item('replicas',\
      \ crd.ReplicasOverlay(envName=item.environment_name, process=proc_spec.name,\
      \ count=item.target_replicas))\n            if item.scaling_config and item.autoscaling\
      \ and item.scaling_config != proc_spec.scaling_config:\n                overlay.append_item('autoscaling',\
      \ crd.AutoscalingOverlay(envName=item.environment_name, process=proc_spec.name,\
      \ minReplicas=item.scaling_config.min_replicas, maxReplicas=item.scaling_config.max_replicas,\
      \ policy=item.scaling_config.policy))\n            if item.plan_name and item.plan_name\
      \ != proc_spec.plan_name:\n                overlay.append_item('resQuotas',\
      \ crd.ResQuotaOverlay(envName=item.environment_name, process=proc_spec.name,\
      \ plan=self.get_quota_plan(item.plan_name)))\n    model_res.spec.envOverlay\
      \ = overlay"
    code_lines: 44
    comment_lines: 0
    complexity: 11
    description: Apply changes to the sub-fields in the 'envOverlay' field which is
      related
    end_line: 247
    line: 204
    message: Complexity 11 exceeds threshold 10
    name: apply_to_proc_overlay
    severity: warning
    signature: 'def apply_to_proc_overlay ( self, model_res: crd.BkAppResource, module:
      Module ) :'
  apiserver/paasng/paasng/platform/declarative/application/validations/v2.py:
  - code: "\ndef to_internal_value(self, data: Dict) -> ApplicationDesc:\n    attrs\
      \ = super().to_internal_value(data)\n    attrs['name_en'] = attrs.get('name_en')\
      \ or attrs['name_zh_cn']\n    has_default = False\n    for module_desc in attrs['modules'].values():\n\
      \        if module_desc.is_default:\n            if has_default:\n         \
      \       raise serializers.ValidationError({'modules': _('一个应用只能有一个主模块')})\n\
      \            has_default = True\n    if not has_default:\n        raise serializers.ValidationError({'modules':\
      \ _('一个应用必须有一个主模块')})\n    for (module_name, module_desc) in attrs['modules'].items():\n\
      \        for svc in module_desc.services:\n            if svc.shared_from and\
      \ svc.shared_from not in attrs['modules']:\n                raise serializers.ValidationError({f'modules[{module_name}].services':\
      \ _('提供共享增强服务的模块不存在')})\n    attrs.setdefault('plugins', [])\n    if self.context.get('app_version'):\n\
      \        attrs['plugins'].append({'type': AppDescPluginType.APP_VERSION, 'data':\
      \ self.context.get('app_version')})\n    if self.context.get('spec_version'):\n\
      \        attrs['spec_version'] = self.context['spec_version']\n    return ApplicationDesc(instance_existed=bool(self.instance),\
      \ **attrs)"
    code_lines: 30
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 160
    line: 131
    message: Complexity 11 exceeds threshold 10
    name: to_internal_value
    severity: warning
    signature: 'def to_internal_value ( self, data: Dict ) -> ApplicationDesc :'
  apiserver/paasng/paasng/platform/declarative/application/validations/v3.py:
  - code: "\ndef to_internal_value(self, data: Dict) -> ApplicationDesc:\n    attrs\
      \ = super().to_internal_value(data)\n    attrs['name_en'] = attrs.get('name_en')\
      \ or attrs['name_zh_cn']\n    modules_list = attrs.pop('modules')\n    attrs['modules']\
      \ = {module_desc.name: module_desc for module_desc in modules_list}\n    has_default\
      \ = False\n    for module_desc in modules_list:\n        if module_desc.is_default:\n\
      \            if has_default:\n                raise serializers.ValidationError({'modules':\
      \ _('一个应用只能有一个主模块')})\n            has_default = True\n    if not has_default:\n\
      \        raise serializers.ValidationError({'modules': _('一个应用必须有一个主模块')})\n\
      \    for (idx, module_desc) in enumerate(modules_list):\n        for svc in\
      \ module_desc.services:\n            if svc.shared_from and svc.shared_from\
      \ not in attrs['modules']:\n                raise serializers.ValidationError({f'modules[{idx}].spec.addons':\
      \ _('提供共享增强服务的模块不存在')})\n    attrs.setdefault('plugins', [])\n    if self.context.get('app_version'):\n\
      \        attrs['plugins'].append({'type': AppDescPluginType.APP_VERSION, 'data':\
      \ self.context.get('app_version')})\n    if self.context.get('spec_version'):\n\
      \        attrs['spec_version'] = self.context['spec_version']\n    return ApplicationDesc(instance_existed=bool(self.instance),\
      \ **attrs)"
    code_lines: 34
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 155
    line: 122
    message: Complexity 11 exceeds threshold 10
    name: to_internal_value
    severity: warning
    signature: 'def to_internal_value ( self, data: Dict ) -> ApplicationDesc :'
  apiserver/paasng/paasng/platform/declarative/deployment/validations/v2.py:
  - code: "\ndef to_internal_value(self, data) -> DeploymentDesc:\n    attrs = super().to_internal_value(data)\n\
      \    processes = []\n    for (proc_type, process) in attrs['processes'].items():\n\
      \        processes.append({'name': proc_type, 'replicas': process['replicas'],\
      \ 'res_quota_plan': get_quota_plan(process['plan']) if process.get('plan') else\
      \ None, 'proc_command': process['command'], 'command': None, 'args': shlex.split(process['command']),\
      \ 'probes': process.get('probes')})\n    hooks: NotSetType | dict = NOTSET\n\
      \    if attrs['scripts'] and pre_release_hook := attrs['scripts'].get('pre_release_hook'):\n\
      \        hooks = {'pre_release': {'command': [], 'args': shlex.split(pre_release_hook)}}\n\
      \    global_vars = []\n    env_vars = []\n    for env_var in attrs.get('env_variables',\
      \ []):\n        if env_var['environment_name'] == ConfigVarEnvName.GLOBAL:\n\
      \            global_vars.append({'name': env_var['key'], 'value': env_var['value']})\n\
      \        else:\n            env_vars.append({'env_name': env_var['environment_name'],\
      \ 'name': env_var['key'], 'value': env_var['value']})\n    env_overlay: NotSetType\
      \ | dict\n    if not env_vars:\n        env_overlay = NOTSET\n    else:\n  \
      \      env_overlay = {'env_variables': env_vars}\n    _svc_discovery_value =\
      \ attrs.get('svc_discovery')\n    svc_discovery: NotSetType | dict[str, list[dict]]\n\
      \    if _svc_discovery_value == NOTSET:\n        svc_discovery = NOTSET\n  \
      \  else:\n        svc_discovery = {}\n        if bk_sass := _svc_discovery_value.get('bk_saas'):\n\
      \            svc_discovery['bk_saas'] = [{'bk_app_code': item['bk_app_code'],\
      \ 'module_name': item.get('module_name')} for item in bk_sass]\n    spec = v1alpha2.BkAppSpec(processes=processes,\
      \ hooks=hooks, configuration={'env': global_vars}, env_overlay=env_overlay,\
      \ svc_discovery=svc_discovery)\n    return cattr.structure({'language': attrs['language'],\
      \ 'source_dir': attrs['source_dir'], 'bk_monitor': attrs.get('bk_monitor', None),\
      \ 'spec_version': AppSpecVersion.VER_2, 'spec': spec}, DeploymentDesc)"
    code_lines: 74
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 153
    line: 80
    message: Complexity 10 exceeds threshold 10
    name: to_internal_value
    severity: acceptable
    signature: 'def to_internal_value ( self, data ) -> DeploymentDesc :'
  apiserver/paasng/paasng/platform/declarative/handlers.py:
  - code: "\ndef _find_module_desc_data(json_data: Dict, module_name: Optional[str],\
      \ modules_data_type: Literal['list', 'dict']) -> Dict:\n    \"\"\"Find a module's\
      \ desc data in the json data. This function can be used in both v2 and v3\n\
      \    because them have similar(but slightly different) structure.\n\n    In\
      \ the `json_data` 2 fields are used to store the module data:\n\n    - \"module\"\
      : contains desc data of the default module.\n    - \"modules\": contains desc\
      \ data of multiple modules, use a list(v3) or dict(v2) format.\n\n    :param\
      \ modules_data_type: The data type that holds the modules data, v2 using dict,\
      \ v3 using list.\n    \"\"\"\n    if not module_name:\n        desc_data = json_data.get('module')\n\
      \        if not desc_data:\n            raise DescriptionValidationError({'module':\
      \ _('模块配置内容不能为空')})\n        return desc_data\n    desc_data = None\n    if\
      \ modules_data := json_data.get('modules'):\n        if modules_data_type ==\
      \ 'dict':\n            desc_data = modules_data.get(module_name)\n         \
      \   existed_modules = ', '.join(modules_data.keys())\n        elif modules_data_type\
      \ == 'list':\n            desc_data = next((m for m in modules_data if m['name']\
      \ == module_name), None)\n            existed_modules = ', '.join((m['name']\
      \ for m in modules_data))\n        else:\n            raise ValueError('Wrong\
      \ modules data type')\n        desc_data = desc_data or json_data.get('module')\n\
      \        if not desc_data:\n            raise DescriptionValidationError({'modules':\
      \ _('未找到 {} 模块的配置，当前已配置模块为 {}').format(module_name, existed_modules)})\n   \
      \ if not desc_data:\n        desc_data = json_data.get('module')\n    if not\
      \ desc_data:\n        raise DescriptionValidationError({'module': _('模块配置内容不能为空')})\n\
      \    return desc_data"
    code_lines: 49
    comment_lines: 0
    complexity: 10
    description: Find a module's desc data in the json data. This function can be
      used in both v2 and v3
    end_line: 415
    line: 367
    message: Complexity 10 exceeds threshold 10
    name: _find_module_desc_data
    severity: acceptable
    signature: 'def _find_module_desc_data ( json_data: Dict, module_name: Optional[str],
      modules_data_type: Literal[''list'', ''dict''] ) -> Dict :'
  apiserver/paasng/paasng/platform/engine/deploy/bg_build/executors.py:
  - code: "\ndef _start_following_logs(self, pb: entities.PipelineBuild):\n    \"\"\
      \"通过轮询，检查流水线是否执行完成，并逐批获取执行日志\"\"\"\n    time_started = time.time()\n    while\
      \ time.time() - time_started < _BUILD_PROCESS_TIMEOUT:\n        time.sleep(self.polling_result_interval)\n\
      \        self.stream.write_message('Pipeline is running, please wait patiently...')\n\
      \        try:\n            build_status = self.ctl.retrieve_build_status(pb)\n\
      \        except BkCIGatewayServiceError:\n            logger.exception(f'call\
      \ bk_ci pipeline for build status and logs failed during deploy[{self.bp}]')\n\
      \            raise\n        if build_status.status in [PipelineBuildStatus.SUCCEED,\
      \ PipelineBuildStatus.FAILED, PipelineBuildStatus.CANCELED]:\n            logger.info('break\
      \ poll loop with pipeline build status: %s', build_status.status)\n        \
      \    break\n    start_following = False\n    for log in self.ctl.retrieve_full_log(pb).logs:\n\
      \        if not (log.tag.startswith('e-') and log.jobId == self.bk_ci_pipeline_job_id):\n\
      \            continue\n        if '[Output]' in log.message:\n            break\n\
      \        if '[Install plugin]' in log.message:\n            start_following\
      \ = True\n        if start_following:\n            self.stream.write_message(re.sub(self.bk_ci_log_level_tag_regex,\
      \ '', log.message))"
    code_lines: 41
    comment_lines: 0
    complexity: 10
    description: 通过轮询，检查流水线是否执行完成，并逐批获取执行日志
    end_line: 373
    line: 333
    message: Complexity 10 exceeds threshold 10
    name: _start_following_logs
    severity: acceptable
    signature: 'def _start_following_logs ( self, pb: entities.PipelineBuild ) :'
  apiserver/paasng/paasng/platform/engine/deploy/bg_wait/wait_bkapp.py:
  - code: "\ndef get_status(self) -> PollingResult:\n    deploy_id = self.params['deploy_id']\n\
      \    dp = AppModelDeploy.objects.get(id=deploy_id)\n    mres = get_mres_from_cluster(ModuleEnvironment.objects.get(application_id=dp.application_id,\
      \ module_id=dp.module_id, environment=dp.environment_name))\n    if not mres:\n\
      \        return PollingResult.doing()\n    if mres.metadata.annotations.get(BKPAAS_DEPLOY_ID_ANNO_KEY)\
      \ != str(deploy_id):\n        return PollingResult.done(data={'state': ModelResState(DeployStatus.UNKNOWN,\
      \ 'Abandoned', 'deployment have been abandoned'), 'last_update': mres.status.lastUpdate})\n\
      \    if mres.status.deployId != str(deploy_id):\n        return PollingResult.doing(data={'bkapp.status.deployId':\
      \ mres.status.deployId})\n    state = MresConditionParser(mres).detect_state()\n\
      \    if state.status == DeployStatus.READY:\n        return PollingResult.done(data={'state':\
      \ state, 'last_update': mres.status.lastUpdate})\n    elif state.status == DeployStatus.ERROR:\n\
      \        polling_failure_count = 1\n        if self.metadata.last_polling_data\
      \ and 'polling_failure_count' in self.metadata.last_polling_data:\n        \
      \    polling_failure_count = self.metadata.last_polling_data['polling_failure_count']\
      \ + 1\n        if polling_failure_count > CNATIVE_DEPLOY_STATUS_POLLING_FAILURE_LIMITS:\n\
      \            return PollingResult.done(data={'state': state, 'last_update':\
      \ mres.status.lastUpdate})\n        return PollingResult.doing(data={'polling_failure_count':\
      \ polling_failure_count})\n    elif state.status == DeployStatus.PROGRESSING:\n\
      \        update_status(dp, state, last_transition_time=mres.status.lastUpdate)\n\
      \    return PollingResult.doing()"
    code_lines: 50
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 213
    line: 164
    message: Complexity 10 exceeds threshold 10
    name: get_status
    severity: acceptable
    signature: 'def get_status ( self ) -> PollingResult :'
  apiserver/paasng/paasng/platform/engine/deploy/release/operator.py:
  - code: "\ndef release_by_k8s_operator(env: ModuleEnvironment, revision: AppModelRevision,\
      \ operator: str, build: Optional[Build] = None, deployment: Optional[Deployment]\
      \ = None) -> str:\n    \"\"\"Create a new release for given environment(which\
      \ will be handled by k8s operator).\n    this action will start an async waiting\
      \ procedure which waits for the release to be finished.\n\n    :param env: The\
      \ environment to create the release for.\n    :param revision: The revision\
      \ to be released.\n    :param operator: current operator's user_id\n    :param\
      \ deployment: the deployment of the release\n\n    :raises: ValueError when\
      \ image credential_refs is invalid  TODO: 抛更具体的异常\n    :raises: UnprocessibleEntityError\
      \ when k8s can not process this manifest\n    :raises: other unknown exceptions...\n\
      \    \"\"\"\n    application = env.application\n    module = env.module\n  \
      \  default_name = f'{application.code}-{revision.pk}-{int(time.time())}'\n \
      \   try:\n        app_model_deploy = AppModelDeploy.objects.create(application_id=application.id,\
      \ module_id=module.id, environment_name=env.environment, name=default_name,\
      \ revision=revision, status=DeployStatus.PENDING.value, operator=operator)\n\
      \    except IntegrityError:\n        logger.warning('Name conflicts when creating\
      \ new AppModelDeploy object, name: %s.', default_name)\n        raise\n    try:\n\
      \        advanced_options = deployment.advanced_options if deployment else None\n\
      \        bkapp_res = get_bkapp_resource_for_deploy(env, deploy_id=str(app_model_deploy.id),\
      \ force_image=build.image if build else None, image_pull_policy=advanced_options.image_pull_policy\
      \ if advanced_options else None, use_cnb=build.is_build_from_cnb() if build\
      \ else False, deployment=deployment)\n        ensure_namespace(env)\n      \
      \  svc_disc.apply_configmap(env, bkapp_res)\n        deploy_addons_tls_certs(env)\n\
      \        deploy_volume_source(env)\n        deployed_manifest = apply_bkapp_to_k8s(env,\
      \ bkapp_res.to_deployable())\n        ensure_bk_log_if_need(env)\n        sync_service_monitor(env)\n\
      \    except Exception:\n        app_model_deploy.status = DeployStatus.ERROR\n\
      \        app_model_deploy.save(update_fields=['status', 'updated'])\n      \
      \  raise\n    revision.deployed_value = deployed_manifest\n    revision.has_deployed\
      \ = True\n    revision.save(update_fields=['deployed_value', 'has_deployed',\
      \ 'updated'])\n    if bkapp_res.spec.hooks and bkapp_res.spec.hooks.preRelease\
      \ and deployment:\n        exec_bkapp_hook.delay(bkapp_res.metadata.name, app_model_deploy.id,\
      \ deployment.id)\n    WaitAppModelReady.start({'env_id': env.id, 'deploy_id':\
      \ app_model_deploy.id, 'deployment_id': deployment.id if deployment else None},\
      \ DeployStatusHandler)\n    return str(app_model_deploy.id)"
    code_lines: 97
    comment_lines: 0
    complexity: 11
    description: Create a new release for given environment(which will be handled
      by k8s operator).
    end_line: 180
    line: 84
    message: Complexity 11 exceeds threshold 10
    name: release_by_k8s_operator
    severity: warning
    signature: 'def release_by_k8s_operator ( env: ModuleEnvironment, revision: AppModelRevision,
      operator: str, build: Optional[Build] = None, deployment: Optional[Deployment]
      = None ) -> str :'
  apiserver/paasng/paasng/platform/engine/utils/source.py:
  - code: "\ndef download_source_to_dir(module: Module, operator: str, deployment:\
      \ Deployment, root_path: Path) -> tuple[str, Path]:\n    \"\"\"Download and\
      \ extract the module's source files to local path, will generate Procfile if\
      \ necessary\n\n    :param root_path: The local path to download the source files\n\
      \    :return: (the configured source directory string, the source directory\
      \ path), the path can be different\n        with the `root_path` if source_dir\
      \ is configured.\n    :raise ValueError: If the configured source directory\
      \ is invalid\n    \"\"\"\n    spec = ModuleSpecs(module)\n    if spec.source_origin_specs.source_origin\
      \ in [SourceOrigin.AUTHORIZED_VCS, SourceOrigin.SCENE]:\n        get_repo_controller(module,\
      \ operator=operator).export(root_path, deployment.version_info)\n    elif spec.deploy_via_package:\n\
      \        PackageController.init_by_module(module, operator).export(root_path,\
      \ deployment.version_info)\n    else:\n        raise NotImplementedError\n \
      \   source_dir_str_deployment = str(deployment.get_source_dir())\n    source_dir_str_desc\
      \ = ''\n    if ModuleSpecs(module).deploy_via_package:\n        try:\n     \
      \       desc_obj = DeploymentDescription.objects.get(deployment=deployment)\n\
      \        except DeploymentDescription.DoesNotExist:\n            pass\n    \
      \    else:\n            source_dir_str_desc = desc_obj.source_dir\n    source_dir_str\
      \ = source_dir_str_deployment\n    if source_dir_str_desc and source_dir_str_desc\
      \ != source_dir_str_deployment:\n        logger.warning('The source_dir in deployment\
      \ description is different from the one in deployment object: %s != %s', source_dir_str_desc,\
      \ source_dir_str_deployment)\n        source_dir_str = source_dir_str_desc\n\
      \    source_dir = validate_source_dir_str(root_path, source_dir_str)\n    if\
      \ module.application.type == ApplicationType.CLOUD_NATIVE and module.build_config.build_method\
      \ == RuntimeType.DOCKERFILE:\n        logger.info('Skip Procfile patching for\
      \ Dockerfile cnative application.')\n        return source_dir_str, source_dir\n\
      \    if reason := patch_source_dir_procfile(source_dir=source_dir, procfile=deployment.get_procfile()):\n\
      \        logger.warning('skip the source patching process: %s', reason)\n  \
      \  return source_dir_str, source_dir"
    code_lines: 71
    comment_lines: 0
    complexity: 10
    description: Download and extract the module's source files to local path, will
      generate Procfile if necessary
    end_line: 307
    line: 237
    message: Complexity 10 exceeds threshold 10
    name: download_source_to_dir
    severity: acceptable
    signature: 'def download_source_to_dir ( module: Module, operator: str, deployment:
      Deployment, root_path: Path ) -> tuple[str, Path] :'
  - code: "\ndef get_deploy_desc_handler_by_version(module: Module, operator: str,\
      \ version_info: VersionInfo, source_dir: Path = _current_path) -> DeployDescHandler:\n\
      \    \"\"\"Get the description handler for the given module and version.\n\n\
      \    :param module: The module object\n    :param operator: The operator name\n\
      \    :param version_info: The version info, will be used to read the description\
      \ file\n    :param source_dir: The source directory path to find the description\
      \ file\n    :return: The handler instance\n    :raise InitDeployDescHandlerError:\
      \ When fail to initialize the handler instance\n    \"\"\"\n    try:\n     \
      \   metadata_reader = get_metadata_reader(module, operator=operator, source_dir=source_dir)\n\
      \    except NotImplementedError:\n        raise InitDeployDescHandlerError('Unsupported\
      \ source type')\n    (app_desc, app_desc_exc) = (None, None)\n    if not _description_flag_disabled(module.application):\n\
      \        try:\n            app_desc = metadata_reader.get_app_desc(version_info)\n\
      \        except GetAppYamlFormatError as e:\n            raise InitDeployDescHandlerError(str(e))\n\
      \        except GetAppYamlError as e:\n            app_desc_exc = e\n    (procfile_data,\
      \ procfile_exc) = (None, None)\n    try:\n        procfile_data = metadata_reader.get_procfile(version_info)\n\
      \    except GetProcfileFormatError as e:\n        raise InitDeployDescHandlerError(str(e))\n\
      \    except GetProcfileError as e:\n        procfile_exc = e\n    if not (app_desc\
      \ or procfile_data):\n        msg = []\n        if app_desc_exc:\n         \
      \   msg.append(f'[app_desc] {app_desc_exc}')\n        if procfile_exc:\n   \
      \         msg.append(f'[Procfile] {procfile_exc}')\n        raise InitDeployDescHandlerError(';\
      \ '.join(msg))\n    try:\n        return get_deploy_desc_handler(app_desc, procfile_data)\n\
      \    except ValueError as e:\n        raise InitDeployDescHandlerError(str(e))"
    code_lines: 50
    comment_lines: 0
    complexity: 12
    description: Get the description handler for the given module and version.
    end_line: 224
    line: 175
    message: Complexity 12 exceeds threshold 10
    name: get_deploy_desc_handler_by_version
    severity: warning
    signature: 'def get_deploy_desc_handler_by_version ( module: Module, operator:
      str, version_info: VersionInfo, source_dir: Path = _current_path ) -> DeployDescHandler
      :'
  apiserver/paasng/paasng/platform/evaluation/evaluators.py:
  - code: "\ndef _evaluate_by_user_visit(self):\n    if not (self.report.pv and self.report.uv):\n\
      \        self.result.issue_type = OperationIssueType.UNVISITED\n        self.result.issues.append(f'应用最近\
      \ {self.visit_summary.time_range} 没有访问记录')\n    for (mod_name, mod) in self.visit_summary.modules.items():\n\
      \        for (env_name, env) in mod.envs.items():\n            env_res_summary\
      \ = self.res_summary.modules[mod_name].envs[env_name]\n            if not (env_res_summary.cpu_requests\
      \ and env_res_summary.mem_requests):\n                continue\n           \
      \ if env.pv and env.uv:\n                continue\n            env_result =\
      \ self.result.modules[mod_name].envs[env_name]\n            env_result.issue_type\
      \ = OperationIssueType.UNVISITED\n            env_result.issues.append(f'该环境最近\
      \ {self.visit_summary.time_range} 没有访问记录')\n            (is_low_cpu_usage, any_proc_running)\
      \ = (True, False)\n            for proc in self.res_summary.modules[mod_name].envs[env_name].procs:\n\
      \                if not (proc.quota and proc.cpu):\n                    continue\n\
      \                any_proc_running = True\n                if proc.cpu.max /\
      \ proc.quota.limits.cpu > 0.01:\n                    is_low_cpu_usage = False\n\
      \                    break\n            if is_low_cpu_usage and any_proc_running:\n\
      \                env_result.issues.append(f'CPU 使用率低于 1% 且近 {self.res_summary.time_range}\
      \ 使用量没有波动')\n                env_result.issue_type = OperationIssueType.IDLE\n\
      \                self.result.issue_type = OperationIssueType.IDLE\n        \
      \        self.result.issues.append(f'模块 {mod_name} 环境 {env_name} 近 {self.visit_summary.time_range}\
      \ 没有访问记录' + f' 且 近 {self.res_summary.time_range} CPU 使用率低于 1%')"
    code_lines: 41
    comment_lines: 0
    complexity: 15
    description: ''
    end_line: 196
    line: 156
    message: Complexity 15 exceeds threshold 10
    name: _evaluate_by_user_visit
    severity: warning
    signature: 'def _evaluate_by_user_visit ( self ) :'
  apiserver/paasng/paasng/platform/evaluation/tasks.py:
  - code: "\ndef _update_or_create_operation_report(app: Application):\n    res_summary\
      \ = AppResQuotaCollector(app).collect()\n    (cpu_requests, mem_requests, cpu_limits,\
      \ mem_limits) = (0, 0, 0, 0)\n    (cpu_usage_avg_val, mem_usage_avg_val) = (0.0,\
      \ 0.0)\n    for module in res_summary.modules.values():\n        for procs in\
      \ [module.envs[AppEnvName.STAG].procs, module.envs[AppEnvName.PROD].procs]:\n\
      \            for proc in procs:\n                if not proc.replicas:\n   \
      \                 continue\n                if proc.quota:\n               \
      \     cpu_requests += proc.replicas * proc.quota.requests.cpu\n            \
      \        mem_requests += proc.replicas * proc.quota.requests.memory\n      \
      \              cpu_limits += proc.replicas * proc.quota.limits.cpu\n       \
      \             mem_limits += proc.replicas * proc.quota.limits.memory\n     \
      \           if proc.cpu:\n                    cpu_usage_avg_val += proc.replicas\
      \ * proc.cpu.avg\n                if proc.memory:\n                    mem_usage_avg_val\
      \ += proc.replicas * proc.memory.avg\n    (total_pv, total_uv) = (0, 0)\n  \
      \  visit_summary = AppUserVisitCollector(app).collect()\n    for mod in visit_summary.modules.values():\n\
      \        for env in [mod.envs[AppEnvName.STAG], mod.envs[AppEnvName.PROD]]:\n\
      \            total_pv += env.pv\n            total_uv += env.uv\n    deploy_summary\
      \ = AppDeploymentCollector(app).collect()\n    latest_deployment = Deployment.objects.filter(app_environment__application=app).order_by('-created').first()\n\
      \    latest_operation = Operation.objects.filter(application=app).order_by('-created').first()\n\
      \    defaults = {'cpu_requests': cpu_requests, 'mem_requests': mem_requests,\
      \ 'cpu_limits': cpu_limits, 'mem_limits': mem_limits, 'cpu_usage_avg': round(cpu_usage_avg_val\
      \ / cpu_limits, 4) if cpu_limits else 0, 'mem_usage_avg': round(mem_usage_avg_val\
      \ / mem_limits, 4) if mem_limits else 0, 'res_summary': asdict(res_summary),\
      \ 'pv': total_pv, 'uv': total_uv, 'visit_summary': asdict(visit_summary), 'latest_deployed_at':\
      \ latest_deployment.created if latest_deployment else None, 'latest_deployer':\
      \ get_username_by_bkpaas_user_id(latest_deployment.operator) if latest_deployment\
      \ else None, 'latest_operated_at': latest_operation.created if latest_operation\
      \ else None, 'latest_operator': latest_operation.get_operator() if latest_operation\
      \ else None, 'latest_operation': latest_operation.get_operate_display() if latest_operation\
      \ else None, 'deploy_summary': asdict(deploy_summary), 'administrators': fetch_role_members(app.code,\
      \ ApplicationRole.ADMINISTRATOR), 'developers': fetch_role_members(app.code,\
      \ ApplicationRole.DEVELOPER), 'collected_at': timezone.now()}\n    (report,\
      \ _) = AppOperationReport.objects.update_or_create(app=app, defaults=defaults)\n\
      \    evaluate_result = AppOperationEvaluator(report, res_summary, visit_summary,\
      \ deploy_summary).evaluate()\n    report.issue_type = evaluate_result.issue_type\n\
      \    report.evaluate_result = asdict(evaluate_result)\n    report.save(update_fields=['issue_type',\
      \ 'evaluate_result'])"
    code_lines: 73
    comment_lines: 0
    complexity: 17
    description: ''
    end_line: 124
    line: 52
    message: Complexity 17 exceeds threshold 10
    name: _update_or_create_operation_report
    severity: high_risk
    signature: 'def _update_or_create_operation_report ( app: Application ) :'
  - code: "\n@shared_task\ndef send_idle_email_to_app_developers(app_codes: List[str],\
      \ only_specified_users: List[str], exclude_specified_users: List[str]):\n  \
      \  \"\"\"发送应用闲置模块邮件给应用管理员/开发者\"\"\"\n    reports = AppOperationReport.objects.filter(issue_type=OperationIssueType.IDLE)\n\
      \    if app_codes:\n        reports = reports.filter(app__code__in=app_codes)\n\
      \    if not reports.exists():\n        logger.info('no idle app reports, skip\
      \ current notification task')\n        return\n    waiting_notify_usernames\
      \ = set()\n    for r in reports:\n        waiting_notify_usernames.update(r.administrators)\n\
      \        waiting_notify_usernames.update(r.developers)\n    if only_specified_users:\n\
      \        waiting_notify_usernames &= set(only_specified_users)\n    if exclude_specified_users:\n\
      \        waiting_notify_usernames -= set(exclude_specified_users)\n    (total_cnt,\
      \ succeed_cnt) = (len(waiting_notify_usernames), 0)\n    failed_usernames =\
      \ []\n    task = AppOperationEmailNotificationTask.objects.create(total_count=total_cnt,\
      \ notification_type=EmailNotificationType.IDLE_APP_MODULE_ENVS)\n    for (idx,\
      \ username) in enumerate(waiting_notify_usernames):\n        filters = ApplicationPermission().gen_develop_app_filters(username)\n\
      \        app_codes = Application.objects.filter(is_active=True).filter(filters).values_list('code',\
      \ flat=True)\n        if just_leave_app_codes := JustLeaveAppManager(username).list():\n\
      \            app_codes = [c for c in app_codes if c not in just_leave_app_codes]\n\
      \        user_idle_app_reports = reports.filter(app__code__in=app_codes)\n \
      \       if not user_idle_app_reports.exists():\n            total_cnt -= 1\n\
      \            logger.info('no idle app reports, skip notification to %s', username)\n\
      \            continue\n        try:\n            AppOperationReportNotifier().send(user_idle_app_reports,\
      \ EmailReceiverType.APP_DEVELOPER, [username])\n        except Exception:\n\
      \            failed_usernames.append(username)\n            logger.exception('failed\
      \ to send idle module envs email to %s', username)\n        succeed_cnt += 1\n\
      \        if idx % 20 == 0:\n            task.succeed_count = succeed_cnt\n \
      \           task.failed_count = len(failed_usernames)\n            task.save(update_fields=['succeed_count',\
      \ 'failed_count'])\n    task.total_count = total_cnt\n    task.succeed_count\
      \ = succeed_cnt\n    task.failed_count = len(failed_usernames)\n    task.failed_usernames\
      \ = failed_usernames\n    task.status = BatchTaskStatus.FINISHED\n    task.end_at\
      \ = timezone.now()\n    task.save(update_fields=['total_count', 'succeed_count',\
      \ 'failed_count', 'failed_usernames', 'status', 'end_at'])"
    code_lines: 67
    comment_lines: 0
    complexity: 12
    description: 发送应用闲置模块邮件给应用管理员/开发者
    end_line: 234
    line: 168
    message: Complexity 12 exceeds threshold 10
    name: send_idle_email_to_app_developers
    severity: warning
    signature: 'def send_idle_email_to_app_developers ( app_codes: List[str], only_specified_users:
      List[str], exclude_specified_users: List[str] ) :'
  apiserver/paasng/paasng/platform/modules/manager.py:
  - code: "\ndef initialize_app_model_resource(self, bkapp_spec: Dict[str, Any]):\n\
      \    \"\"\"\n        Initialize the AppModelResource and import the bkapp_spec\
      \ into the corresponding bkapp models\n\n        :param bkapp_spec: validated_data\
      \ from CreateBkAppSpecSLZ\n        \"\"\"\n    if self.application.type != ApplicationType.CLOUD_NATIVE:\n\
      \        return\n    if not bkapp_spec or bkapp_spec['build_config'].build_method\
      \ != RuntimeType.CUSTOM_IMAGE:\n        return\n    build_config = bkapp_spec['build_config']\n\
      \    config_obj = BuildConfig.objects.get_or_create_by_module(self.module)\n\
      \    build_params = {'image_repository': build_config.image_repository, 'image_credential_name':\
      \ None}\n    if image_credential := build_config.image_credential:\n       \
      \ build_params['image_credential_name'] = image_credential['name']\n    update_build_config_with_method(config_obj,\
      \ build_method=build_config.build_method, data=build_params)\n    processes\
      \ = [Process(name=proc_spec['name'], command=proc_spec['command'], args=proc_spec['args'],\
      \ target_port=proc_spec.get('port', None), probes=proc_spec.get('probes', None),\
      \ services=proc_spec.get('services', None)) for proc_spec in bkapp_spec['processes']]\n\
      \    sync_processes(self.module, processes, manager=FieldMgrName.WEB_FORM)\n\
      \    metrics = []\n    for proc_spec in bkapp_spec['processes']:\n        if\
      \ env_overlay := proc_spec.get('env_overlay'):\n            for (env_name, proc_env_overlay)\
      \ in env_overlay.items():\n                ProcessSpecEnvOverlay.objects.save_by_module(self.module,\
      \ proc_spec['name'], env_name, **proc_env_overlay)\n        if metric := get_items(proc_spec,\
      \ ['monitoring', 'metric']):\n            metrics.append({'process': proc_spec['name'],\
      \ **metric})\n    monitoring = Monitoring(metrics=metrics) if metrics else None\n\
      \    ObservabilityConfig.objects.upsert_by_module(self.module, monitoring)\n\
      \    if hook := bkapp_spec.get('hook'):\n        self.module.deploy_hooks.enable_hook(type_=hook['type'],\
      \ proc_command=hook.get('proc_command'), command=hook.get('command'), args=hook.get('args'))"
    code_lines: 62
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 318
    line: 257
    message: Complexity 11 exceeds threshold 10
    name: initialize_app_model_resource
    severity: warning
    signature: 'def initialize_app_model_resource ( self, bkapp_spec: Dict[str, Any]
      ) :'
  apiserver/paasng/paasng/utils/datetime.py:
  - code: "\ndef calculate_gap_seconds_interval(gap_seconds, wide=False) -> str:\n\
      \    gap_minutes = abs(math.ceil(gap_seconds / 60))\n    if not wide:\n    \
      \    interval_options = ['1s', '10s', '30s', '1m', '5m', '10m', '30m', '1h',\
      \ '3h', '1d']\n    else:\n        interval_options = ['10s', '30s', '1m', '5m',\
      \ '10m', '30m', '1h', '3h', '6h', '1d']\n    if gap_minutes <= 1:\n        index\
      \ = 0\n    elif gap_minutes <= 10:\n        index = 1\n    elif gap_minutes\
      \ <= 30:\n        index = 2\n    elif gap_minutes <= 60:\n        index = 3\n\
      \    elif gap_minutes <= 360:\n        index = 4\n    elif gap_minutes <= 720:\n\
      \        index = 5\n    elif gap_minutes <= 1440:\n        index = 6\n    elif\
      \ gap_minutes <= 4320:\n        index = 7\n    elif gap_minutes <= 10080:\n\
      \        index = 8\n    else:\n        index = 9\n    return interval_options[index]"
    code_lines: 28
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 97
    line: 70
    message: Complexity 11 exceeds threshold 10
    name: calculate_gap_seconds_interval
    severity: warning
    signature: 'def calculate_gap_seconds_interval ( gap_seconds, wide = False ) ->
      str :'
  apiserver/paasng/paasng/utils/i18n/serializers.py:
  - code: "\ndef i18n(cls_or_languages: Optional[Union[Optional[List[str]], SerializerType]]\
      \ = None) -> Union[SerializerType, Callable[[SerializerType], SerializerType]]:\n\
      \    \"\"\"`i18n` decorator will extend those fields wrapped by `I18NField`\
      \ in the serializer.\"\"\"\n    languages = [lang[0] for lang in settings.LANGUAGES]\n\
      \    if isinstance(cls_or_languages, list):\n        languages = cls_or_languages\n\
      \    \n    def decorator(cls: Type[serializers.Serializer]) -> Type[serializers.Serializer]:\n\
      \        \"\"\"Find all i18n fields, add with i18n suffix, finally extend modified\
      \ fields to the `_declared_fields` attr.\n        And The original field will\
      \ be removed.\n        \"\"\"\n        _declared_fields = getattr(cls, '_declared_fields')\n\
      \        fields = {}\n        for (attr, value) in cls.__dict__.items():\n \
      \           if isinstance(value, I18NExtend):\n                fields[attr]\
      \ = value.field\n        for (attr, field) in fields.items():\n            delattr(cls,\
      \ attr)\n            for language_code in languages:\n                i18n_field_name\
      \ = to_translated_field(attr, language_code=language_code)\n               \
      \ _declared_fields[i18n_field_name] = copy.deepcopy(field)\n        super_to_internal_value\
      \ = getattr(cls, 'to_internal_value')\n        \n        def to_internal_value(self,\
      \ data):\n            with ExitStack() as stack:\n                for raw_field_name\
      \ in fields:\n                    for language_code in languages:\n        \
      \                i18n_field_name = to_translated_field(attr, language_code=language_code)\n\
      \                        stack.enter_context(self.fields[i18n_field_name].override_field_name(raw_field_name))\n\
      \                return super_to_internal_value(self, data)\n        setattr(cls,\
      \ 'to_internal_value', to_internal_value)\n        return cls\n    if cls_or_languages\
      \ is None:\n        return decorator\n    elif isinstance(cls_or_languages,\
      \ type) and issubclass(cls_or_languages, serializers.Serializer):\n        return\
      \ decorator(cls_or_languages)\n    raise NotImplementedError"
    code_lines: 49
    comment_lines: 0
    complexity: 11
    description: '`i18n` decorator will extend those fields wrapped by `I18NField`
      in the serializer.'
    end_line: 98
    line: 50
    message: Complexity 11 exceeds threshold 10
    name: i18n
    severity: warning
    signature: 'def i18n ( cls_or_languages: Optional[Union[Optional[List[str]], SerializerType]]
      = None ) -> Union[SerializerType, Callable[[SerializerType], SerializerType]]
      :'
  apiserver/paasng/paasng/utils/models.py:
  - code: "\ndef _make_json_field(base_class: Type[F], cls_name: str, py_model: Type[M],\
      \ module: Optional[str] = None) -> Type[F]:\n    \"\"\"生成会自动进行类型转换为 `py_model`\
      \ 的 `base_class`\n\n    :param base_class: 基础类型\n    :param cls_name: 自动生成的\
      \ JSONField 的类名, 在使用时, cls_name 必须与赋值的变量名一致！否则 migrations 会报错.\n    :param py_model:\
      \ Python 模型, 需要能被 decoder 转换成可序列化成 json serializable object.\n    :param module:\
      \ Python 模块信息\"\"\"\n    if not isinstance(py_model, type) and not (is_sequence(py_model)\
      \ and not is_bare(py_model)) and not is_mapping(py_model):\n        raise NotImplementedError(f'Unsupported\
      \ type: {py_model}')\n    \n    def is_pymodel_instance(value):\n        \"\"\
      \"should unstructured value to string?\"\"\"\n        if is_sequence(py_model):\n\
      \            elem_type = py_model.__args__[0]\n            return all((isinstance(v,\
      \ elem_type) for v in value))\n        elif is_mapping(py_model):\n        \
      \    return isinstance(value, dict)\n        else:\n            return isinstance(value,\
      \ py_model)\n    \n    def pre_init(self, value, obj):\n        \"\"\"Convert\
      \ a dict/list to `py_model` object\"\"\"\n        loaded_value = base_class.pre_init(self,\
      \ value, obj)\n        if loaded_value is None or is_pymodel_instance(value):\n\
      \            return loaded_value\n        return cattr.structure(loaded_value,\
      \ py_model)\n    \n    def get_prep_value(self, value):\n        \"\"\"Convert\
      \ `py_model` object to a string\"\"\"\n        if hasattr(value, 'as_sql'):\n\
      \            return value\n        if value is not None and is_pymodel_instance(value):\n\
      \            value = cattr.unstructure(value)\n        return base_class.get_prep_value(self,\
      \ value)\n    \n    def to_python(self, value):\n        \"\"\"The jsonfield.SubfieldBase\
      \ metaclass calls pre_init instead of to_python, however to_python\n       \
      \ is still necessary for Django's deserializer\"\"\"\n        loaded_value =\
      \ base_class.to_python(self, value)\n        if loaded_value is None:\n    \
      \        return loaded_value\n        return cattr.structure(loaded_value, py_model)\n\
      \    \n    def from_db_value(self, value, expression, connection):\n       \
      \ \"\"\"Convert string-like value to `py_model` object, calling by django\"\"\
      \"\n        loaded_value = base_class.from_db_value(self, value, expression,\
      \ connection)\n        if loaded_value is None:\n            return loaded_value\n\
      \        return cattr.structure(loaded_value, py_model)\n    \n    def value_to_string(self,\
      \ obj):\n        \"\"\"Convert `py_model` object to a string, calling by django\"\
      \"\"\n        value = self.value_from_object(obj)\n        return self.get_prep_value(value)\n\
      \    cls = type(cls_name, (base_class, ), dict(pre_init=pre_init, get_prep_value=get_prep_value,\
      \ to_python=to_python, from_db_value=from_db_value, value_to_string=value_to_string))\n\
      \    if module is None:\n        module = __get_module_from_frame()\n    if\
      \ module is None:\n        raise RuntimeError(\"Can't detect the module name.\
      \ please provide by func args.\")\n    cls.__module__ = str(module)\n    assert\
      \ issubclass(cls, base_class)\n    return cls"
    code_lines: 93
    comment_lines: 0
    complexity: 17
    description: 生成会自动进行类型转换为 `py_model` 的 `base_class`
    end_line: 382
    line: 290
    message: Complexity 17 exceeds threshold 10
    name: _make_json_field
    severity: high_risk
    signature: 'def _make_json_field ( base_class: Type[F], cls_name: str, py_model:
      Type[M], module: Optional[str] = None ) -> Type[F] :'
  apiserver/paasng/paasng/utils/patternmatcher.py:
  - code: "\ndef compile(self, sl: str):\n    reg_str = '^'\n    pattern = self.cleaned_pattern\n\
      \    esc_sl = sl\n    if esc_sl == '\\\\':\n        esc_sl += '\\\\'\n    self.match_type\
      \ = MatchType.Excat\n    scan = Scanner(pattern)\n    i = 0\n    while not scan.is_eof():\n\
      \        ch = scan.next()\n        if ch == '*':\n            if scan.peek()\
      \ == '*':\n                scan.next()\n                if scan.peek() == sl:\n\
      \                    scan.next()\n                if scan.is_eof():\n      \
      \              if self.match_type == MatchType.Excat:\n                    \
      \    self.match_type = MatchType.Prefix\n                    else:\n       \
      \                 reg_str += '.*'\n                        self.match_type =\
      \ MatchType.Regexp\n                else:\n                    reg_str += '(.*'\
      \ + esc_sl + ')?'\n                    self.match_type = MatchType.Regexp\n\
      \                if i == 0:\n                    self.match_type = MatchType.Suffix\n\
      \            else:\n                reg_str += '[^' + esc_sl + ']*'\n      \
      \          self.match_type = MatchType.Regexp\n        elif ch == '?':\n   \
      \         reg_str += '[^' + esc_sl + ']'\n            self.match_type = MatchType.Regexp\n\
      \        elif should_escape(ch):\n            reg_str += '\\\\' + ch\n     \
      \   elif ch == '\\\\':\n            if sl == '\\\\':\n                reg_str\
      \ += esc_sl\n                i += 1\n                continue\n            if\
      \ not scan.is_eof():\n                reg_str += '\\\\' + scan.next()\n    \
      \            self.match_type = MatchType.Regexp\n            else:\n       \
      \         reg_str += '\\\\'\n        elif ch in ('[', ']'):\n            reg_str\
      \ += ch\n            self.match_type = MatchType.Regexp\n        else:\n   \
      \         reg_str += ch\n        i += 1\n    if self.match_type != MatchType.Regexp:\n\
      \        return\n    reg_str += '$'\n    self.regexp = re.compile(reg_str)\n\
      \    return"
    code_lines: 68
    comment_lines: 0
    complexity: 16
    description: ''
    end_line: 133
    line: 66
    message: Complexity 16 exceeds threshold 10
    name: compile
    severity: high_risk
    signature: 'def compile ( self, sl: str ) :'
  apiserver/paasng/tests/api/bkapp_model/test_bkapp_model.py:
  - code: "\ndef test_retrieve(self, api_client, bk_cnative_app, bk_module, web, celery_worker):\n\
      \    url = f'/api/bkapps/applications/{bk_cnative_app.code}/modules/{bk_module.name}/bkapp_model/process_specs/'\n\
      \    resp = api_client.get(url)\n    data = resp.json()\n    metadata = data['metadata']\n\
      \    proc_specs = data['proc_specs']\n    assert metadata['allow_multiple_image']\
      \ is False\n    assert len(proc_specs) == 2\n    assert proc_specs[0]['name']\
      \ == 'web'\n    assert proc_specs[0]['image'] == 'example.com/foo'\n    assert\
      \ proc_specs[0]['command'] == ['python']\n    assert proc_specs[0]['args'] ==\
      \ ['-m', 'http.server']\n    assert proc_specs[0]['env_overlay']['stag']['scaling_config']\
      \ == {'min_replicas': 1, 'max_replicas': 1, 'metrics': [{'type': 'Resource',\
      \ 'metric': 'cpuUtilization', 'value': '85'}], 'policy': 'default'}\n    assert\
      \ proc_specs[0]['services'] is None\n    assert proc_specs[1]['name'] == 'worker'\n\
      \    assert proc_specs[1]['image'] == 'example.com/foo'\n    assert proc_specs[1]['command']\
      \ == ['celery']\n    assert proc_specs[1]['args'] == []\n    assert proc_specs[1]['services']\
      \ is None"
    code_lines: 25
    comment_lines: 0
    complexity: 14
    description: ''
    end_line: 77
    line: 53
    message: Complexity 14 exceeds threshold 10
    name: test_retrieve
    severity: warning
    signature: 'def test_retrieve ( self, api_client, bk_cnative_app, bk_module, web,
      celery_worker ) :'
  - code: "\ndef test_save(self, api_client, bk_cnative_app, bk_module, web, celery_worker):\n\
      \    G(ProcessSpecEnvOverlay, proc_spec=web, environment_name='stag', autoscaling=True,\
      \ scaling_config={'min_replicas': 1, 'max_replicas': 5, 'policy': 'default'})\n\
      \    assert web.get_autoscaling('stag')\n    url = f'/api/bkapps/applications/{bk_cnative_app.code}/modules/{bk_module.name}/bkapp_model/process_specs/'\n\
      \    probes_cfg = {'liveness': {'exec': {'command': ['/bin/bash', '-c', 'echo\
      \ hello']}, 'http_get': None, 'tcp_socket': None, 'initial_delay_seconds': 5,\
      \ 'timeout_seconds': 5, 'period_seconds': 5, 'success_threshold': 1, 'failure_threshold':\
      \ 3}, 'readiness': {'exec': None, 'tcp_socket': None, 'http_get': {'port': 8080,\
      \ 'host': 'bk.example.com', 'path': '/healthz', 'http_headers': [{'name': 'XXX',\
      \ 'value': 'YYY'}], 'scheme': 'HTTPS'}, 'initial_delay_seconds': 15, 'timeout_seconds':\
      \ 60, 'period_seconds': 10, 'success_threshold': 1, 'failure_threshold': 5},\
      \ 'startup': {'exec': None, 'http_get': None, 'tcp_socket': {'port': 8080, 'host':\
      \ 'bk.example.com'}, 'initial_delay_seconds': 5, 'timeout_seconds': 15, 'period_seconds':\
      \ 2, 'success_threshold': 1, 'failure_threshold': 5}}\n    request_data = [{'name':\
      \ 'web', 'image': 'python:latest', 'command': ['python', '-m'], 'args': ['http.server'],\
      \ 'port': 5000, 'env_overlay': {'stag': {'plan_name': 'default', 'target_replicas':\
      \ 2, 'autoscaling': False}}, 'probes': probes_cfg}, {'name': 'beat', 'command':\
      \ ['python', '-m'], 'args': ['celery', 'beat'], 'env_overlay': {'stag': {'plan_name':\
      \ 'default', 'target_replicas': 1}, 'prod': {'plan_name': 'default', 'target_replicas':\
      \ 1, 'autoscaling': True, 'scaling_config': {'min_replicas': 1, 'max_replicas':\
      \ 5, 'metrics': [{'type': 'Resource', 'metric': 'cpuUtilization', 'value': '70'}]}}},\
      \ 'probes': {'liveness': None, 'readiness': None, 'startup': None}}]\n    resp\
      \ = api_client.post(url, data={'proc_specs': request_data})\n    data = resp.json()\n\
      \    proc_specs = data['proc_specs']\n    assert ModuleProcessSpec.objects.filter(module=bk_module).count()\
      \ == 2\n    assert len(proc_specs) == 2\n    assert proc_specs[0]['name'] ==\
      \ 'web'\n    assert proc_specs[0]['image'] == 'example.com/foo'\n    assert\
      \ proc_specs[0]['command'] == ['python', '-m']\n    assert proc_specs[0]['args']\
      \ == ['http.server']\n    assert proc_specs[0]['port'] == 5000\n    assert proc_specs[0]['env_overlay']['stag']['target_replicas']\
      \ == 2\n    assert not proc_specs[0]['env_overlay']['stag']['autoscaling']\n\
      \    assert proc_specs[0]['probes'] == probes_cfg\n    assert proc_specs[1]['name']\
      \ == 'beat'\n    assert proc_specs[1]['image'] == 'example.com/foo'\n    assert\
      \ proc_specs[1]['command'] == ['python', '-m']\n    assert proc_specs[1]['args']\
      \ == ['celery', 'beat']\n    assert proc_specs[1]['env_overlay']['prod']['scaling_config']\
      \ == {'min_replicas': 1, 'max_replicas': 5, 'metrics': [{'type': 'Resource',\
      \ 'metric': 'cpuUtilization', 'value': '85'}], 'policy': 'default'}\n    assert\
      \ proc_specs[1]['probes'] == {'liveness': None, 'readiness': None, 'startup':\
      \ None}\n    spec_obj = ModuleProcessSpec.objects.get(module=bk_module, name='beat')\n\
      \    assert spec_obj.get_scaling_config('prod') == AutoscalingConfig(min_replicas=1,\
      \ max_replicas=5, policy='default')\n    assert spec_obj.probes == {'liveness':\
      \ None, 'readiness': None, 'startup': None}\n    assert spec_obj.probes.liveness\
      \ is None"
    code_lines: 134
    comment_lines: 0
    complexity: 21
    description: ''
    end_line: 212
    line: 79
    message: Complexity 21 exceeds threshold 10
    name: test_save
    severity: critical
    signature: 'def test_save ( self, api_client, bk_cnative_app, bk_module, web,
      celery_worker ) :'
  apiserver/paasng/tests/api/extensions/test_bkplugins.py:
  - code: "\ndef test_sync(self, bk_plugin_app, sys_api_client):\n    module = bk_plugin_app.get_default_module()\n\
      \    assert ConfigVar.objects.filter(module=module).count() == 0\n    response\
      \ = sys_api_client.post(f'/sys/api/plugins_center/bk_plugins/{bk_plugin_app.code}/configuration/',\
      \ data=[{'key': 'FOO', 'value': 'foo'}, {'key': 'BAR', 'value': 'bar'}, {'key':\
      \ 'BAZ', 'value': 'baz'}])\n    assert response.status_code == 200\n    assert\
      \ ConfigVar.objects.filter(module=module).count() == 3\n    assert ConfigVar.objects.get(module=module,\
      \ key='FOO').value == 'foo'\n    assert ConfigVar.objects.get(module=module,\
      \ key='BAR').value == 'bar'\n    assert ConfigVar.objects.get(module=module,\
      \ key='BAZ').value == 'baz'\n    response = sys_api_client.post(f'/sys/api/plugins_center/bk_plugins/{bk_plugin_app.code}/configuration/',\
      \ data=[{'key': 'FOO', 'value': 'foo'}, {'key': 'BAR', 'value': 'BAR'}])\n \
      \   assert response.status_code == 200\n    assert ConfigVar.objects.filter(module=module).count()\
      \ == 2\n    assert ConfigVar.objects.get(module=module, key='FOO').value ==\
      \ 'foo'\n    assert ConfigVar.objects.get(module=module, key='BAR').value ==\
      \ 'BAR'"
    code_lines: 23
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 97
    line: 75
    message: Complexity 11 exceeds threshold 10
    name: test_sync
    severity: warning
    signature: 'def test_sync ( self, bk_plugin_app, sys_api_client ) :'
  apiserver/paasng/tests/api/test_applications.py:
  - code: "\ndef test_create_with_image(self, api_client):\n    \"\"\"托管方式：仅镜像\"\"\
      \"\n    random_suffix = generate_random_string(length=6)\n    image_credential_name\
      \ = generate_random_string(length=6)\n    image_repository = 'strm/helloworld-http'\n\
      \    response = api_client.post('/api/bkapps/cloud-native/', data={'region':\
      \ settings.DEFAULT_REGION_NAME, 'code': f'uta-{random_suffix}', 'name': f'uta-{random_suffix}',\
      \ 'bkapp_spec': {'build_config': {'build_method': 'custom_image', 'image_repository':\
      \ image_repository, 'image_credential': {'name': image_credential_name, 'password':\
      \ '123456', 'username': 'test'}}, 'processes': [{'name': 'web', 'command': ['bash',\
      \ '/app/start_web.sh'], 'env_overlay': {'stag': {'environment_name': 'stag',\
      \ 'target_replicas': 1, 'plan_name': '2C1G'}, 'prod': {'environment_name': 'prod',\
      \ 'target_replicas': 2, 'plan_name': '2C1G'}}}]}, 'source_config': {'source_origin':\
      \ SourceOrigin.CNATIVE_IMAGE, 'source_repo_url': image_repository}})\n    assert\
      \ response.status_code == 201, f\"error: {response.json()['detail']}\"\n   \
      \ app_data = response.json()['application']\n    assert app_data['type'] ==\
      \ 'cloud_native'\n    assert app_data['modules'][0]['web_config']['build_method']\
      \ == 'custom_image'\n    assert app_data['modules'][0]['web_config']['artifact_type']\
      \ == 'none'\n    module = Module.objects.get(id=app_data['modules'][0]['id'])\n\
      \    cfg = BuildConfig.objects.get_or_create_by_module(module)\n    assert cfg.image_repository\
      \ == image_repository\n    assert cfg.image_credential_name == image_credential_name\n\
      \    process_spec = ModuleProcessSpec.objects.get(module=module, name='web')\n\
      \    assert process_spec.command == ['bash', '/app/start_web.sh']\n    assert\
      \ process_spec.get_target_replicas('stag') == 1\n    assert process_spec.get_target_replicas('prod')\
      \ == 2"
    code_lines: 49
    comment_lines: 0
    complexity: 10
    description: 托管方式：仅镜像
    end_line: 541
    line: 493
    message: Complexity 10 exceeds threshold 10
    name: test_create_with_image
    severity: acceptable
    signature: 'def test_create_with_image ( self, api_client ) :'
  apiserver/paasng/tests/api/test_configvar_by_key.py:
  - code: "\n@pytest.mark.parametrize(('init_env', 'init_value', 'update_env', 'update_value',\
      \ 'expected_envs', 'expected_values'), [(None, None, stag_env, 'v1', [stag_env],\
      \ ['v1']), (stag_env, 'stag_v', prod_env, 'prod_v', [stag_env, prod_env], ['stag_v',\
      \ 'prod_v']), (prod_env, 'old_prod', prod_env, 'new_prod', [prod_env], ['new_prod']),\
      \ (global_env, 'global_v', prod_env, 'prod_v', [global_env, prod_env], ['global_v',\
      \ 'prod_v'])])\ndef test_configvar_by_key(api_client, bk_module, init_env, init_value,\
      \ update_env, update_value, expected_envs, expected_values):\n    module = bk_module\n\
      \    env_key = 'FOO'\n    if init_env:\n        if init_env == global_env:\n\
      \            env_obj = -1\n            ConfigVar.objects.create(module=module,\
      \ key=env_key, environment_id=env_obj, value=init_value, description='desc',\
      \ is_global=True)\n        else:\n            env_obj = ApplicationEnvironment.objects.get(module=module,\
      \ environment=init_env)\n            ConfigVar.objects.create(module=module,\
      \ key=env_key, environment=env_obj, value=init_value, description='desc')\n\
      \    path = f'/api/bkapps/applications/{bk_module.application.code}/modules/{bk_module.name}/config_vars/{env_key}/'\n\
      \    resp = api_client.post(path, data={'environment_name': update_env, 'value':\
      \ update_value, 'description': 'desc2'}, format='json')\n    assert resp.status_code\
      \ == 201\n    resp = api_client.get(path)\n    assert resp.status_code == 200\n\
      \    data = resp.json()\n    assert len(data) == len(expected_envs)\n    env_map\
      \ = {d['environment_name']: d['value'] for d in data}\n    for (env, val) in\
      \ zip(expected_envs, expected_values):\n        assert env_map[env] == val\n\
      \    for item in data:\n        if item['environment_name'] == global_env:\n\
      \            assert item['is_global'] is True\n        else:\n            assert\
      \ item['is_global'] is False"
    code_lines: 61
    comment_lines: 0
    complexity: 12
    description: ''
    end_line: 92
    line: 32
    message: Complexity 12 exceeds threshold 10
    name: test_configvar_by_key
    severity: warning
    signature: 'def test_configvar_by_key ( api_client, bk_module, init_env, init_value,
      update_env, update_value, expected_envs, expected_values ) :'
  apiserver/paasng/tests/api/test_market.py:
  - code: "\ndef test_update_market_app(self, api_client, bk_app_full):\n    if getattr(settings,\
      \ 'BK_CONSOLE_DBCONF', None):\n        from paasng.accessories.publish.sync_market.handlers\
      \ import register_app_core_data\n        register_app_core_data(sender=None,\
      \ application=bk_app_full)\n    Product.objects.create_default_product(bk_app_full)\n\
      \    response = api_client.get(reverse('api.market.products.detail', args=(bk_app_full.code,\
      \ )), format='json')\n    data = response.json()\n    target_name = uuid.uuid4().hex[:20]\n\
      \    data['name'] = target_name\n    data['width'] = 841\n    data['contact']\
      \ = 'nobody;nobody1'\n    data['open_mode'] = OpenMode.NEW_TAB.value\n    data['visiable_labels']\
      \ = [{'id': 100, 'type': 'department', 'name': 'xx部门'}, {'id': 2001, 'type':\
      \ 'user', 'name': 'user1'}]\n    put_response = api_client.put(reverse('api.market.products.detail',\
      \ args=(bk_app_full.code, )), data=data, format='json')\n    assert put_response.status_code\
      \ == 200\n    product = Product.objects.get(code=bk_app_full.code)\n    assert\
      \ product.name == target_name\n    assert product.displayoptions.width == 841\n\
      \    assert product.displayoptions.contact == 'nobody;nobody1'\n    assert product.displayoptions.open_mode\
      \ == OpenMode.NEW_TAB.value\n    if getattr(settings, 'BK_CONSOLE_DBCONF', None):\n\
      \        from paasng.accessories.publish.sync_market.managers import AppManger\n\
      \        from paasng.core.core.storages.sqlalchemy import console_db\n     \
      \   session = console_db.get_scoped_session()\n        console_app = AppManger(session).get(bk_app_full.code)\n\
      \        assert console_app.width == product.displayoptions.width == 841\n \
      \       assert console_app.open_mode == product.displayoptions.open_mode\n \
      \       try:\n            assert json.loads(console_app.extra)['contact'] ==\
      \ product.displayoptions.contact\n        except AttributeError:\n         \
      \   logger.info('The extra attribute of the application does not exist, skip\
      \ verification')\n        try:\n            assert console_app.visiable_labels\
      \ == product.transform_visiable_labels()\n        except AttributeError:\n \
      \           logger.info('The visiable_labels attribute of the application does\
      \ not exist, skip verification')"
    code_lines: 52
    comment_lines: 0
    complexity: 14
    description: ''
    end_line: 164
    line: 113
    message: Complexity 14 exceeds threshold 10
    name: test_update_market_app
    severity: warning
    signature: 'def test_update_market_app ( self, api_client, bk_app_full ) :'
  apiserver/paasng/tests/api/test_modules.py:
  - code: "\ndef test_create_with_image(self, bk_cnative_app, api_client):\n    \"\
      \"\"托管方式：仅镜像\"\"\"\n    random_suffix = generate_random_string(length=6)\n \
      \   image_repository = 'strm/helloworld-http'\n    response = api_client.post(f'/api/bkapps/cloud-native/{bk_cnative_app.code}/modules/',\
      \ data={'name': f'uta-{random_suffix}', 'source_config': {'source_origin': SourceOrigin.CNATIVE_IMAGE,\
      \ 'source_repo_url': 'strm/helloworld-http'}, 'bkapp_spec': {'build_config':\
      \ {'build_method': 'custom_image', 'image_repository': image_repository}, 'processes':\
      \ [{'name': 'web', 'command': ['bash', '/app/start_web.sh'], 'env_overlay':\
      \ {'stag': {'environment_name': 'stag', 'target_replicas': 1, 'plan_name': '2C1G'},\
      \ 'prod': {'environment_name': 'prod', 'target_replicas': 2, 'plan_name': '2C1G'}},\
      \ 'port': 30000}], 'hook': {'type': 'pre-release-hook', 'enabled': True, 'command':\
      \ ['/bin/bash'], 'args': ['-c', \"echo 'hello world'\"]}}})\n    assert response.status_code\
      \ == 201, f\"error: {response.json()['detail']}\"\n    module_data = response.json()['module']\n\
      \    assert module_data['web_config']['build_method'] == 'custom_image'\n  \
      \  assert module_data['web_config']['artifact_type'] == 'none'\n    module =\
      \ Module.objects.get(id=module_data['id'])\n    cfg = BuildConfig.objects.get_or_create_by_module(module)\n\
      \    assert cfg.image_repository == image_repository\n    process_spec = ModuleProcessSpec.objects.get(module=module,\
      \ name='web')\n    assert process_spec.command == ['bash', '/app/start_web.sh']\n\
      \    assert process_spec.port == 30000\n    assert process_spec.get_target_replicas('stag')\
      \ == 1\n    assert process_spec.get_target_replicas('prod') == 2\n    deploy_hook\
      \ = ModuleDeployHook.objects.get(module=module, type=DeployHookType.PRE_RELEASE_HOOK)\n\
      \    assert deploy_hook.command == ['/bin/bash']\n    assert deploy_hook.args\
      \ == ['-c', \"echo 'hello world'\"]"
    code_lines: 52
    comment_lines: 0
    complexity: 11
    description: 托管方式：仅镜像
    end_line: 171
    line: 120
    message: Complexity 11 exceeds threshold 10
    name: test_create_with_image
    severity: warning
    signature: 'def test_create_with_image ( self, bk_cnative_app, api_client ) :'
  apiserver/paasng/tests/paas_wl/bk_app/deploy/app_res/test_controllers.py:
  - code: "\n@pytest.mark.mock_get_structured_app()\ndef test_deploy_processes(self,\
      \ wl_app, web_process):\n    handler = ProcessesHandler.new_by_app(wl_app)\n\
      \    with patch('paas_wl.infras.resources.base.kres.NameBasedOperations.replace_or_patch')\
      \ as kd, patch('paas_wl.workloads.networking.ingress.managers.service.service_kmodel')\
      \ as ks, patch('paas_wl.workloads.networking.ingress.managers.base.ingress_kmodel')\
      \ as ki:\n        ks.get.side_effect = AppEntityNotFound()\n        ki.get.side_effect\
      \ = AppEntityNotFound()\n        handler.deploy([web_process])\n        assert\
      \ kd.called\n        (deployment_args, deployment_kwargs) = kd.call_args_list[0]\n\
      \        assert deployment_kwargs.get('name') == f'{region}-{wl_app.name}-web-python-deployment'\n\
      \        assert deployment_kwargs.get('body')\n        assert deployment_kwargs.get('namespace')\
      \ == wl_app.namespace\n        assert ks.get.called\n        assert ks.create.called\n\
      \        proc_service = ks.create.call_args_list[0][0][0]\n        assert proc_service.name\
      \ == f'{region}-{wl_app.name}-web'\n        assert ks.get.called\n        assert\
      \ ki.save.called\n        proc_ingress = ki.save.call_args_list[0][0][0]\n \
      \       assert proc_ingress.name == f'{region}-{wl_app.name}'"
    code_lines: 29
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 170
    line: 142
    message: Complexity 11 exceeds threshold 10
    name: test_deploy_processes
    severity: warning
    signature: 'def test_deploy_processes ( self, wl_app, web_process ) :'
  apiserver/paasng/tests/paas_wl/bk_app/dev_sandbox/test_controller.py:
  - code: "\n@pytest.mark.usefixtures('_do_deploy')\ndef test_deploy_success(self,\
      \ controller, bk_app, module_name, user_dev_wl_app):\n    sandbox_entity_in_cluster\
      \ = controller.sandbox_mgr.get(user_dev_wl_app, user_dev_wl_app.scheduler_safe_name)\n\
      \    assert sandbox_entity_in_cluster.runtime.envs == {'FOO': 'test', 'SOURCE_FETCH_METHOD':\
      \ 'BK_REPO', 'SOURCE_FETCH_URL': 'example.com', 'WORKSPACE': '/cnb/devsandbox/src'}\n\
      \    assert sandbox_entity_in_cluster.status.replicas == 1\n    assert sandbox_entity_in_cluster.status.ready_replicas\
      \ in [0, 1]\n    assert sandbox_entity_in_cluster.status.to_health_phase() in\
      \ ['Progressing', 'Healthy']\n    code_editor_entity_in_cluster = controller.code_editor_mgr.get(user_dev_wl_app,\
      \ get_code_editor_name(user_dev_wl_app))\n    assert code_editor_entity_in_cluster.runtime.envs\
      \ == {'PASSWORD': '123456', 'START_DIR': '/home/coder/project'}\n    assert\
      \ code_editor_entity_in_cluster.status.replicas == 1\n    assert code_editor_entity_in_cluster.status.ready_replicas\
      \ in [0, 1]\n    assert code_editor_entity_in_cluster.status.to_health_phase()\
      \ in ['Progressing', 'Healthy']\n    service_entity_in_cluster = controller.dev_sandbox_svc_mgr.get(user_dev_wl_app,\
      \ get_dev_sandbox_service_name(user_dev_wl_app))\n    assert service_entity_in_cluster.name\
      \ == get_dev_sandbox_service_name(user_dev_wl_app)\n    ingress_entity_in_cluster\
      \ = controller.ingress_mgr.get(user_dev_wl_app, get_ingress_name(user_dev_wl_app))\n\
      \    assert ingress_entity_in_cluster.name == get_ingress_name(user_dev_wl_app)\n\
      \    assert ingress_entity_in_cluster.domains[0].host == get_sub_domain_host(bk_app.code,\
      \ user_dev_wl_app, module_name)"
    code_lines: 31
    comment_lines: 0
    complexity: 12
    description: ''
    end_line: 145
    line: 115
    message: Complexity 12 exceeds threshold 10
    name: test_deploy_success
    severity: warning
    signature: 'def test_deploy_success ( self, controller, bk_app, module_name, user_dev_wl_app
      ) :'
  apiserver/paasng/tests/paas_wl/bk_app/processes/test_models.py:
  - code: "\ndef test_switch(self, wl_app):\n    mgr = ProcessSpecManager(wl_app)\n\
      \    mgr.sync([ProcessTmpl(name='web', command='foo', replicas=2), ProcessTmpl(name='celery',\
      \ command='foo')])\n    web = ProcessSpec.objects.get(engine_app=wl_app, name='web')\n\
      \    assert web.target_replicas == 2\n    assert not web.autoscaling\n    assert\
      \ web.scaling_config is None\n    mgr.sync([ProcessTmpl(name='web', command='foo',\
      \ replicas=2, autoscaling=True, scaling_config=AutoscalingConfig(min_replicas=1,\
      \ max_replicas=3, policy='default')), ProcessTmpl(name='celery', command='foo')])\n\
      \    web.refresh_from_db()\n    assert web.target_replicas == 2\n    assert\
      \ web.autoscaling\n    assert web.scaling_config is not None\n    assert web.scaling_config.min_replicas\
      \ == 1\n    assert web.scaling_config.max_replicas == 3\n    assert web.scaling_config.policy\
      \ == 'default'\n    mgr.sync([ProcessTmpl(name='web', command='foo', replicas=2,\
      \ autoscaling=False), ProcessTmpl(name='celery', command='foo')])\n    web.refresh_from_db()\n\
      \    assert web.target_replicas == 2\n    assert not web.autoscaling\n    assert\
      \ web.scaling_config is not None\n    assert web.scaling_config.min_replicas\
      \ == 1\n    assert web.scaling_config.max_replicas == 3\n    assert web.scaling_config.policy\
      \ == 'default'"
    code_lines: 46
    comment_lines: 0
    complexity: 16
    description: ''
    end_line: 102
    line: 57
    message: Complexity 16 exceeds threshold 10
    name: test_switch
    severity: high_risk
    signature: 'def test_switch ( self, wl_app ) :'
  - code: "\ndef test_sync(self, wl_app):\n    mgr = ProcessProbeManager(wl_app)\n\
      \    mgr.sync([ProcessTmpl(name='web', command='/bin/start.sh', probes=ProbeSet(liveness=Probe(exec=ExecAction(command=['/bin/healthz.sh'])),\
      \ readiness=Probe(tcp_socket=TCPSocketAction(port=8080, host='127.0.0.1')))),\
      \ ProcessTmpl(name='celery', command='/bin/start_celery.sh', probes=ProbeSet(startup=Probe(http_get=HTTPGetAction(port=8080,\
      \ path='/healthz', host='127.0.0.1'))))])\n    probes = ProcessProbe.objects.filter(app=wl_app)\n\
      \    assert probes.count() == 3\n    assert probes.filter(process_type='web').count()\
      \ == 2\n    assert probes.filter(process_type='celery').count() == 1\n    mgr.sync([ProcessTmpl(name='web',\
      \ command='foo', probes=ProbeSet(liveness=Probe(http_get=HTTPGetAction(port=8080,\
      \ path='/healthz')), readiness=Probe(tcp_socket=TCPSocketAction(port=8080)),\
      \ startup=Probe(exec=ExecAction(command=['/bin/healthz.sh']))))])\n    probes\
      \ = ProcessProbe.objects.filter(app=wl_app, process_type='web')\n    assert\
      \ probes.count() == 3\n    probe = probes.filter(probe_type=ProbeType.LIVENESS).first()\n\
      \    assert probe is not None\n    assert probe.success_threshold == 1\n   \
      \ assert probe.failure_threshold == 3\n    assert probe.probe_handler.http_get.port\
      \ == 8080\n    assert probe.probe_handler.http_get.path == '/healthz'\n    mgr.sync([ProcessTmpl(name='web',\
      \ command='foo', probes=None)])\n    assert not ProcessProbe.objects.filter(app=wl_app).exists()"
    code_lines: 51
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 156
    line: 106
    message: Complexity 11 exceeds threshold 10
    name: test_sync
    severity: warning
    signature: 'def test_sync ( self, wl_app ) :'
  apiserver/paasng/tests/paas_wl/bk_app/processes/test_processes.py:
  - code: "\ndef testlist_gen_cnative_process_specs():\n    specs = gen_cnative_process_specs(BkAppResource(metadata={'name':\
      \ 'test'}, spec={'processes': [{'name': 'web', 'resQuotaPlan': '4C2G'}, {'name':\
      \ 'worker', 'resQuotaPlan': 'default', 'autoscaling': {'minReplicas': 1, 'maxReplicas':\
      \ 3, 'policy': 'default'}}], 'envOverlay': {'replicas': [{'process': 'worker',\
      \ 'count': 0, 'envName': 'stag'}], 'autoscaling': [{'process': 'worker', 'minReplicas':\
      \ 3, 'maxReplicas': 5, 'envName': 'stag', 'policy': 'default'}]}}), 'stag')\n\
      \    assert specs[0].name == 'web'\n    assert specs[0].plan_name == '4C2G'\n\
      \    assert specs[0].target_replicas == 1\n    assert specs[0].autoscaling is\
      \ False\n    assert specs[0].scaling_config is None\n    assert specs[0].resource_limit\
      \ == {'cpu': '4000m', 'memory': '2048Mi'}\n    assert specs[0].resource_limit_quota\
      \ == {'cpu': 4000, 'memory': 2048}\n    assert specs[0].resource_requests ==\
      \ {'cpu': '200m', 'memory': '1024Mi'}\n    assert specs[0].target_status ==\
      \ 'start'\n    assert specs[1].name == 'worker'\n    assert specs[1].plan_name\
      \ == 'default'\n    assert specs[1].target_replicas == 0\n    assert specs[1].autoscaling\
      \ is True\n    assert specs[1].scaling_config['min_replicas'] == 3\n    assert\
      \ specs[1].scaling_config['max_replicas'] == 5\n    assert specs[1].resource_limit\
      \ == {'cpu': '4000m', 'memory': '1024Mi'}\n    assert specs[1].resource_limit_quota\
      \ == {'cpu': 4000, 'memory': 1024}\n    assert specs[1].resource_requests ==\
      \ {'cpu': '200m', 'memory': '256Mi'}\n    assert specs[1].target_status == 'stop'"
    code_lines: 50
    comment_lines: 0
    complexity: 20
    description: ''
    end_line: 84
    line: 35
    message: Complexity 20 exceeds threshold 10
    name: testlist_gen_cnative_process_specs
    severity: high_risk
    signature: 'def testlist_gen_cnative_process_specs (  ) :'
  apiserver/paasng/tests/paas_wl/infras/cluster/test_commands.py:
  - code: "\n@pytest.mark.usefixtures('_cluster_envs')\n@pytest.mark.parametrize(('https_enabled',\
      \ 'expect'), [('true', True), ('false', False)])\ndef test_init_cluster(https_enabled,\
      \ expect):\n    os.environ['PAAS_WL_CLUSTER_ENABLED_HTTPS_BY_DEFAULT'] = https_enabled\n\
      \    call_command('initial_default_cluster')\n    cluster = Cluster.objects.get(name='default-main')\n\
      \    ingress_config = cluster.ingress_config\n    assert ingress_config.app_root_domains[0].https_enabled\
      \ is expect\n    assert ingress_config.sub_path_domains[0].https_enabled is\
      \ expect\n    assert ingress_config.app_root_domains[0].name == 'apps1.example.com'\n\
      \    assert ingress_config.sub_path_domains[0].name == 'apps2.example.com'\n\
      \    assert ingress_config.port_map.http == 880\n    assert ingress_config.port_map.https\
      \ == 8443\n    assert cluster.default_tolerations == [{'effect': 'NoSchedule',\
      \ 'key': 'dedicated', 'operator': 'Equal', 'value': 'bkSaas'}]\n    assert cluster.default_node_selector\
      \ == {'dedicated': 'bkSaas'}\n    urls = APIServer.objects.filter(cluster=cluster).values_list('host',\
      \ flat=True)\n    assert set(urls) == {'https://kubernetes.default.svc.cluster.localroot',\
      \ 'https://10.0.0.1'}"
    code_lines: 28
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 74
    line: 47
    message: Complexity 10 exceeds threshold 10
    name: test_init_cluster
    severity: acceptable
    signature: 'def test_init_cluster ( https_enabled, expect ) :'
  apiserver/paasng/tests/paas_wl/infras/cluster/test_models.py:
  - code: "\ndef test_domains(self, region):\n    ingress_config = {'app_root_domains':\
      \ ['foo.com', {'name': 'bar.com'}, {'name': 'baz.com', 'reserved': True}]}\n\
      \    c: Cluster = Cluster.objects.create(region=region, name='dft', is_default=True,\
      \ ingress_config=ingress_config)\n    c.refresh_from_db()\n    assert isinstance(c.ingress_config,\
      \ IngressConfig)\n    assert len(c.ingress_config.app_root_domains) == 3\n \
      \   assert all((isinstance(domain, Domain) for domain in c.ingress_config.app_root_domains))\n\
      \    assert c.ingress_config.app_root_domains[0].name == 'foo.com'\n    assert\
      \ c.ingress_config.app_root_domains[0].reserved is False\n    assert c.ingress_config.app_root_domains[1].name\
      \ == 'bar.com'\n    assert c.ingress_config.app_root_domains[1].reserved is\
      \ False\n    assert c.ingress_config.app_root_domains[2].name == 'baz.com'\n\
      \    assert c.ingress_config.app_root_domains[2].reserved is True"
    code_lines: 14
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 143
    line: 130
    message: Complexity 10 exceeds threshold 10
    name: test_domains
    severity: acceptable
    signature: 'def test_domains ( self, region ) :'
  apiserver/paasng/tests/paas_wl/infras/resource_templates/test_addons.py:
  - code: "\ndef test_secret_volume(self, wl_app, secret_volume_addon_template):\n\
      \    assert len(AddonManager(wl_app).get_volumes()) == 0\n    secret_volume_addon_template.link_to_app(wl_app)\n\
      \    volumes = AddonManager(wl_app).get_volumes()\n    assert len(volumes) ==\
      \ 1\n    volume = volumes[0]\n    assert volume.name == 'secret'\n    assert\
      \ volume.secret\n    assert volume.secret.secretName == 'the-secret'\n    assert\
      \ len(volume.secret.items) == 1\n    assert volume.secret.items[0].key == 'a'\n\
      \    assert volume.secret.items[0].path == 'secret/a'\n    assert volume.secret.items[0].mode\
      \ == 420"
    code_lines: 15
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 95
    line: 81
    message: Complexity 10 exceeds threshold 10
    name: test_secret_volume
    severity: acceptable
    signature: 'def test_secret_volume ( self, wl_app, secret_volume_addon_template
      ) :'
  apiserver/paasng/tests/paasng/accessories/servicehub/remote/test_manager.py:
  - code: "\n@pytest.mark.parametrize(('specs', 'ok'), [({}, True), ({'version': 'sth-wrong'},\
      \ False), ({'version': '1'}, True)])\ndef test_bind_with_specs(self, store,\
      \ bk_module, bk_service_ver, specs, ok):\n    mgr = RemoteServiceMgr(store=store)\n\
      \    assert mgr.module_is_bound_with(bk_service_ver, bk_module) is False\n \
      \   if ok:\n        mgr.bind_service(bk_service_ver, bk_module, specs=specs.copy())\n\
      \    else:\n        with pytest.raises(BindServiceNoPlansError):\n         \
      \   mgr.bind_service(bk_service_ver, bk_module, specs=specs.copy())\n    assert\
      \ mgr.module_is_bound_with(bk_service_ver, bk_module) is ok\n    if ok and specs:\n\
      \        for env in bk_module.envs.all():\n            for rel in mixed_service_mgr.list_unprovisioned_rels(env.engine_app,\
      \ bk_service_ver):\n                plan = rel.get_plan()\n                assert\
      \ len(plan.specifications) > 0\n                for (k, v) in specs.items():\n\
      \                    assert plan.specifications[k] == v"
    code_lines: 25
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 248
    line: 224
    message: Complexity 11 exceeds threshold 10
    name: test_bind_with_specs
    severity: warning
    signature: 'def test_bind_with_specs ( self, store, bk_module, bk_service_ver,
      specs, ok ) :'
  - code: "\n@mock.patch('paasng.accessories.servicehub.services.get_application_cluster')\n\
      @pytest.mark.parametrize(('cluster_name', 'zone_name', 'plans', 'expected_zone_name',\
      \ 'ok'), [(None, None, [gen_plan('r1', dict(app_zone='universal'), {})], 'universal',\
      \ True), ('A', 'universal', [gen_plan('r1', dict(app_zone='universal'), {})],\
      \ 'universal', True), ('A', 'ZA', [gen_plan('r1', dict(app_zone='ZA'), {})],\
      \ 'ZA', True), ('A', 'ZA', [gen_plan('r1', dict(app_zone='ZB'), {}), gen_plan('r1',\
      \ dict(app_zone='ZA'), {})], 'ZA', True), (None, None, [gen_plan('r1', dict(app_zone='sth-wrong'),\
      \ {})], 'universal', False), ('A', 'universal', [gen_plan('r1', dict(app_zone='ZA'),\
      \ {})], 'ZA', False), ('A', 'ZA', [gen_plan('r1', dict(app_zone='universal'),\
      \ {})], 'universal', False), ('A', 'ZA', [gen_plan('r1', dict(app_zone='ZB'),\
      \ {})], 'ZB', False)])\ndef test_bound_with_diff_app_zone(self, g_cluster, store,\
      \ bk_module, bk_service_ver_zone, cluster_name, zone_name, plans, expected_zone_name,\
      \ ok):\n    \"\"\"测试不同环境绑定不一样的 plan, 依赖 specifications[app_zone]\"\"\"\n   \
      \ g_cluster.return_value = Cluster(name=cluster_name, is_default=True)\n   \
      \ mgr = RemoteServiceMgr(store=store)\n    bk_service_ver_zone.plans = plans\n\
      \    assert mgr.module_is_bound_with(bk_service_ver_zone, bk_module) is False\n\
      \    with override_settings(APP_ZONE_CLUSTER_MAPPINGS={cluster_name: zone_name}\
      \ if zone_name else {}):\n        if ok:\n            mgr.bind_service(bk_service_ver_zone,\
      \ bk_module, {})\n        else:\n            with pytest.raises(BindServiceNoPlansError):\n\
      \                mgr.bind_service(bk_service_ver_zone, bk_module, {})\n    assert\
      \ mgr.module_is_bound_with(bk_service_ver_zone, bk_module) is ok\n    if ok:\n\
      \        with mock.patch.object(store, 'get') as get_svc:\n            get_svc.return_value\
      \ = asdict(bk_service_ver_zone)\n            for env in bk_module.envs.all():\n\
      \                for rel in mgr.list_unprovisioned_rels(env.engine_app, bk_service_ver_zone):\n\
      \                    plan = rel.get_plan()\n                    assert len(plan.specifications)\
      \ > 0\n                    assert plan.specifications['app_zone'] == expected_zone_name"
    code_lines: 63
    comment_lines: 0
    complexity: 10
    description: 测试不同环境绑定不一样的 plan, 依赖 specifications[app_zone]
    end_line: 396
    line: 334
    message: Complexity 10 exceeds threshold 10
    name: test_bound_with_diff_app_zone
    severity: acceptable
    signature: 'def test_bound_with_diff_app_zone ( self, g_cluster, store, bk_module,
      bk_service_ver_zone, cluster_name, zone_name, plans, expected_zone_name, ok
      ) :'
  - code: "\n@mock.patch('paas_wl.workloads.networking.egress.shim.get_cluster_egress_info')\n\
      @mock.patch('paasng.accessories.servicehub.remote.client.RemoteServiceClient.provision_instance')\n\
      @pytest.mark.parametrize('plans', [[gen_plan('r1', {'app_zone': 'universal'},\
      \ {})], [gen_plan('r1', {'app_zone': 'universal'}, {'restricted_envs': ['stag']}),\
      \ gen_plan('r1', {'app_zone': 'universal'}, {'restricted_envs': ['prod']})]])\n\
      def test_provision(self, mocked_provision, get_cluster_egress_info, store, bk_module,\
      \ bk_service_ver, plans):\n    \"\"\"Test service instance provision\"\"\"\n\
      \    get_cluster_egress_info.return_value = {'egress_ips': ['1.1.1.1'], 'digest_version':\
      \ 'foo'}\n    mgr = RemoteServiceMgr(store=store)\n    bk_service_ver.plans\
      \ = plans\n    mgr.bind_service(bk_service_ver, bk_module)\n    with mock.patch.object(mgr,\
      \ 'get') as get_service:\n        get_service.return_value = bk_service_ver\n\
      \        for env in bk_module.envs.all():\n            expected_plan = plans[1]\
      \ if env.environment == 'prod' and len(plans) == 2 else plans[0]\n         \
      \   for rel in mgr.list_unprovisioned_rels(env.engine_app):\n              \
      \  assert rel.is_provisioned() is False\n                rel.provision()\n \
      \               assert rel.is_provisioned() is True\n                assert\
      \ str(rel.db_obj.service_id) == bk_service_ver.uuid\n                assert\
      \ str(rel.db_obj.plan_id) == expected_plan.uuid\n                assert mocked_provision.called\n\
      \                assert len(mocked_provision.call_args[0]) == 3\n          \
      \      assert bool(all(mocked_provision.call_args[0]))\n                assert\
      \ mocked_provision.call_args[1]['params']['username'] == rel.db_engine_app.name"
    code_lines: 38
    comment_lines: 0
    complexity: 13
    description: Test service instance provision
    end_line: 147
    line: 110
    message: Complexity 13 exceeds threshold 10
    name: test_provision
    severity: warning
    signature: 'def test_provision ( self, mocked_provision, get_cluster_egress_info,
      store, bk_module, bk_service_ver, plans ) :'
  apiserver/paasng/tests/paasng/bk_plugins/pluginscenter/release/test_executor.py:
  - code: "\ndef test_execute_current_stage(self, release, stage_class_setter):\n\
      \    executor = PluginReleaseExecutor(release)\n    assert release.current_stage.status\
      \ == PluginReleaseStatus.INITIAL\n    assert release.current_stage.stage_id\
      \ == 'stage1'\n    executor.execute_current_stage('')\n    assert release.current_stage.stage_id\
      \ == 'stage1'\n    assert release.current_stage.status == PluginReleaseStatus.PENDING\n\
      \    with pytest.raises(APIError) as exc:\n        executor.execute_current_stage('')\n\
      \    assert exc.value.code == error_codes.EXECUTE_STAGE_ERROR.code\n    assert\
      \ exc.value.message == error_codes.EXECUTE_STAGE_ERROR.f(_('当前阶段已被执行, 不能重复触发已执行的阶段')).message\n\
      \    release.current_stage.reset()\n    stage_class_setter.return_value = build_stage_controller(PluginReleaseStatus.SUCCESSFUL)\n\
      \    assert release.current_stage.stage_id == 'stage1'\n    executor.execute_current_stage('')\n\
      \    assert release.current_stage.stage_id == 'stage1'\n    assert release.current_stage.status\
      \ == PluginReleaseStatus.SUCCESSFUL"
    code_lines: 24
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 177
    line: 154
    message: Complexity 10 exceeds threshold 10
    name: test_execute_current_stage
    severity: acceptable
    signature: 'def test_execute_current_stage ( self, release, stage_class_setter
      ) :'
  apiserver/paasng/tests/paasng/bk_plugins/pluginscenter/test_integration.py:
  - code: "\n@pytest.mark.usefixtures('_setup_release_stages', '_setup_bk_user')\n\
      def test_release_version(self, thirdparty_client, pd, plugin, api_client, iam_policy_client):\n\
      \    assert PluginRelease.objects.filter(plugin=plugin, type='prod', status__in=PluginReleaseStatus.running_status()).count()\
      \ == 0\n    with mock.patch('paasng.bk_plugins.pluginscenter.shim.get_plugin_repo_accessor')\
      \ as get_plugin_repo_accessor:\n        get_plugin_repo_accessor().extract_smart_revision.return_value\
      \ = 'hash'\n        resp = api_client.post(f'/api/bkplugins/{pd.identifier}/plugins/{plugin.id}/releases/',\
      \ data={'type': 'prod', 'source_version_type': 'branch', 'source_version_name':\
      \ 'foo', 'version': '0.0.1', 'comment': '...', 'semver_type': 'patch'})\n  \
      \      assert resp.status_code == 201\n    release = PluginRelease.objects.get(plugin=plugin)\n\
      \    assert release.current_stage.stage_id == 'market'\n    assert release.current_stage.status\
      \ == PluginReleaseStatus.PENDING\n    resp = api_client.post(f'/api/bkplugins/{pd.identifier}/plugins/{plugin.id}/releases/{release.id}/next/')\n\
      \    assert resp.status_code == 400\n    assert resp.json() == {'code': error_codes.EXECUTE_STAGE_ERROR.code,\
      \ 'detail': error_codes.EXECUTE_STAGE_ERROR.f(_('当前阶段未执行成功, 不允许进入下一阶段')).message}\n\
      \    resp = api_client.post(f'/api/bkplugins/{pd.identifier}/plugins/{plugin.id}/market/',\
      \ data={'category': '...', 'introduction': '...', 'description': '...', 'contact':\
      \ '...'})\n    assert resp.status_code == 200\n    release.refresh_from_db()\n\
      \    assert release.current_stage.status == PluginReleaseStatus.SUCCESSFUL\n\
      \    counter = 0\n    \n    def deploy_action_side_effect(*args, **kwargs):\n\
      \        nonlocal counter\n        counter += 1\n        if counter == 1:\n\
      \            return {'deploy_id': '...', 'status': 'pending', 'detail': '',\
      \ 'steps': [{'id': 'step-1', 'name': '步骤1', 'status': 'pending'}]}\n       \
      \ elif counter == 2:\n            return {'deploy_id': '...', 'status': 'successful',\
      \ 'detail': '', 'steps': [{'id': 'step-1', 'name': '步骤1', 'status': 'successful'}]}\n\
      \        else:\n            return {'logs': ['1', '2', '3'], 'finished': True}\n\
      \    thirdparty_client.call.side_effect = deploy_action_side_effect\n    resp\
      \ = api_client.post(f'/api/bkplugins/{pd.identifier}/plugins/{plugin.id}/releases/{release.id}/next/')\n\
      \    assert resp.status_code == 200\n    release.refresh_from_db()\n    release.current_stage.refresh_from_db()\n\
      \    assert release.current_stage.stage_id == 'deploy'\n    assert release.current_stage.api_detail\
      \ == {'deploy_id': '...', 'status': 'pending', 'detail': '', 'steps': [{'id':\
      \ 'step-1', 'name': '步骤1', 'status': 'pending'}]}\n    resp = api_client.get(f'/api/bkplugins/{pd.identifier}/plugins/{plugin.id}/releases/{release.id}/stages/{release.current_stage.stage_id}/')\n\
      \    assert resp.json() == {'stage_id': 'deploy', 'stage_name': '部署', 'status':\
      \ 'pending', 'fail_message': '', 'invoke_method': 'deployAPI', 'status_polling_method':\
      \ 'api', 'detail': {'steps': [{'id': 'step-1', 'name': '步骤1', 'status': 'successful'}],\
      \ 'finished': True, 'logs': ['1', '2', '3']}}\n    release.refresh_from_db()\n\
      \    assert release.current_stage.status == PluginReleaseStatus.SUCCESSFUL\n\
      \    assert release.status == PluginReleaseStatus.SUCCESSFUL\n    release.current_stage.status\
      \ = PluginReleaseStatus.FAILED\n    release.current_stage.operator = 'xxxxxx'\n\
      \    release.current_stage.save(update_fields=['status', 'operator'])\n    assert\
      \ release.status == PluginReleaseStatus.SUCCESSFUL"
    code_lines: 131
    comment_lines: 0
    complexity: 18
    description: ''
    end_line: 312
    line: 182
    message: Complexity 18 exceeds threshold 10
    name: test_release_version
    severity: high_risk
    signature: 'def test_release_version ( self, thirdparty_client, pd, plugin, api_client,
      iam_policy_client ) :'
  apiserver/paasng/tests/paasng/infras/accounts/test_models.py:
  - code: "\ndef test_match_different_scope(self):\n    scope = Scope.parse_from_str('group:v3-test-group')\n\
      \    assert scope.type == ScopeType.GROUP\n    assert scope.item == 'v3-test-group'\n\
      \    scope = Scope.parse_from_str('project:admin/Skynet')\n    assert scope.type\
      \ == ScopeType.PROJECT\n    assert scope.item == 'admin/Skynet'\n    scope =\
      \ Scope.parse_from_str('project:admin_yu/Sky-net')\n    assert scope.type ==\
      \ ScopeType.PROJECT\n    assert scope.item == 'admin_yu/Sky-net'\n    scope\
      \ = Scope.parse_from_str('user:user')\n    assert scope.type == ScopeType.USER\n\
      \    assert scope.item == 'user'\n    scope = Scope.parse_from_str('api')\n\
      \    assert scope.type == ScopeType.USER\n    assert scope.item == 'user'\n\
      \    scope = Scope.parse_from_str('')\n    assert scope.type == ScopeType.USER\n\
      \    assert scope.item == 'user'"
    code_lines: 24
    comment_lines: 0
    complexity: 13
    description: ''
    end_line: 48
    line: 25
    message: Complexity 13 exceeds threshold 10
    name: test_match_different_scope
    severity: warning
    signature: 'def test_match_different_scope ( self ) :'
  apiserver/paasng/tests/paasng/misc/monitoring/metrics/test_client.py:
  - code: "\ndef test_get_by_container_name(self):\n    \"\"\"测试 对象转换 dict\"\"\"\n\
      \    pr = PromResult.from_resp(raw_resp=self.fake_range_result)\n    r1 = pr.get_raw_by_container_name('ieod-bkapp-career-stag')\n\
      \    assert r1\n    assert len(r1['values']) == 4\n    r2 = pr.get_raw_by_container_name('cl5')\n\
      \    assert r2\n    assert len(r2['values']) == 3\n    assert r1['metric'] ==\
      \ {'container_name': 'ieod-bkapp-career-stag'}\n    assert r1['values'] == [[1590000844,\
      \ '0.0003452615666667214'], [1590001444, '0.00040326460000083365'], [1590002044,\
      \ '0.0003675630666667947'], [1590003044, '0.0003675630666667947']]\n    r3 =\
      \ pr.get_raw_by_container_name('cxxxx')\n    assert r3 is None\n    r4 = pr.get_raw_by_container_name()\n\
      \    assert r4\n    assert len(r4['values']) == 3"
    code_lines: 26
    comment_lines: 0
    complexity: 10
    description: 测试 对象转换 dict
    end_line: 119
    line: 94
    message: Complexity 10 exceeds threshold 10
    name: test_get_by_container_name
    severity: acceptable
    signature: 'def test_get_by_container_name ( self ) :'
  - code: "\ndef test_get_by_container_name(self):\n    \"\"\"测试对象转换为 dict\"\"\"\n\
      \    pr = BkPromResult.from_series(self.fake_range_series)\n    r1 = pr.get_raw_by_container_name('celery-proc')\n\
      \    assert r1\n    assert len(r1['values']) == 4\n    r2 = pr.get_raw_by_container_name('web-proc')\n\
      \    assert r2\n    assert len(r2['values']) == 3\n    assert r1['metric'] ==\
      \ {'container_name': 'celery-proc'}\n    assert r1['values'] == [[1673257280,\
      \ '1073741824'], [1673257290, '1073741824'], [1673257300, '1073741824'], [1673257310,\
      \ '1073741824']]\n    r3 = pr.get_raw_by_container_name('xxx')\n    assert r3\
      \ is None\n    r4 = pr.get_raw_by_container_name()\n    assert r4\n    assert\
      \ len(r4['values']) == 3"
    code_lines: 27
    comment_lines: 0
    complexity: 10
    description: 测试对象转换为 dict
    end_line: 224
    line: 198
    message: Complexity 10 exceeds threshold 10
    name: test_get_by_container_name
    severity: acceptable
    signature: 'def test_get_by_container_name ( self ) :'
  apiserver/paasng/tests/paasng/platform/applications/test_lapp.py:
  - code: "\n@pytest.mark.parametrize(('is_lapp', 'data', 'expected'), [(False, {},\
      \ {'bk_error_msg': '{code} not found', 'bk_error_code': '1301100', 'result':\
      \ False, 'data': ''}), (True, {'app_name': 'Bar', 'introduction': 'introduction',\
      \ 'developers': ['admin', 'blueking']}, {'bk_error_msg': '', 'bk_error_code':\
      \ '0', 'result': True, 'data': {'light_app_code': '{light_app_code}', 'app_name':\
      \ '{app_name}', 'introduction': 'introduction', 'developers': ['admin', 'blueking']}}),\
      \ (True, {'app_name': 'Bar', 'introduction': 'introduction', 'developers': ['admin',\
      \ 'blueking'], 'app_tag': ''}, {'bk_error_msg': '', 'bk_error_code': '0', 'result':\
      \ True, 'data': {'light_app_code': '{light_app_code}', 'app_name': '{app_name}',\
      \ 'introduction': 'introduction', 'developers': ['admin', 'blueking']}})])\n\
      def test_edit(self, legacy_tag, legacy_app, sys_light_api_client, is_lapp, data,\
      \ expected):\n    with legacy_db.session_scope() as session:\n        AppAdaptor(session).update(code=legacy_app.code,\
      \ data={'is_lapp': is_lapp})\n    data = {'light_app_code': legacy_app.code,\
      \ **data}\n    if 'app_tag' in data:\n        data['app_tag'] = legacy_tag.code\n\
      \    response = sys_light_api_client.patch('/sys/api/light-applications/', data=data)\n\
      \    assert response.status_code == 200\n    result = response.json()\n    result_data\
      \ = result.pop('data')\n    expected_data = expected.pop('data')\n    assert\
      \ result.pop('bk_error_msg') == expected.pop('bk_error_msg').format(code=legacy_app.code)\n\
      \    if expected['result']:\n        for (k, v) in expected_data.items():\n\
      \            if isinstance(v, str):\n                assert result_data[k] ==\
      \ v.format(**data)\n            else:\n                assert result_data[k]\
      \ == v\n    assert result == expected"
    code_lines: 70
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 244
    line: 175
    message: Complexity 10 exceeds threshold 10
    name: test_edit
    severity: acceptable
    signature: 'def test_edit ( self, legacy_tag, legacy_app, sys_light_api_client,
      is_lapp, data, expected ) :'
  apiserver/paasng/tests/paasng/platform/bkapp_model/entities_syncer/test_proc_env_overlays.py:
  - code: "\ndef test_integrated(self, bk_module, proc_web, proc_celery):\n    ret\
      \ = sync_env_overlays_replicas(bk_module, [ReplicasOverlay(env_name='prod',\
      \ process='web', count=2), ReplicasOverlay(env_name='prod', process='worker',\
      \ count=2)], manager=fieldmgr.FieldMgrName.APP_DESC)\n    assert ret.updated_num\
      \ == 1\n    assert ret.created_num == 1\n    assert ret.deleted_num == 1\n \
      \   assert get_overlay_obj(proc_web, 'prod').target_replicas == 2\n    assert\
      \ get_overlay_obj(proc_celery, 'prod').target_replicas == 2\n    assert get_overlay_obj(proc_web,\
      \ 'stag').target_replicas is None\n    fieldmgr.FieldManager(bk_module, fieldmgr.f_overlay_replicas(proc_web.name,\
      \ 'prod')).set(fieldmgr.FieldMgrName.WEB_FORM)\n    sync_env_overlays_replicas(bk_module,\
      \ NOTSET, manager=fieldmgr.FieldMgrName.APP_DESC)\n    assert get_overlay_obj(proc_web,\
      \ 'prod').target_replicas == 2\n    assert get_overlay_obj(proc_celery, 'prod').target_replicas\
      \ is None\n    assert get_overlay_obj(proc_web, 'stag').target_replicas is None\n\
      \    sync_env_overlays_replicas(bk_module, [], manager=fieldmgr.FieldMgrName.APP_DESC)\n\
      \    assert get_overlay_obj(proc_web, 'prod').target_replicas is None"
    code_lines: 30
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 98
    line: 69
    message: Complexity 11 exceeds threshold 10
    name: test_integrated
    severity: warning
    signature: 'def test_integrated ( self, bk_module, proc_web, proc_celery ) :'
  - code: "\ndef test_normal(self, bk_module, proc_web, proc_celery):\n    ret = sync_env_overlays_autoscalings(bk_module,\
      \ [AutoscalingOverlay(env_name='prod', process='web', min_replicas=1, max_replicas=2,\
      \ policy='default'), AutoscalingOverlay(env_name='prod', process='worker', min_replicas=2,\
      \ max_replicas=5, policy='default')], manager=fieldmgr.FieldMgrName.APP_DESC)\n\
      \    assert ret.updated_num == 1\n    assert ret.created_num == 1\n    assert\
      \ ret.deleted_num == 1\n    assert get_overlay_obj(proc_web, 'prod').autoscaling\n\
      \    assert get_overlay_obj(proc_web, 'prod').scaling_config == AutoscalingConfig(min_replicas=1,\
      \ max_replicas=2, policy='default')\n    assert get_overlay_obj(proc_celery,\
      \ 'prod').autoscaling\n    assert get_overlay_obj(proc_celery, 'prod').scaling_config\
      \ == AutoscalingConfig(min_replicas=2, max_replicas=5, policy='default')\n \
      \   assert get_overlay_obj(proc_web, 'stag').autoscaling is None\n    assert\
      \ get_overlay_obj(proc_web, 'stag').scaling_config is None"
    code_lines: 27
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 185
    line: 159
    message: Complexity 10 exceeds threshold 10
    name: test_normal
    severity: acceptable
    signature: 'def test_normal ( self, bk_module, proc_web, proc_celery ) :'
  apiserver/paasng/tests/paasng/platform/bkapp_model/entities_syncer/test_processes.py:
  - code: "\ndef test_integrated(self, bk_module, proc_web, proc_celery):\n    assert\
      \ ModuleProcessSpec.objects.filter(module=bk_module).count() == 2\n    ret =\
      \ sync_processes(bk_module, [Process(name=proc_web.name, replicas=1, command=['./start.sh'],\
      \ res_quota_plan='4C1G', target_port=30000, probes=ProbeSet(liveness=Probe(http_get=HTTPGetAction(port='${PORT}',\
      \ path='/healthz'), initial_delay_seconds=30, timeout_seconds=5, period_seconds=5,\
      \ success_threshold=1, failure_threshold=3), readiness=Probe(tcp_socket=TCPSocketAction(port=30000))),\
      \ services=[ProcService(name='web', target_port=30000, exposed_type={'name':\
      \ 'bk/http'})]), Process(name='sleep', replicas=1, command=['bash'], res_quota_plan='4C2G',\
      \ args=['-c', '100'], proc_command='sleep 100', autoscaling=AutoscalingConfig(min_replicas=2,\
      \ max_replicas=10, policy='default'))], FieldMgrName.APP_DESC)\n    assert ret.updated_num\
      \ == 1\n    assert ret.created_num == 1\n    assert ret.deleted_num == 1\n \
      \   assert ModuleProcessSpec.objects.filter(module=bk_module).count() == 2\n\
      \    specs = ModuleProcessSpec.objects.filter(module=bk_module, name=proc_web.name)\n\
      \    assert specs.count() == 1\n    spec = specs.first()\n    assert spec.port\
      \ == 30000\n    assert spec.probes.liveness.http_get.port == '${PORT}'\n   \
      \ assert spec.probes.liveness.initial_delay_seconds == 30\n    assert spec.probes.liveness.period_seconds\
      \ == 5\n    assert spec.probes.readiness.tcp_socket.port == 30000\n    assert\
      \ spec.plan_name == '4C1G'\n    assert spec.services[0].exposed_type.name ==\
      \ 'bk/http'\n    spec = ModuleProcessSpec.objects.get(module=bk_module, name='sleep')\n\
      \    assert spec.proc_command == 'sleep 100'\n    assert spec.command is None\n\
      \    assert spec.target_replicas == 1\n    assert spec.scaling_config.max_replicas\
      \ == 10\n    assert spec.scaling_config.min_replicas == 2\n    assert spec.plan_name\
      \ == '4C2G'\n    assert spec.services is None"
    code_lines: 63
    comment_lines: 0
    complexity: 21
    description: ''
    end_line: 99
    line: 37
    message: Complexity 21 exceeds threshold 10
    name: test_integrated
    severity: critical
    signature: 'def test_integrated ( self, bk_module, proc_web, proc_celery ) :'
  apiserver/paasng/tests/paasng/platform/engine/deploy/bg_build/test_utils.py:
  - code: "\ndef test_generate_env_vars_without_metadata(self, build_proc, wl_app):\n\
      \    env_vars = generate_builder_env_vars(build_proc, {})\n    bucket = settings.BLOBSTORE_BUCKET_APP_SOURCE\n\
      \    cache_path = f'{wl_app.region}/home/{wl_app.name}/cache'\n    assert env_vars.pop('TAR_PATH')\
      \ == f'{bucket}/{build_proc.source_tar_path}', 'TAR_PATH 与预期不符'\n    assert\
      \ env_vars.pop('PUT_PATH') == f'{bucket}/{generate_slug_path(build_proc)}',\
      \ 'PUT_PATH 与预期不符'\n    assert env_vars.pop('CACHE_PATH') == f'{bucket}/{cache_path}',\
      \ 'CACHE_PATH 与预期不符'\n    if settings.BUILD_EXTRA_ENV_VARS:\n        for (k,\
      \ v) in settings.BUILD_EXTRA_ENV_VARS.items():\n            assert env_vars.pop(k)\
      \ == v, f'{k} 与预期不符'\n    if settings.PYTHON_BUILDPACK_PIP_INDEX_URL:\n    \
      \    for (k, v) in get_envs_from_pypi_url(settings.PYTHON_BUILDPACK_PIP_INDEX_URL).items():\n\
      \            assert env_vars.pop(k) == v, f'{k} 与预期不符'"
    code_lines: 13
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 51
    line: 39
    message: Complexity 10 exceeds threshold 10
    name: test_generate_env_vars_without_metadata
    severity: acceptable
    signature: 'def test_generate_env_vars_without_metadata ( self, build_proc, wl_app
      ) :'
  apiserver/paasng/tests/paasng/platform/engine/deploy/test_building.py:
  - code: "\ndef test_start_build(self, builder_class, bk_cnative_app, bk_module_full,\
      \ bk_deployment_full, model_resource):\n    desc_handler = get_deploy_desc_handler(None,\
      \ {'web': 'gunicorn'})\n    with mock.patch('paasng.platform.engine.deploy.building.get_deploy_desc_handler_by_version',\
      \ return_value=desc_handler), mock.patch('paasng.platform.engine.deploy.building.{}.compress_and_upload'.format(builder_class.__name__)),\
      \ mock.patch('paasng.platform.engine.deploy.building.BuildProcessPoller') as\
      \ mocked_poller, mock.patch('paasng.platform.engine.utils.output.RedisChannelStream')\
      \ as mocked_stream, mock.patch('paasng.platform.engine.deploy.building.{}.launch_build_processes'.format(builder_class.__name__))\
      \ as launch_build_processes:\n        faked_build_process_id = uuid.uuid4().hex\n\
      \        launch_build_processes.return_value = faked_build_process_id\n    \
      \    attach_all_phases(sender=bk_deployment_full.app_environment, deployment=bk_deployment_full)\n\
      \        builder = builder_class.from_deployment_id(bk_deployment_full.id)\n\
      \        builder.start()\n        deployment = Deployment.objects.get(pk=bk_deployment_full.id)\n\
      \        assert deployment.status == JobStatus.PENDING.value\n        assert\
      \ deployment.build_process_id.hex == faked_build_process_id\n        assert\
      \ deployment.err_detail is None\n        assert launch_build_processes.called\n\
      \        (source_tar_path, bkapp_revision_id) = launch_build_processes.call_args[0]\n\
      \        assert source_tar_path != ''\n        assert bkapp_revision_id is not\
      \ None\n        assert mocked_stream().write_title.called\n        assert mocked_poller.start.called\n\
      \        assert mocked_poller.start.call_args[0][0] == {'build_process_id':\
      \ deployment.build_process_id.hex, 'deployment_id': deployment.id}"
    code_lines: 42
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 198
    line: 157
    message: Complexity 10 exceeds threshold 10
    name: test_start_build
    severity: acceptable
    signature: 'def test_start_build ( self, builder_class, bk_cnative_app, bk_module_full,
      bk_deployment_full, model_resource ) :'
  - code: "\ndef test_start_normal(self, builder_class, bk_deployment_full):\n   \
      \ with mock.patch('paasng.platform.engine.configurations.source_file.MetaDataFileReader.get_procfile')\
      \ as mocked_get_procfile, mock.patch('paasng.platform.engine.deploy.building.{}.compress_and_upload'.format(builder_class.__name__)),\
      \ mock.patch('paasng.platform.engine.deploy.building.BuildProcessPoller') as\
      \ mocked_poller, mock.patch('paasng.platform.engine.utils.output.RedisChannelStream')\
      \ as mocked_stream, mock.patch('paasng.platform.engine.deploy.building.{}.launch_build_processes'.format(builder_class.__name__))\
      \ as launch_build_processes:\n        mocked_get_procfile.return_value = {'web':\
      \ 'gunicorn'}\n        faked_build_process_id = uuid.uuid4().hex\n        launch_build_processes.return_value\
      \ = faked_build_process_id\n        attach_all_phases(sender=bk_deployment_full.app_environment,\
      \ deployment=bk_deployment_full)\n        builder = builder_class.from_deployment_id(bk_deployment_full.id)\n\
      \        builder.start()\n        deployment = Deployment.objects.get(pk=bk_deployment_full.id)\n\
      \        assert deployment.status == JobStatus.PENDING.value\n        assert\
      \ deployment.build_process_id.hex == faked_build_process_id\n        assert\
      \ deployment.err_detail is None\n        assert launch_build_processes.called\n\
      \        (source_tar_path, bkapp_revision_id) = launch_build_processes.call_args[0]\n\
      \        assert source_tar_path != ''\n        assert bkapp_revision_id is None\n\
      \        assert mocked_stream().write_title.called\n        assert mocked_poller.start.called\n\
      \        assert mocked_poller.start.call_args[0][0] == {'build_process_id':\
      \ deployment.build_process_id.hex, 'deployment_id': deployment.id}"
    code_lines: 41
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 138
    line: 98
    message: Complexity 10 exceeds threshold 10
    name: test_start_normal
    severity: acceptable
    signature: 'def test_start_normal ( self, builder_class, bk_deployment_full )
      :'
  apiserver/paasng/tests/paasng/platform/mgrlegacy/cnative/test_migrators.py:
  - code: "\ndef test_migrate_and_rollback(self, bk_app, bk_module, image_repository_module,\
      \ migration_process, cnb_builder, cnb_runner, buildpack, slugbuilder, slugrunner):\n\
      \    BuildConfigMigrator(migration_process).migrate()\n    config = BuildConfig.objects.get(module=bk_module)\n\
      \    assert config.buildpacks.filter(id=buildpack.id).exists()\n    assert config.buildpack_builder\
      \ == cnb_builder\n    assert config.buildpack_runner == cnb_runner\n    image_config\
      \ = BuildConfig.objects.get(module=image_repository_module)\n    assert image_config.image_repository\
      \ == 'https://example.com/image'\n    assert image_config.build_method == RuntimeType.CUSTOM_IMAGE.value\n\
      \    assert Module.objects.get(id=image_repository_module.id).source_origin\
      \ == SourceOrigin.CNATIVE_IMAGE.value\n    BuildConfigMigrator(migration_process).rollback()\n\
      \    config = BuildConfig.objects.get(module=bk_module)\n    assert config.buildpacks.filter(id=buildpack.id).exists()\n\
      \    assert config.buildpack_builder == slugbuilder\n    assert config.buildpack_runner\
      \ == slugrunner\n    image_config = BuildConfig.objects.get(module=image_repository_module)\n\
      \    assert image_config.image_repository is None\n    legacy_image_repository_module\
      \ = Module.objects.get(id=image_repository_module.id)\n    assert legacy_image_repository_module.source_origin\
      \ == SourceOrigin.IMAGE_REGISTRY.value\n    assert legacy_image_repository_module.get_source_obj().get_repo_url()\
      \ == 'https://example.com/image'"
    code_lines: 34
    comment_lines: 0
    complexity: 13
    description: ''
    end_line: 136
    line: 103
    message: Complexity 13 exceeds threshold 10
    name: test_migrate_and_rollback
    severity: warning
    signature: 'def test_migrate_and_rollback ( self, bk_app, bk_module, image_repository_module,
      migration_process, cnb_builder, cnb_runner, buildpack, slugbuilder, slugrunner
      ) :'
  apiserver/paasng/tests/paasng/platform/modules/test_helpers.py:
  - code: "\n@pytest.mark.parametrize(('slugbuilder_attrs', 'buildpack_attrs', 'linked',\
      \ 'ok'), [(dict(name=generate_random_string(12)), dict(name=generate_random_string(16)),\
      \ False, False), (dict(region=generate_random_string()), dict(), False, False),\
      \ (dict(), dict(region=generate_random_string()), False, False), (dict(name=generate_random_string(12)),\
      \ dict(name=generate_random_string(16)), True, True), (dict(region=generate_random_string()),\
      \ dict(), True, False), (dict(), dict(region=generate_random_string()), True,\
      \ False), (dict(), dict(), True, True)])\ndef test_bind_buildpack(bk_module,\
      \ slugbuilder, slugrunner, buildpack, slugbuilder_attrs, buildpack_attrs, linked,\
      \ ok):\n    for (k, v) in slugbuilder_attrs.items():\n        setattr(slugbuilder,\
      \ k, v)\n        setattr(slugrunner, k, v)\n    for (k, v) in buildpack_attrs.items():\n\
      \        setattr(buildpack, k, v)\n    slugbuilder.buildpacks.clear()\n    slugbuilder.save()\n\
      \    slugrunner.save()\n    buildpack.save()\n    binder = ModuleRuntimeBinder(bk_module)\n\
      \    build_config = bk_module.build_config\n    assert build_config.buildpack_builder\
      \ is None\n    assert build_config.buildpack_runner is None\n    assert slugbuilder.buildpacks.count()\
      \ == 0\n    if linked:\n        slugbuilder.buildpacks.add(buildpack)\n    \
      \    assert slugbuilder.buildpacks.count() == 1\n    if ok:\n        binder.bind_image(slugrunner=slugrunner,\
      \ slugbuilder=slugbuilder)\n        binder.bind_buildpack(buildpack)\n     \
      \   manager = ModuleRuntimeManager(bk_module)\n        assert manager.get_slug_builder(raise_exception=True)\
      \ == slugbuilder\n        assert manager.list_buildpacks() == [buildpack]\n\
      \        binder.bind_buildpack(buildpack)\n        assert bk_module.build_config.buildpacks.count()\
      \ == 1\n    else:\n        with pytest.raises(BindError):\n            binder.bind_image(slugrunner=slugrunner,\
      \ slugbuilder=slugbuilder)\n            binder.bind_buildpack(buildpack)"
    code_lines: 50
    comment_lines: 0
    complexity: 12
    description: ''
    end_line: 121
    line: 72
    message: Complexity 12 exceeds threshold 10
    name: test_bind_buildpack
    severity: warning
    signature: 'def test_bind_buildpack ( bk_module, slugbuilder, slugrunner, buildpack,
      slugbuilder_attrs, buildpack_attrs, linked, ok ) :'
  - code: "\n@pytest.mark.parametrize(('slugbuilder_attrs', 'slugrunner_attrs', 'ok'),\
      \ [(dict(name=generate_random_string(12)), dict(name=generate_random_string(16)),\
      \ False), (dict(region=generate_random_string()), dict(), False), (dict(), dict(region=generate_random_string()),\
      \ False), (dict(), dict(), True)])\ndef test_bind_image(bk_module, slugbuilder,\
      \ slugrunner, slugbuilder_attrs, slugrunner_attrs, ok):\n    for (k, v) in slugbuilder_attrs.items():\n\
      \        setattr(slugbuilder, k, v)\n    for (k, v) in slugrunner_attrs.items():\n\
      \        setattr(slugrunner, k, v)\n    slugbuilder.save()\n    slugrunner.save()\n\
      \    binder = ModuleRuntimeBinder(bk_module)\n    build_config = bk_module.build_config\n\
      \    assert build_config.buildpack_builder is None\n    assert build_config.buildpack_runner\
      \ is None\n    if ok:\n        binder.bind_image(slugrunner, slugbuilder)\n\
      \        manager = ModuleRuntimeManager(bk_module)\n        assert manager.get_slug_builder(raise_exception=True)\
      \ == slugbuilder\n        assert manager.get_slug_runner(raise_exception=True)\
      \ == slugrunner\n        binder.bind_image(slugrunner, slugbuilder)\n      \
      \  build_config.refresh_from_db()\n        assert build_config.buildpack_builder\
      \ == slugbuilder\n        assert build_config.buildpack_runner == slugrunner\n\
      \    else:\n        with pytest.raises(BindError):\n            binder.bind_image(slugrunner,\
      \ slugbuilder)"
    code_lines: 35
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 69
    line: 35
    message: Complexity 10 exceeds threshold 10
    name: test_bind_image
    severity: acceptable
    signature: 'def test_bind_image ( bk_module, slugbuilder, slugrunner, slugbuilder_attrs,
      slugrunner_attrs, ok ) :'
  apiserver/paasng/tests/paasng/platform/sourcectl/test_sourcectl_git.py:
  - code: "\ndef test_list_all_repositories(self, client, github_repo_url, user_credentials):\n\
      \    \n    def mock_list_repo(*args, **kwargs):\n        return [{'owner': {'login':\
      \ 'octocat', 'avatar_url': 'https://github.com/images/error/octocat_happy.gif'},\
      \ 'name': 'Hello-World', 'description': 'This your first repo!', 'html_url':\
      \ 'https://github.com/octocat/Hello-World', 'clone_url': 'https://github.com/octocat/Hello-World.git',\
      \ 'ssh_url': 'git@github.com:octocat/Hello-World.git', 'created_at': '2011-01-26T19:01:12Z',\
      \ 'updated_at': '2011-01-26T19:14:43Z'}, {'owner': {'login': 'octocat', 'avatar_url':\
      \ 'https://github.com/images/error/octocat_happy.gif'}, 'name': 'hello-worId',\
      \ 'description': 'My first repository on GitHub.', 'html_url': 'https://github.com/octocat/hello-worId',\
      \ 'clone_url': 'https://github.com/octocat/hello-worId.git', 'ssh_url': 'git@github.com:octocat/hello-worId.git',\
      \ 'created_at': '2014-01-26T19:01:12Z', 'updated_at': '2014-01-26T19:14:43Z'}]\n\
      \    client.list_repo.side_effect = mock_list_repo\n    ret = GitHubRepoController.list_all_repositories(api_url=github_repo_url,\
      \ **user_credentials)\n    assert len(ret) == 2\n    assert ret[0].namespace\
      \ == 'octocat'\n    assert ret[0].project == 'Hello-World'\n    assert ret[0].description\
      \ == 'This your first repo!'\n    assert ret[0].last_activity_at == datetime.datetime(2011,\
      \ 1, 26, 19, 14, 43, tzinfo=tzutc())\n    assert ret[1].web_url == 'https://github.com/octocat/hello-worId'\n\
      \    assert ret[1].http_url_to_repo == 'https://github.com/octocat/hello-worId.git'\n\
      \    assert ret[1].ssh_url_to_repo == 'git@github.com:octocat/hello-worId.git'\n\
      \    assert ret[1].created_at == datetime.datetime(2014, 1, 26, 19, 1, 12, tzinfo=tzutc())"
    code_lines: 42
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 220
    line: 179
    message: Complexity 10 exceeds threshold 10
    name: test_list_all_repositories
    severity: acceptable
    signature: 'def test_list_all_repositories ( self, client, github_repo_url, user_credentials
      ) :'
  operator/scripts/update_helm_chart.py:
  - code: "\ndef _remove_useless_newline(self):\n    \"\"\"去除 go-yaml unmarshal 中不需要的换行\"\
      \"\"\n    for src_files in filepath_conf.values():\n        for src in src_files:\n\
      \            if not src.endswith('yaml'):\n                continue\n      \
      \      fp = self.chart_source_dir / TMPL_DIR / src\n            try:\n     \
      \           contents = fp.read_text().splitlines()\n            except FileNotFoundError:\n\
      \                print(f'file {src} not exists, auto create...')\n         \
      \       fp.touch()\n                continue\n            for idx in range(len(contents)):\n\
      \                if idx and contents[idx].count('}}') and contents[idx - 1].count('{{')\
      \ - contents[idx - 1].count('}}') == 1:\n                    contents[idx -\
      \ 1] = contents[idx - 1].rstrip() + ' '\n                    contents[idx -\
      \ 1] += contents[idx].lstrip()\n                    contents[idx] = ''\n   \
      \         fp.write_text('\\n'.join([line for line in contents if line]) + '\\\
      n')"
    code_lines: 29
    comment_lines: 0
    complexity: 10
    description: 去除 go-yaml unmarshal 中不需要的换行
    end_line: 617
    line: 589
    message: Complexity 10 exceeds threshold 10
    name: _remove_useless_newline
    severity: acceptable
    signature: 'def _remove_useless_newline ( self ) :'
  svc-rabbitmq/tasks/management/commands/worker.py:
  - code: "\ndef guard(self):\n    logger.info(_('{} guarding cluster at {}').format(self.name,\
      \ self.pid))\n    self.start_event.set()\n    Stat(self).save()\n    logger.info(_('Q\
      \ Cluster-{} running.').format(self.parent_pid))\n    self.schedule()\n    counter\
      \ = 0\n    cycle = Conf.GUARD_CYCLE\n    while not self.stop_event.is_set()\
      \ or not counter:\n        for p in self.pool:\n            with p.timer.get_lock():\n\
      \                if not p.is_alive() or p.timer.value == 0:\n              \
      \      self.reincarnate(p)\n                    continue\n                if\
      \ p.timer.value > 0:\n                    p.timer.value -= cycle\n        if\
      \ not self.monitor.is_alive():\n            self.reincarnate(self.monitor)\n\
      \        if not self.pusher.is_alive():\n            self.reincarnate(self.pusher)\n\
      \        counter += cycle\n        if counter >= 30:\n            counter =\
      \ 0\n            self.schedule()\n        Stat(self).save()\n        sleep(cycle)\n\
      \    self.stop()"
    code_lines: 35
    comment_lines: 0
    complexity: 10
    description: ''
    end_line: 101
    line: 67
    message: Complexity 10 exceeds threshold 10
    name: guard
    severity: acceptable
    signature: 'def guard ( self ) :'
  svc-rabbitmq/vendor/definitions.py:
  - code: "\ndef is_idle(self, ignore_consumer: bool = False, max_idle: Optional[timedelta]\
      \ = None):\n    if not ignore_consumer and self.consumer_count > 0:\n      \
      \  return False\n    if not self.idle_since:\n        return False\n    if self.acks_uncommitted\
      \ > 0:\n        return False\n    if self.messages_unacknowledged > 0:\n   \
      \     return False\n    if self.messages_uncommitted > 0:\n        return False\n\
      \    if self.messages_unconfirmed > 0:\n        return False\n    if max_idle\
      \ and self.idle_since + max_idle > datetime.utcnow():\n        return False\n\
      \    message_stats = self.message_stats\n    if not message_stats:\n       \
      \ return True\n    if message_stats.confirm_details and message_stats.confirm_details.rate\
      \ > 0:\n        return False\n    if message_stats.publish_details and message_stats.publish_details.rate\
      \ > 0:\n        return False\n    return True"
    code_lines: 33
    comment_lines: 0
    complexity: 15
    description: ''
    end_line: 96
    line: 64
    message: Complexity 15 exceeds threshold 10
    name: is_idle
    severity: warning
    signature: 'def is_idle ( self, ignore_consumer: bool = False, max_idle: Optional[timedelta]
      = None ) :'
  svc-rabbitmq/vendor/management/commands/evict_connections.py:
  - code: "\ndef run_once(self, client: Client, max_idle_seconds: int, safe_peer_host:\
      \ typing.List[str], peer_host: typing.List[str], *args, **kwargs):\n    vhost_set\
      \ = self.get_vhost_set(*args, **kwargs)\n    if vhost_set:\n        print(f\"\
      evicting connections in vhosts: {', '.join(vhost_set)}\")\n    safe_peer_host_set\
      \ = set()\n    if safe_peer_host:\n        safe_peer_host_set.update(safe_peer_host)\n\
      \        print(f\"safe peer hosts: {', '.join(safe_peer_host_set)}\")\n    peer_host_set\
      \ = set()\n    if peer_host:\n        peer_host_set.update(peer_host)\n    \
      \    print(f\"evicting connections for peer hosts: {', '.join(peer_host_set)}\"\
      )\n    rest_connections: typing.List[Connection] = []\n    for i in client.connection.list():\n\
      \        connection = Connection(**i)\n        if vhost_set and connection.vhost\
      \ not in vhost_set:\n            continue\n        if peer_host_set and connection.peer_host\
      \ not in peer_host_set:\n            continue\n        if safe_peer_host_set\
      \ and connection.peer_host in safe_peer_host_set:\n            continue\n  \
      \      try:\n            chs = client.connection.channels(connection.name)\n\
      \        except Exception as err:\n            print(f'list channels for connection\
      \ {connection} failed: {err}, check in next time')\n            rest_connections.append(connection)\n\
      \            continue\n        channels = [Channel(**i) for i in chs]\n    \
      \    if not self.has_consumer_channel(channels):\n            print(f'connection\
      \ {connection} is for publisher')\n        elif not self.consumer_channels_idle(channels,\
      \ timedelta(seconds=max_idle_seconds)):\n            print(f'connection {connection}\
      \ is activating, skipped')\n            rest_connections.append(connection)\n\
      \            continue\n        else:\n            print(f'idle connection {connection}\
      \ is for consumer')\n        if not self.close_connection(client, connection,\
      \ *args, **kwargs):\n            rest_connections.append(connection)\n    return\
      \ rest_connections"
    code_lines: 58
    comment_lines: 0
    complexity: 15
    description: ''
    end_line: 144
    line: 87
    message: Complexity 15 exceeds threshold 10
    name: run_once
    severity: warning
    signature: 'def run_once ( self, client: Client, max_idle_seconds: int, safe_peer_host:
      typing.List[str], peer_host: typing.List[str], *args, **kwargs ) :'
  svc-rabbitmq/vendor/management/commands/recovery_connections.py:
  - code: "\ndef channel_is_activated(self, channel, ignore_consumer):\n    if not\
      \ ignore_consumer and channel['consumer_count'] > 0:\n        return True\n\
      \    if channel['acks_uncommitted'] > 0:\n        return True\n    if channel['messages_unacknowledged']\
      \ > 0:\n        return True\n    if channel['messages_uncommitted'] > 0:\n \
      \       return True\n    if channel['messages_unconfirmed'] > 0:\n        return\
      \ True\n    message_stats = channel.get('message_stats')\n    if not message_stats:\n\
      \        return False\n    if 'confirm_details' in message_stats and message_stats['confirm_details']['rate']\
      \ > 0:\n        return True\n    if 'publish_details' in message_stats and message_stats['publish_details']['rate']\
      \ > 0:\n        return True\n    return False"
    code_lines: 27
    comment_lines: 0
    complexity: 12
    description: ''
    end_line: 143
    line: 117
    message: Complexity 12 exceeds threshold 10
    name: channel_is_activated
    severity: warning
    signature: 'def channel_is_activated ( self, channel, ignore_consumer ) :'
  svc-rabbitmq/vendor/management/commands/reset_ins_config.py:
  - code: "\ndef handle(self, host: Optional[str], port: Optional[str], password:\
      \ Optional[str], api_port: Optional[int], api_url: Optional[str], admin: Optional[str],\
      \ dry_run: bool, **options):\n    svc_objs = ServiceInstance.objects.all()\n\
      \    for svc_obj in svc_objs:\n        credentials = svc_obj.get_credentials()\n\
      \        updated_credentials = credentials.copy()\n        if api_url:\n   \
      \         updated_credentials['management_api'] = api_url\n        elif host\
      \ and api_port:\n            updated_credentials['management_api'] = 'http://%s:%s'\
      \ % (host, api_port)\n        if host:\n            updated_credentials['host']\
      \ = host\n        if port:\n            updated_credentials['port'] = port\n\
      \        if password:\n            updated_credentials['password'] = password\n\
      \        if admin:\n            updated_credentials['admin'] = admin\n     \
      \   if not dry_run and updated_credentials != credentials:\n            svc_obj.credentials\
      \ = json.dumps(updated_credentials)\n            svc_obj.save(update_fields=['credentials'])\n\
      \        self.stdout.write(self.style.NOTICE(f'实例配置变化：\\n before:{credentials}\
      \ \\n after:{updated_credentials} \\n'))"
    code_lines: 40
    comment_lines: 0
    complexity: 11
    description: ''
    end_line: 83
    line: 44
    message: Complexity 11 exceeds threshold 10
    name: handle
    severity: warning
    signature: 'def handle ( self, host: Optional[str], port: Optional[str], password:
      Optional[str], api_port: Optional[int], api_url: Optional[str], admin: Optional[str],
      dry_run: bool, **options ) :'
  svc-rabbitmq/vendor/management/commands/sync_user_policies.py:
  - code: "\ndef handle(self, add, update, delete, dry_run, sleep, *args, **kwargs):\n\
      \    vhosts = self.get_vhost_set(*args, **kwargs)\n    enabled_policies = {}\n\
      \    disabled_policies = {}\n    for p in self.get_policies(*args, **kwargs):\n\
      \        if p.enable:\n            enabled_policies[p.name] = p\n        else:\n\
      \            disabled_policies[p.name] = p\n    client = self.get_client_by_cluster(*args,\
      \ **kwargs)\n    for vhost in vhosts:\n        time.sleep(sleep)\n        policies\
      \ = {p['name']: p for p in client.user_policy.get(vhost)}\n        if add:\n\
      \            names = enabled_policies.keys() - policies.keys()\n           \
      \ print(f'policies will be add: {names}')\n            if not dry_run:\n   \
      \             self.patch_policies(vhost, client, names, enabled_policies)\n\
      \        if update:\n            names = []\n            for n in enabled_policies.keys()\
      \ & policies.keys():\n                if not self.compare_policies(enabled_policies[n].dict(),\
      \ policies[n]):\n                    names.append(n)\n            print(f'policies\
      \ will be update: {names}')\n            if not dry_run:\n                self.patch_policies(vhost,\
      \ client, names, enabled_policies)\n        if delete:\n            names =\
      \ disabled_policies & policies.keys()\n            print(f'policies will be\
      \ delete: {names}')\n            if not dry_run:\n                self.delete_policies(vhost,\
      \ client, names)"
    code_lines: 37
    comment_lines: 0
    complexity: 12
    description: ''
    end_line: 122
    line: 86
    message: Complexity 12 exceeds threshold 10
    name: handle
    severity: warning
    signature: 'def handle ( self, add, update, delete, dry_run, sleep, *args, **kwargs
      ) :'
summary:
  by_severity:
    acceptable: 33
    critical: 2
    high_risk: 10
    warning: 43
  files_scanned: 75
  high_complexity_count: 88
  scan_duration_ms: 0
  total_count: 88
